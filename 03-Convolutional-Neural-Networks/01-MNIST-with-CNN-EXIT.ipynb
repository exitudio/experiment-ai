{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is \n",
      "0.1334\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is \n",
      "0.8523\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is \n",
      "0.9096\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is \n",
      "0.9253\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is \n",
      "0.9322\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is \n",
      "0.9443\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is \n",
      "0.9505\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is \n",
      "0.9539\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is \n",
      "0.9581\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is \n",
      "0.9608\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is \n",
      "0.9594\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is \n",
      "0.9642\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is \n",
      "0.9664\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is \n",
      "0.9697\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is \n",
      "0.9692\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is \n",
      "0.9702\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is \n",
      "0.9713\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is \n",
      "0.9716\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is \n",
      "0.973\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is \n",
      "0.9751\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is \n",
      "0.9738\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is \n",
      "0.9734\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is \n",
      "0.9759\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is \n",
      "0.978\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is \n",
      "0.9779\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is \n",
      "0.9785\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is \n",
      "0.9798\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is \n",
      "0.9794\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is \n",
      "0.9804\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is \n",
      "0.9788\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is \n",
      "0.9802\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "Accuracy is \n",
      "0.9815\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "Accuracy is \n",
      "0.9812\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "Accuracy is \n",
      "0.981\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "Accuracy is \n",
      "0.9819\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "Accuracy is \n",
      "0.982\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "Accuracy is \n",
      "0.9811\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "Accuracy is \n",
      "0.9817\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "Accuracy is \n",
      "0.982\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "Accuracy is \n",
      "0.9847\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "Accuracy is \n",
      "0.9835\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "Accuracy is \n",
      "0.9834\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "Accuracy is \n",
      "0.9833\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "Accuracy is \n",
      "0.9848\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "Accuracy is \n",
      "0.9843\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "Accuracy is \n",
      "0.9852\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "Accuracy is \n",
      "0.9836\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "Accuracy is \n",
      "0.9867\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "Accuracy is \n",
      "0.9861\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "Accuracy is \n",
      "0.9863\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape,stddev=0.1) # random as normal distribution but only in 2SD\n",
    "    return tf.Variable(init_random_dist)\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "# conv func\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# layer func\n",
    "def convolutional_layer(input_x, shape):\n",
    "    # [Height, Weight, Channel(l-1), Channel(l)]\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]]) # shape[3] -> current # of channels\n",
    "    return tf.nn.relu( conv2d(input_x, W) + b)\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# initiate layer\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "\n",
    "convo_2 = convolutional_layer(convo_1_pooling, [6, 6, 32, 64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "\n",
    "# Why 7 by 7 image? Because we did 2 pooling layers, so (28/2)/2 = 7\n",
    "# 64 then just comes from the output of the previous Convolution\n",
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))\n",
    "\n",
    "# placeholder\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)\n",
    "\n",
    "y_pred = normal_full_layer(full_one_dropout, 10) # output 0-9\n",
    "\n",
    "# Loss Function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Session\n",
    "steps = 5000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        batch_x, batch_y = mnist.train.next_batch(50)\n",
    "        sess.run(train, feed_dict={x:batch_x, y_true: batch_y, hold_prob: 0.5})\n",
    "        \n",
    "        # print output every 100 steps\n",
    "        if i%100 == 0:\n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is ')\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print(sess.run(acc, feed_dict={x: mnist.test.images, y_true: mnist.test.labels, hold_prob: 1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
