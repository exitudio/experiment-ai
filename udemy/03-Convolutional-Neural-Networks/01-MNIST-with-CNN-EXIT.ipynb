{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epinyoanun/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/epinyoanun/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-45a0f29c3110>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/epinyoanun/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/epinyoanun/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/epinyoanun/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/epinyoanun/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/epinyoanun/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-400604ee3e1c>:51: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Currently on step 0\n",
      "Accuracy is \n",
      "0.1082\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is \n",
      "0.8317\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is \n",
      "0.9047\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is \n",
      "0.923\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is \n",
      "0.9369\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is \n",
      "0.945\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is \n",
      "0.9493\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is \n",
      "0.9536\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is \n",
      "0.9571\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is \n",
      "0.9555\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is \n",
      "0.9609\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is \n",
      "0.9605\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is \n",
      "0.9638\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is \n",
      "0.9677\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is \n",
      "0.9669\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is \n",
      "0.9698\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is \n",
      "0.9708\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is \n",
      "0.9723\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is \n",
      "0.9717\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is \n",
      "0.9722\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is \n",
      "0.9736\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is \n",
      "0.9749\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is \n",
      "0.9757\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is \n",
      "0.9774\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is \n",
      "0.9762\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is \n",
      "0.9761\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is \n",
      "0.9785\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is \n",
      "0.9796\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is \n",
      "0.9794\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is \n",
      "0.9806\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is \n"
     ]
    }
   ],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape,stddev=0.1) # random as normal distribution but only in 2SD\n",
    "    return tf.Variable(init_random_dist)\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "# conv func\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# layer func\n",
    "def convolutional_layer(input_x, shape):\n",
    "    # [Height, Weight, Channel(l-1), Channel(l)]\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]]) # shape[3] -> current # of channels\n",
    "    return tf.nn.relu( conv2d(input_x, W) + b)\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# initiate layer\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "\n",
    "convo_2 = convolutional_layer(convo_1_pooling, [6, 6, 32, 64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "\n",
    "# Why 7 by 7 image? Because we did 2 pooling layers, so (28/2)/2 = 7\n",
    "# 64 then just comes from the output of the previous Convolution\n",
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1, 7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat, 1024))\n",
    "\n",
    "# placeholder\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one, keep_prob=hold_prob)\n",
    "\n",
    "y_pred = normal_full_layer(full_one_dropout, 10) # output 0-9\n",
    "\n",
    "# Loss Function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Session\n",
    "steps = 5000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        batch_x, batch_y = mnist.train.next_batch(50)\n",
    "        sess.run(train, feed_dict={x:batch_x, y_true: batch_y, hold_prob: 0.5})\n",
    "        \n",
    "        # print output every 100 steps\n",
    "        if i%100 == 0:\n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is ')\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            print(sess.run(acc, feed_dict={x: mnist.test.images, y_true: mnist.test.labels, hold_prob: 1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
