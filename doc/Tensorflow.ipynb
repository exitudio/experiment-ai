{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Using session \"InteractiveSession\" instead\n",
    "# def runTensor(tensor):\n",
    "#     with tf.Session() as sess:\n",
    "#         return sess.run(tensor)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "- I'd recommend to always use ```tf.get_variable(...)``` -- it will make it way easier to refactor your code if you need to share variables at any time.\n",
    "\n",
    "\n",
    "\n",
    "- In Notebook, need to use ```tf.reset_default_graph()``` to reset graph\n",
    "- Can use ```xavier_initializer```\n",
    "\n",
    "I can find two main differences between one and the other:\n",
    "\n",
    " 1. First is that ```tf.Variable``` will always create a new variable, whether ```tf.get_variable``` gets from the graph an existing variable with those parameters, and if it does not exists, it creates a new one.\n",
    "\n",
    " 2. ```tf.Variable``` requires that an initial value be specified.\n",
    "\n",
    "[From Stackoverflow](https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0927178 ]\n",
      " [ 0.07955277]\n",
      " [-0.41374165]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "W = tf.get_variable(\"w\", shape=(3, 1), initializer=tf.contrib.layers.xavier_initializer())\n",
    "init_g = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_g)\n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variable_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"one\"):\n",
    "    a = tf.get_variable(\"v\", [1]) #a.name == \"one/v:0\"\n",
    "with tf.variable_scope(\"one\", reuse = True):\n",
    "    c = tf.get_variable(\"v\", [1]) #c.name == \"one/v:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scope_variable(scope, name, shape=None):\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        v = tf.get_variable(name, shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= [[1 2]\n",
      " [3 4]]\n",
      "b= [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.reshape([1,2,3,4],shape=[2,2])\n",
    "print('a=', a.eval())\n",
    "\n",
    "b = tf.reshape([1,2,3,4,5,6],shape=[-1,2]) # -1 means what ever that fit\n",
    "print('b=', b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (1, 2, 2, 3)\n",
      "W.shape =  (1, 1, 3, 1)\n",
      "conv.shape =  (1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[[[1,2,3],[4,5,6]],\n",
    "           [[7,8,9],[10,11,12]]]],dtype=np.float32)\n",
    "W=np.array([[[[1],[1],[1]]]],dtype=np.float32)\n",
    "\n",
    "print('x.shape = ', x.shape)\n",
    "print('W.shape = ', W.shape)\n",
    "\n",
    "# conv\n",
    "#  - stride = [batch, height(row), width(col), channel] >>> typically batch and channel should be 1 \n",
    "#             because no skip batch and apply to all channel\n",
    "#  - padding = 'SAME' add padding 0\n",
    "conv = tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "print('conv.shape = ', conv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   : 1\n",
      "height  : 2\n",
      "width   : 3\n",
      "channels: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[13, 14, 15, 16],\n",
       "         [17, 18, 19, 20],\n",
       "         [21, 22, 23, 24]],\n",
       "\n",
       "        [[13, 14, 15, 16],\n",
       "         [17, 18, 19, 20],\n",
       "         [21, 22, 23, 24]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [batch, height, width, channels]\n",
    "x = list(range(1,25))\n",
    "x = np.reshape(x,[1,2,3,4])\n",
    "\n",
    "print('batch   :',len(x))\n",
    "print('height  :',len(x[0]))\n",
    "print('width   :',len(x[0][0]))\n",
    "print('channels:',len(x[0][0][0]))\n",
    "# # Try to adjust height/width/channel of ksize and strides to make you more understand.\n",
    "# >>> typically batch and channel should be 1\n",
    "max_pool = tf.nn.max_pool( x, ksize=[1, 2, 1, 1], # size of window : [batch, height, width, channels]\n",
    "                            strides=[1, 1, 1, 1], # stride (skip) : [batch, height, width, channels]\n",
    "                            padding='SAME')\n",
    "max_pool.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "```python\n",
    "tf.nn.dropout(full_layer_one, keep_prob=hold_prob)\n",
    "```\n",
    "It's only dropout in layer, not the whole network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = tf.placeholder(tf.float32, name=\"yo\")\n",
    "x = tf.Variable(1)\n",
    "c = tf.constant(5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean([[1,2,3],[4,5,6]],axis=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax([[1,2,3],[7,5,6]],1).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64561473]\n",
      " [ 0.16171492]\n",
      " [-0.56667975]\n",
      " [-0.51069586]\n",
      " [ 0.16061438]]\n",
      "[[ 0.64128838]\n",
      " [ 0.15659153]\n",
      " [-0.56902042]\n",
      " [-0.51227018]\n",
      " [ 0.15805164]]\n",
      "[[ 0.63670926]\n",
      " [ 0.15131068]\n",
      " [-0.5715858 ]\n",
      " [-0.51399054]\n",
      " [ 0.15527839]]\n",
      "[[ 0.63187181]\n",
      " [ 0.14587935]\n",
      " [-0.57437236]\n",
      " [-0.51586501]\n",
      " [ 0.15229611]]\n",
      "[[ 0.62677544]\n",
      " [ 0.1403097 ]\n",
      " [-0.57737017]\n",
      " [-0.51790027]\n",
      " [ 0.14911173]]\n",
      "[[ 0.62142593]\n",
      " [ 0.13461987]\n",
      " [-0.5805618 ]\n",
      " [-0.52010089]\n",
      " [ 0.14573867]]\n",
      "[[ 0.61583676]\n",
      " [ 0.12883431]\n",
      " [-0.58392167]\n",
      " [-0.52246853]\n",
      " [ 0.14219744]]\n",
      "[[ 0.61002998]\n",
      " [ 0.12298357]\n",
      " [-0.58741616]\n",
      " [-0.52500112]\n",
      " [ 0.13851567]]\n",
      "[[ 0.6040366 ]\n",
      " [ 0.11710347]\n",
      " [-0.59100461]\n",
      " [-0.5276921 ]\n",
      " [ 0.13472741]]\n",
      "[[ 0.597896  ]\n",
      " [ 0.1112334 ]\n",
      " [-0.59464127]\n",
      " [-0.53052994]\n",
      " [ 0.13087159]]\n",
      "[[ 0.59165461]\n",
      " [ 0.10541426]\n",
      " [-0.59827816]\n",
      " [-0.53349791]\n",
      " [ 0.12698977]]\n",
      "[[ 0.5853637 ]\n",
      " [ 0.09968603]\n",
      " [-0.60186829]\n",
      " [-0.5365744 ]\n",
      " [ 0.1231236 ]]\n",
      "[[ 0.57907674]\n",
      " [ 0.09408567]\n",
      " [-0.60536864]\n",
      " [-0.53973363]\n",
      " [ 0.11931234]]\n",
      "[[ 0.57284653]\n",
      " [ 0.08864547]\n",
      " [-0.60874272]\n",
      " [-0.54294685]\n",
      " [ 0.11559075]]\n",
      "[[ 0.56672261]\n",
      " [ 0.08339199]\n",
      " [-0.611962  ]\n",
      " [-0.54618381]\n",
      " [ 0.11198781]]\n",
      "[[ 0.56074901]\n",
      " [ 0.07834572]\n",
      " [-0.61500646]\n",
      " [-0.54941439]\n",
      " [ 0.10852604]]\n",
      "[[ 0.55496277]\n",
      " [ 0.07352109]\n",
      " [-0.61786424]\n",
      " [-0.55261015]\n",
      " [ 0.10522148]]\n",
      "[[ 0.549393  ]\n",
      " [ 0.06892692]\n",
      " [-0.62053066]\n",
      " [-0.55574561]\n",
      " [ 0.10208417]]\n",
      "[[ 0.54406074]\n",
      " [ 0.06456696]\n",
      " [-0.62300692]\n",
      " [-0.55879918]\n",
      " [ 0.09911888]]\n",
      "[[ 0.53897924]\n",
      " [ 0.06044061]\n",
      " [-0.62529871]\n",
      " [-0.56175372]\n",
      " [ 0.09632598]]\n",
      "[[ 0.53415478]\n",
      " [ 0.05654363]\n",
      " [-0.62741486]\n",
      " [-0.56459657]\n",
      " [ 0.09370234]]\n",
      "[[ 0.52958772]\n",
      " [ 0.05286892]\n",
      " [-0.62936621]\n",
      " [-0.56731937]\n",
      " [ 0.09124224]]\n",
      "[[ 0.5252736 ]\n",
      " [ 0.04940722]\n",
      " [-0.63116462]\n",
      " [-0.56991756]\n",
      " [ 0.0889381 ]]\n",
      "[[ 0.52120435]\n",
      " [ 0.0461478 ]\n",
      " [-0.63282234]\n",
      " [-0.57238979]\n",
      " [ 0.08678119]]\n",
      "[[ 0.51736936]\n",
      " [ 0.043079  ]\n",
      " [-0.6343514 ]\n",
      " [-0.57473724]\n",
      " [ 0.08476213]]\n",
      "[[ 0.51375634]\n",
      " [ 0.04018879]\n",
      " [-0.63576336]\n",
      " [-0.57696304]\n",
      " [ 0.08287133]]\n",
      "[[ 0.51035212]\n",
      " [ 0.03746508]\n",
      " [-0.63706902]\n",
      " [-0.57907165]\n",
      " [ 0.08109933]]\n",
      "[[ 0.50714321]\n",
      " [ 0.03489606]\n",
      " [-0.63827837]\n",
      " [-0.58106847]\n",
      " [ 0.07943697]]\n",
      "[[ 0.50411621]\n",
      " [ 0.03247039]\n",
      " [-0.63940054]\n",
      " [-0.5829594 ]\n",
      " [ 0.07787558]]\n",
      "[[ 0.50125814]\n",
      " [ 0.03017733]\n",
      " [-0.64044378]\n",
      " [-0.58475058]\n",
      " [ 0.076407  ]]\n",
      "[[ 0.49855663]\n",
      " [ 0.0280068 ]\n",
      " [-0.64141554]\n",
      " [-0.58644819]\n",
      " [ 0.07502371]]\n",
      "[[ 0.49600003]\n",
      " [ 0.02594947]\n",
      " [-0.64232249]\n",
      " [-0.58805827]\n",
      " [ 0.07371874]]\n",
      "[[ 0.49357745]\n",
      " [ 0.02399667]\n",
      " [-0.6431706 ]\n",
      " [-0.58958665]\n",
      " [ 0.07248576]]\n",
      "[[ 0.49127882]\n",
      " [ 0.02214049]\n",
      " [-0.64396522]\n",
      " [-0.59103886]\n",
      " [ 0.07131893]]\n",
      "[[ 0.48909484]\n",
      " [ 0.02037362]\n",
      " [-0.64471111]\n",
      " [-0.59242013]\n",
      " [ 0.070213  ]]\n",
      "[[ 0.48701698]\n",
      " [ 0.01868941]\n",
      " [-0.64541253]\n",
      " [-0.59373531]\n",
      " [ 0.06916316]]\n",
      "[[ 0.48503741]\n",
      " [ 0.01708179]\n",
      " [-0.64607329]\n",
      " [-0.59498895]\n",
      " [ 0.06816506]]\n",
      "[[ 0.48314898]\n",
      " [ 0.01554521]\n",
      " [-0.64669679]\n",
      " [-0.59618526]\n",
      " [ 0.06721475]]\n",
      "[[ 0.48134513]\n",
      " [ 0.0140746 ]\n",
      " [-0.64728609]\n",
      " [-0.59732811]\n",
      " [ 0.06630865]]\n",
      "[[ 0.47961989]\n",
      " [ 0.01266536]\n",
      " [-0.64784392]\n",
      " [-0.5984211 ]\n",
      " [ 0.06544351]]\n",
      "[[ 0.4779678 ]\n",
      " [ 0.01131328]\n",
      " [-0.64837276]\n",
      " [-0.59946752]\n",
      " [ 0.06461638]]\n",
      "[[ 0.47638385]\n",
      " [ 0.0100145 ]\n",
      " [-0.6488748 ]\n",
      " [-0.60047041]\n",
      " [ 0.06382458]]\n",
      "[[ 0.4748635 ]\n",
      " [ 0.00876551]\n",
      " [-0.64935205]\n",
      " [-0.60143258]\n",
      " [ 0.06306566]]\n",
      "[[ 0.47340255]\n",
      " [ 0.0075631 ]\n",
      " [-0.64980631]\n",
      " [-0.60235661]\n",
      " [ 0.0623374 ]]\n",
      "[[ 0.47199718]\n",
      " [ 0.00640432]\n",
      " [-0.65023923]\n",
      " [-0.60324486]\n",
      " [ 0.06163776]]\n",
      "[[ 0.47064388]\n",
      " [ 0.00528648]\n",
      " [-0.65065228]\n",
      " [-0.60409953]\n",
      " [ 0.0609649 ]]\n",
      "[[ 0.46933942]\n",
      " [ 0.00420708]\n",
      " [-0.65104681]\n",
      " [-0.60492264]\n",
      " [ 0.0603171 ]]\n",
      "[[ 0.46808084]\n",
      " [ 0.00316384]\n",
      " [-0.65142404]\n",
      " [-0.60571604]\n",
      " [ 0.05969282]]\n",
      "[[ 0.46686542]\n",
      " [ 0.00215467]\n",
      " [-0.65178511]\n",
      " [-0.60648146]\n",
      " [ 0.05909063]]\n",
      "[[ 0.46569064]\n",
      " [ 0.00117763]\n",
      " [-0.65213103]\n",
      " [-0.60722049]\n",
      " [ 0.05850922]]\n",
      "[[ 4.64554178e-01]\n",
      " [ 2.30927490e-04]\n",
      " [-6.52462742e-01]\n",
      " [-6.07934603e-01]\n",
      " [ 5.79473644e-02]]\n",
      "[[ 0.46345389]\n",
      " [-0.00068709]\n",
      " [-0.6527811 ]\n",
      " [-0.60862516]\n",
      " [ 0.05740396]]\n",
      "[[ 0.46238781]\n",
      " [-0.00157796]\n",
      " [-0.65308691]\n",
      " [-0.60929342]\n",
      " [ 0.05687798]]\n",
      "[[ 0.46135408]\n",
      " [-0.00244309]\n",
      " [-0.65338088]\n",
      " [-0.60994057]\n",
      " [ 0.05636846]]\n",
      "[[ 0.46035101]\n",
      " [-0.00328381]\n",
      " [-0.65366369]\n",
      " [-0.6105677 ]\n",
      " [ 0.05587453]]\n",
      "[[ 0.459377  ]\n",
      " [-0.00410134]\n",
      " [-0.65393596]\n",
      " [-0.61117583]\n",
      " [ 0.05539537]]\n",
      "[[ 0.4584306 ]\n",
      " [-0.00489682]\n",
      " [-0.65419827]\n",
      " [-0.6117659 ]\n",
      " [ 0.05493022]]\n",
      "[[ 0.45751043]\n",
      " [-0.00567132]\n",
      " [-0.65445113]\n",
      " [-0.61233879]\n",
      " [ 0.05447837]]\n",
      "[[ 0.45661521]\n",
      " [-0.00642583]\n",
      " [-0.65469506]\n",
      " [-0.61289534]\n",
      " [ 0.05403916]]\n",
      "[[ 0.45574374]\n",
      " [-0.00716127]\n",
      " [-0.6549305 ]\n",
      " [-0.61343632]\n",
      " [ 0.053612  ]]\n",
      "[[ 0.45489493]\n",
      " [-0.00787852]\n",
      " [-0.65515788]\n",
      " [-0.61396244]\n",
      " [ 0.05319629]]\n",
      "[[ 0.45406771]\n",
      " [-0.00857838]\n",
      " [-0.65537759]\n",
      " [-0.61447438]\n",
      " [ 0.05279151]]\n",
      "[[ 0.45326111]\n",
      " [-0.00926163]\n",
      " [-0.65559002]\n",
      " [-0.61497278]\n",
      " [ 0.05239715]]\n",
      "[[ 0.45247423]\n",
      " [-0.00992896]\n",
      " [-0.65579549]\n",
      " [-0.61545823]\n",
      " [ 0.05201275]]\n",
      "[[ 0.45170619]\n",
      " [-0.01058107]\n",
      " [-0.65599434]\n",
      " [-0.6159313 ]\n",
      " [ 0.05163788]]\n",
      "[[ 0.4509562 ]\n",
      " [-0.01121857]\n",
      " [-0.65618687]\n",
      " [-0.61639251]\n",
      " [ 0.0512721 ]]\n",
      "[[ 0.45022348]\n",
      " [-0.01184206]\n",
      " [-0.65637336]\n",
      " [-0.61684235]\n",
      " [ 0.05091505]]\n",
      "[[ 0.44950733]\n",
      " [-0.01245211]\n",
      " [-0.65655407]\n",
      " [-0.61728129]\n",
      " [ 0.05056635]]\n",
      "[[ 0.44880707]\n",
      " [-0.01304924]\n",
      " [-0.65672927]\n",
      " [-0.61770978]\n",
      " [ 0.05022566]]\n",
      "[[ 0.44812207]\n",
      " [-0.01363395]\n",
      " [-0.65689918]\n",
      " [-0.61812823]\n",
      " [ 0.04989266]]\n",
      "[[ 0.44745172]\n",
      " [-0.01420672]\n",
      " [-0.65706402]\n",
      " [-0.61853703]\n",
      " [ 0.04956703]]\n",
      "[[ 0.44679545]\n",
      " [-0.01476799]\n",
      " [-0.657224  ]\n",
      " [-0.61893655]\n",
      " [ 0.0492485 ]]\n",
      "[[ 0.44615274]\n",
      " [-0.01531818]\n",
      " [-0.65737932]\n",
      " [-0.61932716]\n",
      " [ 0.04893679]]\n",
      "[[ 0.44552307]\n",
      " [-0.0158577 ]\n",
      " [-0.65753017]\n",
      " [-0.61970917]\n",
      " [ 0.04863165]]\n",
      "[[ 0.44490596]\n",
      " [-0.01638693]\n",
      " [-0.65767672]\n",
      " [-0.6200829 ]\n",
      " [ 0.04833282]]\n",
      "[[ 0.44430095]\n",
      " [-0.01690622]\n",
      " [-0.65781913]\n",
      " [-0.62044866]\n",
      " [ 0.04804007]]\n",
      "[[ 0.44370762]\n",
      " [-0.01741593]\n",
      " [-0.65795757]\n",
      " [-0.62080674]\n",
      " [ 0.04775319]]\n",
      "[[ 0.44312554]\n",
      " [-0.01791637]\n",
      " [-0.65809217]\n",
      " [-0.62115739]\n",
      " [ 0.04747197]]\n",
      "[[ 0.44255433]\n",
      " [-0.01840786]\n",
      " [-0.65822309]\n",
      " [-0.62150088]\n",
      " [ 0.04719621]]\n",
      "[[ 0.44199362]\n",
      " [-0.0188907 ]\n",
      " [-0.65835046]\n",
      " [-0.62183745]\n",
      " [ 0.04692572]]\n",
      "[[ 0.44144305]\n",
      " [-0.01936515]\n",
      " [-0.6584744 ]\n",
      " [-0.62216734]\n",
      " [ 0.04666032]]\n",
      "[[ 0.44090228]\n",
      " [-0.0198315 ]\n",
      " [-0.65859503]\n",
      " [-0.62249076]\n",
      " [ 0.04639985]]\n",
      "[[ 0.440371  ]\n",
      " [-0.02028999]\n",
      " [-0.65871248]\n",
      " [-0.62280793]\n",
      " [ 0.04614413]]\n",
      "[[ 0.4398489 ]\n",
      " [-0.02074088]\n",
      " [-0.65882684]\n",
      " [-0.62311906]\n",
      " [ 0.04589302]]\n",
      "[[ 0.43933568]\n",
      " [-0.02118439]\n",
      " [-0.65893822]\n",
      " [-0.62342433]\n",
      " [ 0.04564637]]\n",
      "[[ 0.43883107]\n",
      " [-0.02162075]\n",
      " [-0.65904673]\n",
      " [-0.62372392]\n",
      " [ 0.04540403]]\n",
      "[[ 0.4383348 ]\n",
      " [-0.02205018]\n",
      " [-0.65915245]\n",
      " [-0.62401802]\n",
      " [ 0.04516588]]\n",
      "[[ 0.43784661]\n",
      " [-0.02247287]\n",
      " [-0.65925548]\n",
      " [-0.62430679]\n",
      " [ 0.04493178]]\n",
      "[[ 0.43736626]\n",
      " [-0.02288902]\n",
      " [-0.6593559 ]\n",
      " [-0.6245904 ]\n",
      " [ 0.0447016 ]]\n",
      "[[ 0.43689352]\n",
      " [-0.02329882]\n",
      " [-0.65945379]\n",
      " [-0.62486899]\n",
      " [ 0.04447524]]\n",
      "[[ 0.43642816]\n",
      " [-0.02370245]\n",
      " [-0.65954924]\n",
      " [-0.62514272]\n",
      " [ 0.04425258]]\n",
      "[[ 0.43596997]\n",
      " [-0.02410008]\n",
      " [-0.65964232]\n",
      " [-0.62541172]\n",
      " [ 0.04403351]]\n",
      "[[ 0.43551875]\n",
      " [-0.02449187]\n",
      " [-0.6597331 ]\n",
      " [-0.62567614]\n",
      " [ 0.04381793]]\n",
      "[[ 0.43507429]\n",
      " [-0.02487799]\n",
      " [-0.65982165]\n",
      " [-0.62593609]\n",
      " [ 0.04360573]]\n",
      "[[ 0.43463641]\n",
      " [-0.02525859]\n",
      " [-0.65990803]\n",
      " [-0.62619172]\n",
      " [ 0.04339683]]\n",
      "[[ 0.43420492]\n",
      " [-0.02563381]\n",
      " [-0.65999231]\n",
      " [-0.62644313]\n",
      " [ 0.04319113]]\n",
      "[[ 0.43377965]\n",
      " [-0.0260038 ]\n",
      " [-0.66007455]\n",
      " [-0.62669044]\n",
      " [ 0.04298855]]\n",
      "[[ 0.43336044]\n",
      " [-0.02636869]\n",
      " [-0.66015481]\n",
      " [-0.62693377]\n",
      " [ 0.04278899]]\n",
      "[[ 0.43294712]\n",
      " [-0.02672861]\n",
      " [-0.66023315]\n",
      " [-0.62717322]\n",
      " [ 0.04259239]]\n",
      "[[ 0.43253954]\n",
      " [-0.02708368]\n",
      " [-0.66030961]\n",
      " [-0.62740889]\n",
      " [ 0.04239865]]\n",
      "[[ 0.43213755]\n",
      " [-0.02743403]\n",
      " [-0.66038425]\n",
      " [-0.62764088]\n",
      " [ 0.04220771]]\n",
      "[[ 0.431741  ]\n",
      " [-0.02777978]\n",
      " [-0.66045712]\n",
      " [-0.62786928]\n",
      " [ 0.04201949]]\n",
      "[[ 0.43134976]\n",
      " [-0.02812103]\n",
      " [-0.66052827]\n",
      " [-0.6280942 ]\n",
      " [ 0.04183393]]\n",
      "[[ 0.43096369]\n",
      " [-0.02845789]\n",
      " [-0.66059774]\n",
      " [-0.62831571]\n",
      " [ 0.04165095]]\n",
      "[[ 0.43058267]\n",
      " [-0.02879048]\n",
      " [-0.66066558]\n",
      " [-0.6285339 ]\n",
      " [ 0.0414705 ]]\n",
      "[[ 0.43020656]\n",
      " [-0.02911888]\n",
      " [-0.66073182]\n",
      " [-0.62874886]\n",
      " [ 0.04129251]]\n",
      "[[ 0.42983526]\n",
      " [-0.02944321]\n",
      " [-0.66079652]\n",
      " [-0.62896065]\n",
      " [ 0.04111692]]\n",
      "[[ 0.42946864]\n",
      " [-0.02976354]\n",
      " [-0.6608597 ]\n",
      " [-0.62916937]\n",
      " [ 0.04094366]]\n",
      "[[ 0.4291066 ]\n",
      " [-0.03007998]\n",
      " [-0.66092142]\n",
      " [-0.62937508]\n",
      " [ 0.0407727 ]]\n",
      "[[ 0.42874902]\n",
      " [-0.03039261]\n",
      " [-0.6609817 ]\n",
      " [-0.62957785]\n",
      " [ 0.04060397]]\n",
      "[[ 0.42839581]\n",
      " [-0.03070151]\n",
      " [-0.66104058]\n",
      " [-0.62977775]\n",
      " [ 0.04043741]]\n",
      "[[ 0.42804685]\n",
      " [-0.03100677]\n",
      " [-0.66109809]\n",
      " [-0.62997485]\n",
      " [ 0.04027299]]\n",
      "[[ 0.42770206]\n",
      " [-0.03130847]\n",
      " [-0.66115427]\n",
      " [-0.63016922]\n",
      " [ 0.04011065]]\n",
      "[[ 0.42736134]\n",
      " [-0.03160669]\n",
      " [-0.66120915]\n",
      " [-0.63036091]\n",
      " [ 0.03995034]]\n",
      "[[ 0.4270246 ]\n",
      " [-0.0319015 ]\n",
      " [-0.66126277]\n",
      " [-0.63054999]\n",
      " [ 0.03979201]]\n",
      "[[ 0.42669176]\n",
      " [-0.03219296]\n",
      " [-0.66131514]\n",
      " [-0.63073651]\n",
      " [ 0.03963564]]\n",
      "[[ 0.42636271]\n",
      " [-0.03248116]\n",
      " [-0.6613663 ]\n",
      " [-0.63092053]\n",
      " [ 0.03948116]]\n",
      "[[ 0.4260374 ]\n",
      " [-0.03276616]\n",
      " [-0.66141628]\n",
      " [-0.63110211]\n",
      " [ 0.03932854]]\n",
      "[[ 0.42571572]\n",
      " [-0.03304803]\n",
      " [-0.6614651 ]\n",
      " [-0.63128129]\n",
      " [ 0.03917774]]\n",
      "[[ 0.42539761]\n",
      " [-0.03332683]\n",
      " [-0.66151279]\n",
      " [-0.63145813]\n",
      " [ 0.03902873]]\n",
      "[[ 0.425083  ]\n",
      " [-0.03360261]\n",
      " [-0.66155938]\n",
      " [-0.63163269]\n",
      " [ 0.03888145]]\n",
      "[[ 0.4247718 ]\n",
      " [-0.03387545]\n",
      " [-0.66160488]\n",
      " [-0.631805  ]\n",
      " [ 0.03873588]]\n",
      "[[ 0.42446395]\n",
      " [-0.0341454 ]\n",
      " [-0.66164933]\n",
      " [-0.63197511]\n",
      " [ 0.03859199]]\n",
      "[[ 0.42415938]\n",
      " [-0.03441252]\n",
      " [-0.66169275]\n",
      " [-0.63214308]\n",
      " [ 0.03844973]]\n",
      "[[ 0.42385802]\n",
      " [-0.03467686]\n",
      " [-0.66173516]\n",
      " [-0.63230893]\n",
      " [ 0.03830907]]\n",
      "[[ 0.4235598 ]\n",
      " [-0.03493847]\n",
      " [-0.66177657]\n",
      " [-0.63247273]\n",
      " [ 0.03816999]]\n",
      "[[ 0.42326468]\n",
      " [-0.03519741]\n",
      " [-0.66181702]\n",
      " [-0.6326345 ]\n",
      " [ 0.03803244]]\n",
      "[[ 0.42297258]\n",
      " [-0.03545373]\n",
      " [-0.66185652]\n",
      " [-0.63279429]\n",
      " [ 0.0378964 ]]\n",
      "[[ 0.42268344]\n",
      " [-0.03570748]\n",
      " [-0.66189509]\n",
      " [-0.63295213]\n",
      " [ 0.03776185]]\n",
      "[[ 0.42239721]\n",
      " [-0.0359587 ]\n",
      " [-0.66193276]\n",
      " [-0.63310807]\n",
      " [ 0.03762874]]\n",
      "[[ 0.42211383]\n",
      " [-0.03620745]\n",
      " [-0.66196953]\n",
      " [-0.63326215]\n",
      " [ 0.03749706]]\n",
      "[[ 0.42183325]\n",
      " [-0.03645376]\n",
      " [-0.66200543]\n",
      " [-0.63341439]\n",
      " [ 0.03736677]]\n",
      "[[ 0.42155542]\n",
      " [-0.03669768]\n",
      " [-0.66204047]\n",
      " [-0.63356483]\n",
      " [ 0.03723785]]\n",
      "[[ 0.42128027]\n",
      " [-0.03693925]\n",
      " [-0.66207468]\n",
      " [-0.63371351]\n",
      " [ 0.03711028]]\n",
      "[[ 0.42100778]\n",
      " [-0.03717852]\n",
      " [-0.66210806]\n",
      " [-0.63386047]\n",
      " [ 0.03698402]]\n",
      "[[ 0.42073787]\n",
      " [-0.03741553]\n",
      " [-0.66214064]\n",
      " [-0.63400572]\n",
      " [ 0.03685906]]\n",
      "[[ 0.42047051]\n",
      " [-0.03765031]\n",
      " [-0.66217243]\n",
      " [-0.63414931]\n",
      " [ 0.03673537]]\n",
      "[[ 0.42020566]\n",
      " [-0.0378829 ]\n",
      " [-0.66220344]\n",
      " [-0.63429126]\n",
      " [ 0.03661292]]\n",
      "[[ 0.41994326]\n",
      " [-0.03811335]\n",
      " [-0.6622337 ]\n",
      " [-0.63443161]\n",
      " [ 0.03649171]]\n",
      "[[ 0.41968327]\n",
      " [-0.03834168]\n",
      " [-0.66226321]\n",
      " [-0.63457037]\n",
      " [ 0.03637169]]\n",
      "[[ 0.41942565]\n",
      " [-0.03856794]\n",
      " [-0.66229199]\n",
      " [-0.63470759]\n",
      " [ 0.03625286]]\n",
      "[[ 0.41917036]\n",
      " [-0.03879215]\n",
      " [-0.66232005]\n",
      " [-0.63484329]\n",
      " [ 0.03613518]]\n",
      "[[ 0.41891736]\n",
      " [-0.03901436]\n",
      " [-0.66234741]\n",
      " [-0.63497749]\n",
      " [ 0.03601865]]\n",
      "[[ 0.41866661]\n",
      " [-0.03923459]\n",
      " [-0.66237407]\n",
      " [-0.63511023]\n",
      " [ 0.03590324]]\n",
      "[[ 0.41841806]\n",
      " [-0.03945289]\n",
      " [-0.66240006]\n",
      " [-0.63524152]\n",
      " [ 0.03578893]]\n",
      "[[ 0.41817169]\n",
      " [-0.03966927]\n",
      " [-0.66242538]\n",
      " [-0.63537139]\n",
      " [ 0.0356757 ]]\n",
      "[[ 0.41792746]\n",
      " [-0.03988377]\n",
      " [-0.66245004]\n",
      " [-0.63549987]\n",
      " [ 0.03556354]]\n",
      "[[ 0.41768532]\n",
      " [-0.04009642]\n",
      " [-0.66247407]\n",
      " [-0.63562697]\n",
      " [ 0.03545243]]\n",
      "[[ 0.41744525]\n",
      " [-0.04030725]\n",
      " [-0.66249746]\n",
      " [-0.63575273]\n",
      " [ 0.03534234]]\n",
      "[[ 0.41720722]\n",
      " [-0.04051629]\n",
      " [-0.66252023]\n",
      " [-0.63587717]\n",
      " [ 0.03523327]]\n",
      "[[ 0.41697118]\n",
      " [-0.04072357]\n",
      " [-0.66254239]\n",
      " [-0.6360003 ]\n",
      " [ 0.0351252 ]]\n",
      "[[ 0.4167371 ]\n",
      " [-0.0409291 ]\n",
      " [-0.66256396]\n",
      " [-0.63612214]\n",
      " [ 0.0350181 ]]\n",
      "[[ 0.41650496]\n",
      " [-0.04113293]\n",
      " [-0.66258493]\n",
      " [-0.63624273]\n",
      " [ 0.03491197]]\n",
      "[[ 0.41627473]\n",
      " [-0.04133508]\n",
      " [-0.66260532]\n",
      " [-0.63636208]\n",
      " [ 0.03480678]]\n",
      "[[ 0.41604636]\n",
      " [-0.04153557]\n",
      " [-0.66262515]\n",
      " [-0.6364802 ]\n",
      " [ 0.03470253]]\n",
      "[[ 0.41581984]\n",
      " [-0.04173442]\n",
      " [-0.66264442]\n",
      " [-0.63659713]\n",
      " [ 0.0345992 ]]\n",
      "[[ 0.41559514]\n",
      " [-0.04193166]\n",
      " [-0.66266314]\n",
      " [-0.63671287]\n",
      " [ 0.03449678]]\n",
      "[[ 0.41537222]\n",
      " [-0.04212733]\n",
      " [-0.66268131]\n",
      " [-0.63682745]\n",
      " [ 0.03439524]]\n",
      "[[ 0.41515106]\n",
      " [-0.04232142]\n",
      " [-0.66269896]\n",
      " [-0.63694088]\n",
      " [ 0.03429458]]\n",
      "[[ 0.41493163]\n",
      " [-0.04251398]\n",
      " [-0.66271608]\n",
      " [-0.63705318]\n",
      " [ 0.03419478]]\n",
      "[[ 0.41471391]\n",
      " [-0.04270503]\n",
      " [-0.66273269]\n",
      " [-0.63716438]\n",
      " [ 0.03409584]]\n",
      "[[ 0.41449787]\n",
      " [-0.04289458]\n",
      " [-0.66274879]\n",
      " [-0.63727448]\n",
      " [ 0.03399773]]\n",
      "[[ 0.41428348]\n",
      " [-0.04308265]\n",
      " [-0.66276439]\n",
      " [-0.6373835 ]\n",
      " [ 0.03390045]]\n",
      "[[ 0.41407072]\n",
      " [-0.04326928]\n",
      " [-0.6627795 ]\n",
      " [-0.63749146]\n",
      " [ 0.03380397]]\n",
      "[[ 0.41385957]\n",
      " [-0.04345447]\n",
      " [-0.66279413]\n",
      " [-0.63759838]\n",
      " [ 0.0337083 ]]\n",
      "[[ 0.41365001]\n",
      " [-0.04363825]\n",
      " [-0.66280828]\n",
      " [-0.63770427]\n",
      " [ 0.03361342]]\n",
      "[[ 0.413442  ]\n",
      " [-0.04382063]\n",
      " [-0.66282197]\n",
      " [-0.63780914]\n",
      " [ 0.03351931]]\n",
      "[[ 0.41323553]\n",
      " [-0.04400165]\n",
      " [-0.66283519]\n",
      " [-0.63791302]\n",
      " [ 0.03342597]]\n",
      "[[ 0.41303057]\n",
      " [-0.04418131]\n",
      " [-0.66284796]\n",
      " [-0.63801591]\n",
      " [ 0.03333339]]\n",
      "[[ 0.41282711]\n",
      " [-0.04435964]\n",
      " [-0.66286029]\n",
      " [-0.63811783]\n",
      " [ 0.03324155]]\n",
      "[[ 0.41262512]\n",
      " [-0.04453664]\n",
      " [-0.66287218]\n",
      " [-0.6382188 ]\n",
      " [ 0.03315044]]\n",
      "[[ 0.41242458]\n",
      " [-0.04471235]\n",
      " [-0.66288363]\n",
      " [-0.63831882]\n",
      " [ 0.03306006]]\n",
      "[[ 0.41222547]\n",
      " [-0.04488678]\n",
      " [-0.66289466]\n",
      " [-0.63841791]\n",
      " [ 0.03297038]]\n",
      "[[ 0.41202778]\n",
      " [-0.04505994]\n",
      " [-0.66290526]\n",
      " [-0.63851609]\n",
      " [ 0.03288142]]\n",
      "[[ 0.41183147]\n",
      " [-0.04523185]\n",
      " [-0.66291545]\n",
      " [-0.63861336]\n",
      " [ 0.03279314]]\n",
      "[[ 0.41163654]\n",
      " [-0.04540253]\n",
      " [-0.66292524]\n",
      " [-0.63870974]\n",
      " [ 0.03270555]]\n",
      "[[ 0.41144296]\n",
      " [-0.045572  ]\n",
      " [-0.66293462]\n",
      " [-0.63880524]\n",
      " [ 0.03261863]]\n",
      "[[ 0.41125072]\n",
      " [-0.04574026]\n",
      " [-0.66294361]\n",
      " [-0.63889988]\n",
      " [ 0.03253238]]\n",
      "[[ 0.41105979]\n",
      " [-0.04590734]\n",
      " [-0.6629522 ]\n",
      " [-0.63899366]\n",
      " [ 0.03244679]]\n",
      "[[ 0.41087017]\n",
      " [-0.04607325]\n",
      " [-0.66296041]\n",
      " [-0.6390866 ]\n",
      " [ 0.03236184]]\n",
      "[[ 0.41068183]\n",
      " [-0.04623801]\n",
      " [-0.66296824]\n",
      " [-0.63917871]\n",
      " [ 0.03227753]]\n",
      "[[ 0.41049475]\n",
      " [-0.04640162]\n",
      " [-0.6629757 ]\n",
      " [-0.63927   ]\n",
      " [ 0.03219385]]\n",
      "[[ 0.41030892]\n",
      " [-0.04656411]\n",
      " [-0.66298279]\n",
      " [-0.63936048]\n",
      " [ 0.0321108 ]]\n",
      "[[ 0.41012432]\n",
      " [-0.04672549]\n",
      " [-0.66298951]\n",
      " [-0.63945016]\n",
      " [ 0.03202835]]\n",
      "[[ 0.40994094]\n",
      " [-0.04688576]\n",
      " [-0.66299588]\n",
      " [-0.63953905]\n",
      " [ 0.03194652]]\n",
      "[[ 0.40975877]\n",
      " [-0.04704496]\n",
      " [-0.66300189]\n",
      " [-0.63962717]\n",
      " [ 0.03186528]]\n",
      "[[ 0.40957777]\n",
      " [-0.04720308]\n",
      " [-0.66300756]\n",
      " [-0.63971451]\n",
      " [ 0.03178463]]\n",
      "[[ 0.40939795]\n",
      " [-0.04736015]\n",
      " [-0.66301288]\n",
      " [-0.6398011 ]\n",
      " [ 0.03170457]]\n",
      "[[ 0.40921928]\n",
      " [-0.04751616]\n",
      " [-0.66301786]\n",
      " [-0.63988694]\n",
      " [ 0.03162508]]\n",
      "[[ 0.40904176]\n",
      " [-0.04767115]\n",
      " [-0.66302251]\n",
      " [-0.63997204]\n",
      " [ 0.03154616]]\n",
      "[[ 0.40886536]\n",
      " [-0.04782512]\n",
      " [-0.66302682]\n",
      " [-0.64005642]\n",
      " [ 0.0314678 ]]\n",
      "[[ 0.40869007]\n",
      " [-0.04797807]\n",
      " [-0.66303081]\n",
      " [-0.64014007]\n",
      " [ 0.03138999]]\n",
      "[[ 0.40851588]\n",
      " [-0.04813003]\n",
      " [-0.66303448]\n",
      " [-0.64022302]\n",
      " [ 0.03131274]]\n",
      "[[ 0.40834278]\n",
      " [-0.04828101]\n",
      " [-0.66303784]\n",
      " [-0.64030526]\n",
      " [ 0.03123602]]\n",
      "[[ 0.40817075]\n",
      " [-0.04843101]\n",
      " [-0.66304087]\n",
      " [-0.64038681]\n",
      " [ 0.03115983]]\n",
      "[[ 0.40799977]\n",
      " [-0.04858005]\n",
      " [-0.6630436 ]\n",
      " [-0.64046767]\n",
      " [ 0.03108418]]\n",
      "[[ 0.40782985]\n",
      " [-0.04872815]\n",
      " [-0.66304603]\n",
      " [-0.64054786]\n",
      " [ 0.03100904]]\n",
      "[[ 0.40766096]\n",
      " [-0.0488753 ]\n",
      " [-0.66304815]\n",
      " [-0.64062738]\n",
      " [ 0.03093442]]\n",
      "[[ 0.40749308]\n",
      " [-0.04902152]\n",
      " [-0.66304998]\n",
      " [-0.64070624]\n",
      " [ 0.03086031]]\n",
      "[[ 0.40732622]\n",
      " [-0.04916682]\n",
      " [-0.66305152]\n",
      " [-0.64078445]\n",
      " [ 0.0307867 ]]\n"
     ]
    }
   ],
   "source": [
    "X_ = tf.placeholder(tf.float64, [None, 5], name=\"Input\")\n",
    "Y_ = tf.placeholder(tf.float64, [None, 1], name=\"Output\")\n",
    "\n",
    "X = np.random.randint(1,10,[10,5])\n",
    "Y = np.random.randint(0,2,[10,1])\n",
    "\n",
    "with tf.variable_scope(\"LogReg\"):\n",
    "    # reuse = True : just for rerunning this snipplet\n",
    "    pred = tf.contrib.layers.fully_connected(X_, 1, activation_fn=tf.nn.sigmoid, scope = 'fc1', reuse=tf.AUTO_REUSE)\n",
    "    loss = tf.losses.mean_squared_error(labels=Y_, predictions=pred)\n",
    "    training_ops = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    all_vars= tf.global_variables()\n",
    "    def get_var(name):\n",
    "        for i in range(len(all_vars)):\n",
    "            if all_vars[i].name.startswith(name):\n",
    "                return all_vars[i]\n",
    "        return None\n",
    "    fc1_var = get_var('LogReg/fc1/weights')\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    for i in range(200):\n",
    "        _,fc1_var_np = sess.run([training_ops,fc1_var], feed_dict={\n",
    "        X_: X,\n",
    "        Y_: Y \n",
    "        })\n",
    "        print(fc1_var_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:0 [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "b:0 [0. 0. 0. 0.]\n",
      "W_1:0 [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "b_1:0 [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.zeros([2,4]), name=\"W\")\n",
    "b = tf.Variable(tf.zeros([4]), name=\"b\")\n",
    "c = a+b\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(c)\n",
    "\n",
    "# Get all weight\n",
    "tvars = tf.trainable_variables()\n",
    "tvars_vals = sess.run(tvars)\n",
    "for var, val in zip(tvars, tvars_vals):\n",
    "    print(var.name, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. get weight from manual code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex. 1\n",
    "w_b = [v for v in tf.global_variables() if v.name == 'layer_1/w:0' or v.name == 'layer_1/b:0']\n",
    "w_val = w_b[0].eval()\n",
    "b_val = w_b[1].eval()\n",
    "w_val, b_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex. 2\n",
    "model_vars = tf.trainable_variables()\n",
    "d_A_vars = [var for var in model_vars if 'd_A' in var.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. get weight from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = tf.estimator.LinearClassifier.get_variable_names(train)\n",
    "for name in var_names:\n",
    "    var_value = tf.estimator.LinearClassifier.get_variable_value(train, name)\n",
    "    print(name, var_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 4])\n",
    "y = tf.constant([2, 5])\n",
    "z = tf.constant([3, 6])\n",
    "print(tf.stack([x, y, z]).eval()) # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)\n",
    "print(tf.stack([x, y, z], axis=1).eval())  # [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy\n",
    "From this [link](https://stackoverflow.com/questions/46291253/tensorflow-sigmoid-and-cross-entropy-vs-sigmoid-cross-entropy-with-logits?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa)\n",
    "\n",
    "```python\n",
    "p = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "logit_q = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "q = tf.nn.sigmoid(logit_q)\n",
    "\n",
    "feed_dict = {\n",
    "  p: [[0, 0, 0, 1, 0],\n",
    "      [1, 0, 0, 0, 0]],\n",
    "  logit_q: [[0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "            [0.3, 0.3, 0.2, 0.1, 0.1]]\n",
    "}\n",
    "\n",
    "prob2 = p * -tf.log(q) + (1 - p) * -tf.log(1 - q)\n",
    "prob3 = p * -tf.log(tf.sigmoid(logit_q)) + (1-p) * -tf.log(1-tf.sigmoid(logit_q))\n",
    "prob4 = tf.nn.sigmoid_cross_entropy_with_logits(labels=p, logits=logit_q)\n",
    "\n",
    "# prob2 - prob4 are the same result\n",
    "print(prob2.eval(feed_dict))\n",
    "print(prob3.eval(feed_dict))\n",
    "print(prob4.eval(feed_dict))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.46555310322600874&quot;).pbtxt = '';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.46555310322600874&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "#### 1. dense (fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.dense(x, 10, tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.losses.mean_squared_error(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
