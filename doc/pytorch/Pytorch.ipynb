{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0.dev20181014'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1762  0.9099  0.2967\n",
      " 0.1739  0.5473  0.4969\n",
      " 0.7902  0.6606  0.9394\n",
      " 0.9505  0.5490  0.3846\n",
      " 0.0921  0.8280  0.6790\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(3, 4).fill_(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(a,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4682])\n",
      "0.46823084354400635\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [15, 22]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1,2], [3,4]])\n",
    "B = torch.tensor([[1,2], [3,4]])\n",
    "A.mm(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "# or set it later\n",
    "a.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grad & backward\n",
    "backward() have to call on shape (1,1) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1234., 1234.],\n",
       "        [1234., 1234.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(2,2).fill_(4)\n",
    "x.requires_grad_(True)\n",
    "y = 1234*x\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PowBackward0 at 0x111bb4278>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x**2\n",
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.no_grad()\n",
    "temporary set all \"requires_grad\" to false. But doesn't affect the existing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = (x ** 2)\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)\n",
    "    print(y.requires_grad)\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [example2] torch.no_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[10,20],\n",
    "              [30,40]])\n",
    "a.requires_grad_(True)\n",
    "\n",
    "# try to uncoment (and comment the one outside) to see the different\n",
    "d = a ** 3\n",
    "with torch.no_grad():\n",
    "    b = d**2\n",
    "    print('---')\n",
    "# b = a**2\n",
    "print(b.requires_grad)\n",
    "# -----------------------------------\n",
    "\n",
    "c = torch.sum(b + a)\n",
    "\n",
    "c.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### grad.zero_()\n",
    "Every time a variable is back propogated through, the gradient will be accumulated instead of being replaced. (This makes it easier for rnn, because each module will be back propogated through several times.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w1 -= learning_rate * w1.grad\n",
    "    w2 -= learning_rate * w2.grad\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type & Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.linspace(0,20,21, dtype=np.float32).reshape(-1,1)\n",
    "input = torch.from_numpy(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [15.],\n",
       "       [16.],\n",
       "       [17.],\n",
       "       [18.],\n",
       "       [19.],\n",
       "       [20.]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.numpy()\n",
    "# or using\n",
    "input.data.numpy() # if the value is require_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reshape & change type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.arange(0, 22, 1).view(-1, 1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3])\n",
    "zero = torch.Tensor([0])\n",
    "torch.max(zero, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detach\n",
    "- ```tensor.detach()``` copy tensor and break computational graph (does not require grad) \n",
    "- ```tensor.clone()``` copy tensor also computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API (F)\n",
    " functional API (F.dropout), you have to set the training flag yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device\n",
    "2 places to add device\n",
    "1. model\n",
    "```\n",
    "simpleNet = Net().to(device)\n",
    "```\n",
    "2. data \n",
    "```\n",
    "for i, (x, y) in enumerate(data_loader_train):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather\n",
    "change value in the batch along dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30, 20, 10],\n",
       "        [40, 60, 50]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[10,20,30],\n",
    "                  [40,50,60]])\n",
    "# 1. along dimension 0\n",
    "# 2. which index you want to gather (in this case 0-3)\n",
    "torch.gather(t, 1, torch.tensor([[2, 1, 0],\n",
    "                                 [0, 2, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scatter\n",
    "the opposite of gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55., 22.,  0., 44.],\n",
       "        [11.,  0., 33., 88.],\n",
       "        [ 0., 66., 77.,  0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[11,22,33,44], \n",
    "                  [55,66,77,88]], dtype=torch.float)\n",
    "sc = torch.tensor([[1,0,1,0], \n",
    "                   [0,2,2,1]])\n",
    "# sc and t have to have the same size\n",
    "# sc will tell that in the what index will get the value of the same position of sc in t\n",
    "torch.zeros(3, 4).scatter_(0, sc, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 0., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(4)\n",
    "target = torch.tensor([1,0,3,1])\n",
    "# sc and t have to have the same size\n",
    "# sc will tell that in the what index will get the value of the same position of sc in t\n",
    "torch.zeros(4).scatter_add_(0, target, ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter_add_\n",
    "same as scatter but add to the existing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56., 23.,  1., 45.],\n",
       "        [12.,  1., 34., 89.],\n",
       "        [ 1., 67., 78.,  1.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[11,22,33,44], \n",
    "                  [55,66,77,88]], dtype=torch.float)\n",
    "sc = torch.tensor([[1,0,1,0], \n",
    "                   [0,2,2,1]])\n",
    "torch.ones(3, 4).scatter_add_(0, sc, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index_select\n",
    "map value of index base on dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33, 33],\n",
       "        [11, 11],\n",
       "        [22, 22]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[11,11],\n",
    "                  [22,22],\n",
    "                  [33,33]])\n",
    "b = torch.tensor([2,0,1])\n",
    "a.index_select(0, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(torch.tensor([1,2]), 2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parmeter\n",
    "when add to Module, it gets added to the parameter list automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([5, 3])\n",
      "<class 'torch.Tensor'> torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]], requires_grad=True), Parameter containing:\n",
       " tensor([1., 1., 1.], requires_grad=True)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NN_Network(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        super(NN_Network, self).__init__()\n",
    "        self.linear = nn.Linear(in_dim,out_dim)\n",
    "        self.linear.weight = torch.nn.Parameter(torch.zeros(in_dim,out_dim))\n",
    "        self.linear.bias = torch.nn.Parameter(torch.ones(out_dim))\n",
    "\n",
    "    def forward(self, input_array):\n",
    "        y_pred = self.linear(input_array)\n",
    "        return y_pred\n",
    "net = NN_Network(5, 3)\n",
    "\n",
    "for param in net.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
