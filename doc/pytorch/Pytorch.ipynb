{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0.dev20181014'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5095, 0.7636, 0.4633],\n",
      "        [0.3256, 0.7317, 0.5197],\n",
      "        [0.8709, 0.1790, 0.6974],\n",
      "        [0.7209, 0.3823, 0.8801],\n",
      "        [0.7720, 0.7033, 0.9843]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(3, 4).fill_(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(a,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6446])\n",
      "0.644601047039032\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [15, 22]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1,2], [3,4]])\n",
    "B = torch.tensor([[1,2], [3,4]])\n",
    "A.mm(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "# or set it later\n",
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grad & backward\n",
    "backward() have to call on shape (1,1) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1234., 1234.],\n",
       "        [1234., 1234.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(2,2).fill_(4)\n",
    "x.requires_grad_(True)\n",
    "y = 1234*x\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PowBackward0 at 0x120285898>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x**2\n",
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.no_grad()\n",
    "temporary set all \"requires_grad\" to false. But doesn't affect the existing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = (x ** 2)\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)\n",
    "    print(y.requires_grad)\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [example2] torch.no_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[10,20],\n",
    "              [30,40]])\n",
    "a.requires_grad_(True)\n",
    "\n",
    "# try to uncoment (and comment the one outside) to see the different\n",
    "d = a ** 3\n",
    "with torch.no_grad():\n",
    "    b = d**2\n",
    "    print('---')\n",
    "# b = a**2\n",
    "print(b.requires_grad)\n",
    "# -----------------------------------\n",
    "\n",
    "c = torch.sum(b + a)\n",
    "\n",
    "c.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### grad.zero_()\n",
    "Every time a variable is back propogated through, the gradient will be accumulated instead of being replaced. (This makes it easier for rnn, because each module will be back propogated through several times.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with torch.no_grad():\n",
    "    w1 -= learning_rate * w1.grad\n",
    "    w2 -= learning_rate * w2.grad\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type & Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor.shape[0] and tensor.size(0) are the same thing\n",
    "shape is alias of size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input = np.linspace(0,20,21, dtype=np.float32).reshape(-1,1)\n",
    "input = torch.from_numpy(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [12.],\n",
       "       [13.],\n",
       "       [14.],\n",
       "       [15.],\n",
       "       [16.],\n",
       "       [17.],\n",
       "       [18.],\n",
       "       [19.],\n",
       "       [20.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.numpy()\n",
    "# or using\n",
    "input.data.numpy() # if the value is require_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reshape & change type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.arange(0, 22, 1).view(-1, 1).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3])\n",
    "zero = torch.Tensor([0])\n",
    "torch.max(zero, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detach\n",
    "- ```tensor.detach()``` copy tensor and break computational graph (does not require grad) \n",
    "- ```tensor.clone()``` copy tensor also computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API (F)\n",
    " functional API (F.dropout), you have to set the training flag yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device\n",
    "2 places to add device\n",
    "1. model\n",
    "```\n",
    "simpleNet = Net().to(device)\n",
    "```\n",
    "2. data \n",
    "```\n",
    "for i, (x, y) in enumerate(data_loader_train):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather\n",
    "change value in the batch along dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30, 20, 10],\n",
       "        [40, 60, 50]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[10,20,30],\n",
    "                  [40,50,60]])\n",
    "# 1. along dimension 0\n",
    "# 2. which index you want to gather (in this case 0-3)\n",
    "torch.gather(t, 1, torch.tensor([[2, 1, 0],\n",
    "                                 [0, 2, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scatter\n",
    "the opposite of gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55., 22.,  0., 44.],\n",
       "        [11.,  0., 33., 88.],\n",
       "        [ 0., 66., 77.,  0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[11,22,33,44], \n",
    "                  [55,66,77,88]], dtype=torch.float)\n",
    "sc = torch.tensor([[1,0,1,0], \n",
    "                   [0,2,2,1]])\n",
    "# sc and t have to have the same size\n",
    "# sc will tell that in the what index will get the value of the same position of sc in t\n",
    "torch.zeros(3, 4).scatter_(0, sc, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 0., 1.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(4)\n",
    "target = torch.tensor([1,0,3,1])\n",
    "# sc and t have to have the same size\n",
    "# sc will tell that in the what index will get the value of the same position of sc in t\n",
    "torch.zeros(4).scatter_add_(0, target, ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter_add_\n",
    "same as scatter but add to the existing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56., 24.,  3., 48.],\n",
       "        [ 5.,  6., 40., 96.],\n",
       "        [20., 76., 88., 12.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = torch.tensor([[1,2,3,4],\n",
    "                       [5,6,7,8],\n",
    "                       [9,10,11,12]], dtype=torch.float)\n",
    "index = torch.tensor([[2,0,1,0], \n",
    "                      [0,2,2,1]])\n",
    "other = torch.tensor([[11,22,33,44], \n",
    "                      [55,66,77,88]], dtype=torch.float)\n",
    "\n",
    "source.scatter_add_(0, index, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 0., 1., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = torch.tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "target = torch.tensor([0., 0., 2., 5.], dtype=torch.long)\n",
    "ones = torch.tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
    "counts.scatter_add_(0, target, ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-08"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index_select\n",
    "map value of index base on dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33, 33],\n",
       "        [11, 11],\n",
       "        [22, 22]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[11,11],\n",
    "                  [22,22],\n",
    "                  [33,33]])\n",
    "b = torch.tensor([2,0,1])\n",
    "a.index_select(0, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x.unsqueeze(0))\n",
    "print(x.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2], [3]])\n",
    "print(x.expand(3,4))\n",
    "print(x.expand(-1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parmeter\n",
    "when add to Module, it gets added to the parameter list automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NN_Network(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        super(NN_Network, self).__init__()\n",
    "        self.linear = nn.Linear(in_dim,out_dim)\n",
    "        self.linear.weight = torch.nn.Parameter(torch.zeros(in_dim,out_dim))\n",
    "        self.linear.bias = torch.nn.Parameter(torch.ones(out_dim))\n",
    "\n",
    "    def forward(self, input_array):\n",
    "        y_pred = self.linear(input_array)\n",
    "        return y_pred\n",
    "net = NN_Network(5, 3)\n",
    "\n",
    "for param in net.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "list(net.parameters())"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clamp\n",
    "clip data in bound\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5000, -0.3000,  0.4000,  0.5000])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([-1, -0.3, 0.4, 3])\n",
    "a.clamp(min=-0.5, max=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval / Train\n",
    "model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval model instead of training mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.qnetwork_local.eval()\n",
    "with torch.no_grad():\n",
    "    action_values = self.qnetwork_local(state)\n",
    "self.qnetwork_local.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [1., 2., 3.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "b = torch.Tensor([1,2,3]).unsqueeze(0)\n",
    "torch.cat([a,b], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 1.],\n",
       "        [4., 5., 6., 3.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "b = torch.Tensor([1,3]).unsqueeze(1)\n",
    "torch.cat([a,b], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append(a, b, dim=0):\n",
    "    b = b.unsqueeze(dim)\n",
    "    if a is None:\n",
    "        shape = list(b.shape)\n",
    "        shape[dim] = 0\n",
    "        a = b.new_empty(shape)\n",
    "    return torch.cat([a, b], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.]],\n",
       "\n",
       "        [[11., 12., 13.],\n",
       "         [14., 15., 16.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = None\n",
    "b = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "c = torch.Tensor([[11,12,13], [14,15,16]])\n",
    "a = append(a, b)\n",
    "append(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 8, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4d = torch.empty(5, 4, 3, 2)\n",
    "padding = (1, 1, 2, 3)  # pad last dim first/last of each dimension\n",
    "out = F.pad(t4d, padding, \"constant\", 0)  # effectively zero padding\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
