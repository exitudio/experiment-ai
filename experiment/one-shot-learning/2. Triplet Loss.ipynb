{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "- train only semi-hard\n",
    "- evaluate matrix (roc, kfold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- original paper :[here](https://arxiv.org/abs/1503.03832)\n",
    "- code [pytorch](https://github.com/tbmoon/facenet) convert of [(1) pytorch](https://github.com/liorshk/facenet_pytorch) and [(2) tf](https://github.com/davidsandberg/facenet)\n",
    "- dataset [here](http://vis-www.cs.umass.edu/lfw/), paper claims that they got 99.63% acc, cuts the error rate in comparison to the best published result [15] by 30%\n",
    "- inspired by n [19] in the context of nearest-neighbor classification\n",
    "\n",
    "\n",
    "\n",
    "**definition**\n",
    "- online/offline\n",
    "    - Generate triplets offline: find argmax/argmin (positive/negative) every n steps\n",
    "    - Generate triplets online: \"-------------------------------------\" within a mini-batch\n",
    "<br>\n",
    "\n",
    "**Implementation (based on paper)**\n",
    "- ensured that a minimal number of exemplars of any one identity is present in each mini-batch\n",
    "- all anchor positive pairs in a mini-batch while still selecting the **hard** negatives. (They claim, it's more stable than with both **hard** neg&pos)\n",
    "- hardest negatives can lead to local minima early on in training\n",
    "- select semi-hard, argmin(f(x)) that still more than positive\n",
    "\n",
    "- Stochastic Gradient Descent (SGD) with standard backprop and AdaGrad \n",
    "- start with a learning rate of 0.05, and lower over time\n",
    "- margin Î± is set to 0.2\n",
    "- use rectified linear units\n",
    "- Input sizes range from 96x96 pixels to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import random\n",
    "import numpy as np\n",
    "import functools \n",
    "import operator \n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from exitai.learner import Learner\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_dict(dict_obj):\n",
    "    key = random.choice(list(dict_obj))\n",
    "    return dict_obj[key]\n",
    "def random_except(arr, except_value):\n",
    "    random_value = random.choice(arr)\n",
    "    if random_value == except_value:\n",
    "        return random_except(arr, except_value)\n",
    "    return random_value\n",
    "class OneShotDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, max_num_each_class=10):\n",
    "        self.class_dict = {}\n",
    "        self.dataset = dataset\n",
    "        num_each_class = {}\n",
    "        length = 0\n",
    "        self.all_data = []\n",
    "        \n",
    "        for i, (data, label) in enumerate(self.dataset):\n",
    "            label_item = label.item()\n",
    "            if label_item not in list(self.class_dict.keys()):\n",
    "                self.class_dict[label_item] = []\n",
    "                num_each_class[label_item] = 0\n",
    "                \n",
    "            if max_num_each_class is -1 or num_each_class[label_item] < max_num_each_class:\n",
    "                self.class_dict[label_item].append((data, label))\n",
    "                num_each_class[label_item] += 1\n",
    "                length += 1\n",
    "        \n",
    "        for i in range(length):\n",
    "            self.all_data.append(self.gen_data())\n",
    "                \n",
    "    def gen_data(self):\n",
    "        # anchor\n",
    "        image_anchor, class_anchor_tensor = random.choice(random_dict(self.class_dict))\n",
    "        class_anchor = class_anchor_tensor.item()\n",
    "        \n",
    "        # positive\n",
    "        image_positive, class_positive_tensor = random.choice(self.class_dict[class_anchor])\n",
    "        if image_positive is image_anchor:\n",
    "            # rerandom if anchor and positive are the same\n",
    "            image_positive, class_positive_tensor = random.choice(self.class_dict[class_anchor])\n",
    "            \n",
    "        # negative\n",
    "        class_negative = random_except(list(self.class_dict), class_anchor)\n",
    "        image_negative, class_negative_tensor = random.choice(self.class_dict[class_negative])\n",
    "        return image_anchor, image_positive, image_negative\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.all_data[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_test = OneShotDataset(datasets.MNIST(root='../../data/', train=False, download=False, transform=transforms.ToTensor()))\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=8, shuffle=True, num_workers=8)\n",
    "example_batch = next(iter(data_loader_test))\n",
    "\n",
    "\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1], example_batch[2]),0)\n",
    "img = torchvision.utils.make_grid(concatenated)\n",
    "img = img.numpy()\n",
    "\n",
    "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "                                   transforms.RandomAffine(15, scale=(.9,1.2)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5,), (1,))\n",
    "                               ])\n",
    "transform_test = transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5,), (1,))\n",
    "                               ])\n",
    "dataset_train = OneShotDataset(datasets.MNIST(root='../../data/', train=True, download=True, transform=transform_train), max_num_each_class=50)\n",
    "dataset_test = OneShotDataset(datasets.MNIST(root='../../data/', train=False, download=False, transform=transform_test))\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=8)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetOneShot(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetOneShot, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 20, 5, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(20, 50, 5, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4*4*50, 500),\n",
    "            nn.Linear(500, 10)\n",
    "        )\n",
    "        self.is_classification = True\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(-1, 50*4*4)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input_anchor, input_positive, input_negative):\n",
    "        output1 = self.forward_once(input_anchor)\n",
    "        output2 = self.forward_once(input_positive)\n",
    "        output3 = self.forward_once(input_negative)\n",
    "        return output1, output2, output3\n",
    "    def name(self):\n",
    "        return \"LeNetOneShot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, margin=0.2):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist   = F.pairwise_distance(anchor, positive)\n",
    "        neg_dist   = F.pairwise_distance(anchor, negative)\n",
    "        \n",
    "        hinge_dist = torch.clamp(self.margin + pos_dist - neg_dist, min = 0.0)\n",
    "        loss       = torch.mean(hinge_dist)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2\n",
    "criterion = TripletLoss(margin).to(device)\n",
    "def model_loss_func(input_data, model, phase):\n",
    "    input_anchor, input_positive, input_negative = input_data\n",
    "    output_anchor, output_positive, output_negative = model(input_anchor, input_positive, input_negative)\n",
    "    \n",
    "    if phase=='train':\n",
    "        # train only semi-hard\n",
    "        distance_positive = F.pairwise_distance(output_anchor, output_positive)\n",
    "        distance_negative = F.pairwise_distance(output_anchor, output_negative)\n",
    "        mask_hard = distance_negative < distance_positive+margin\n",
    "        num_hard = mask_hard.sum()\n",
    "        print('num_hard:', num_hard.item())\n",
    "        if num_hard == 0:\n",
    "            return 0, 0, 'skip' # if return the third params means skip update weight\n",
    "        output_anchor = output_anchor[mask_hard]\n",
    "        output_positive = output_positive[mask_hard]\n",
    "        output_negative = output_negative[mask_hard]\n",
    "        #-----------------------------------\n",
    "    \n",
    "    \n",
    "    loss = criterion(output_anchor, output_positive, output_negative)\n",
    "    return (output_anchor, output_positive, output_negative), loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "***BE CAREFUL***\n",
    "The accuracy depends on threshold. Right now it's unreliable. We will find the best threshold later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- epoch:0 ------\n",
      "num_hard: 128\n",
      "num_hard: 95\n",
      "num_hard: 42\n",
      "num_hard: 41\n",
      "   [train] Average loss: 0.1580, acc: 39.40%\n",
      "   [test] Average loss: 0.0542, acc: 91.00%\n",
      "---- epoch:1 ------\n",
      "num_hard: 27\n",
      "num_hard: 19\n",
      "num_hard: 20\n",
      "num_hard: 27\n",
      "   [train] Average loss: 0.1451, acc: 11.80%\n",
      "   [test] Average loss: 0.0515, acc: 88.00%\n",
      "---- epoch:2 ------\n",
      "num_hard: 16\n",
      "num_hard: 17\n",
      "num_hard: 15\n",
      "num_hard: 10\n",
      "   [train] Average loss: 0.1193, acc: 8.00%\n",
      "   [test] Average loss: 0.0530, acc: 90.00%\n",
      "---- epoch:3 ------\n",
      "num_hard: 7\n",
      "num_hard: 14\n",
      "num_hard: 11\n",
      "num_hard: 8\n",
      "   [train] Average loss: 0.1029, acc: 6.80%\n",
      "   [test] Average loss: 0.0536, acc: 89.00%\n",
      "---- epoch:4 ------\n",
      "num_hard: 4\n",
      "num_hard: 2\n",
      "num_hard: 4\n",
      "num_hard: 6\n",
      "   [train] Average loss: 0.0872, acc: 2.80%\n",
      "   [test] Average loss: 0.0533, acc: 88.00%\n",
      "---- epoch:5 ------\n",
      "num_hard: 2\n",
      "num_hard: 1\n",
      "num_hard: 3\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0621, acc: 1.00%\n",
      "   [test] Average loss: 0.0515, acc: 88.00%\n",
      "---- epoch:6 ------\n",
      "num_hard: 0\n",
      "num_hard: 1\n",
      "num_hard: 0\n",
      "num_hard: 1\n",
      "   [train] Average loss: 0.0414, acc: 0.40%\n",
      "   [test] Average loss: 0.0414, acc: 93.00%\n",
      "---- epoch:7 ------\n",
      "num_hard: 3\n",
      "num_hard: 7\n",
      "num_hard: 8\n",
      "num_hard: 13\n",
      "   [train] Average loss: 0.1404, acc: 3.60%\n",
      "   [test] Average loss: 0.0571, acc: 88.00%\n",
      "---- epoch:8 ------\n",
      "num_hard: 8\n",
      "num_hard: 5\n",
      "num_hard: 9\n",
      "num_hard: 6\n",
      "   [train] Average loss: 0.1875, acc: 3.00%\n",
      "   [test] Average loss: 0.0527, acc: 91.00%\n",
      "---- epoch:9 ------\n",
      "num_hard: 1\n",
      "num_hard: 6\n",
      "num_hard: 6\n",
      "num_hard: 8\n",
      "   [train] Average loss: 0.1769, acc: 2.80%\n",
      "   [test] Average loss: 0.0728, acc: 87.00%\n",
      "---- epoch:10 ------\n",
      "num_hard: 7\n",
      "num_hard: 2\n",
      "num_hard: 5\n",
      "num_hard: 6\n",
      "   [train] Average loss: 0.1076, acc: 3.00%\n",
      "   [test] Average loss: 0.0608, acc: 88.00%\n",
      "---- epoch:11 ------\n",
      "num_hard: 3\n",
      "num_hard: 4\n",
      "num_hard: 1\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.1053, acc: 1.20%\n",
      "   [test] Average loss: 0.0559, acc: 89.00%\n",
      "---- epoch:12 ------\n",
      "num_hard: 0\n",
      "num_hard: 1\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0666, acc: 0.00%\n",
      "   [test] Average loss: 0.0551, acc: 90.00%\n",
      "---- epoch:13 ------\n",
      "num_hard: 1\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0079, acc: 0.20%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:14 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:15 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:16 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:17 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:18 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:19 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:20 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:21 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:22 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:23 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:24 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n",
      "---- epoch:25 ------\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "num_hard: 0\n",
      "   [train] Average loss: 0.0000, acc: 0.00%\n",
      "   [test] Average loss: 0.0553, acc: 90.00%\n"
     ]
    }
   ],
   "source": [
    "model = LeNetOneShot()\n",
    "\n",
    "def eval_func(input_data, output, loss):\n",
    "    anchor, positive, negative = output\n",
    "    positive_distance = F.pairwise_distance(anchor, positive)\n",
    "    negative_distance = F.pairwise_distance(anchor, negative)\n",
    "    return (positive_distance < negative_distance).sum().item()\n",
    "learner = Learner(data_loader_train, data_loader_test, model)\n",
    "learner.fit(model_loss_func, 0.002, num_epochs=100, eval_func=eval_func, early_stop='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding threshod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [test] Average loss: 0.0414, acc: 93.00%\n"
     ]
    }
   ],
   "source": [
    "def eval_func(input_data, output, loss):\n",
    "        anchor, positive, negative = output\n",
    "        positive_distance = F.pairwise_distance(anchor, positive)\n",
    "        negative_distance = F.pairwise_distance(anchor, negative)\n",
    "        return (positive_distance < negative_distance).sum().item()\n",
    "learner.predict(model_loss_func, eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_threshold(threshold):\n",
    "    def eval_func(input_data, output, loss):\n",
    "        anchor, positive, negative = output\n",
    "        \n",
    "        # positive\n",
    "        positive_distance = F.pairwise_distance(anchor, positive)\n",
    "        positive_correct = positive_distance<threshold\n",
    "        \n",
    "        # negative\n",
    "        negative_distance = F.pairwise_distance(anchor, negative)\n",
    "        negative_correct = negative_distance>threshold\n",
    "        return (positive_correct+negative_correct).sum().item()/2\n",
    "    learner.predict(model_loss_func, eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.8\n",
      "   [test] Average loss: 0.0414, acc: 80.50%\n",
      "threshold: 0.81\n",
      "   [test] Average loss: 0.0414, acc: 80.50%\n",
      "threshold: 0.8200000000000001\n",
      "   [test] Average loss: 0.0414, acc: 80.50%\n",
      "threshold: 0.8300000000000001\n",
      "   [test] Average loss: 0.0414, acc: 80.50%\n",
      "threshold: 0.8400000000000001\n",
      "   [test] Average loss: 0.0414, acc: 81.00%\n",
      "threshold: 0.8500000000000001\n",
      "   [test] Average loss: 0.0414, acc: 81.50%\n",
      "threshold: 0.8600000000000001\n",
      "   [test] Average loss: 0.0414, acc: 81.50%\n",
      "threshold: 0.8700000000000001\n",
      "   [test] Average loss: 0.0414, acc: 82.50%\n",
      "threshold: 0.8800000000000001\n",
      "   [test] Average loss: 0.0414, acc: 82.50%\n",
      "threshold: 0.8900000000000001\n",
      "   [test] Average loss: 0.0414, acc: 83.50%\n",
      "threshold: 0.9000000000000001\n",
      "   [test] Average loss: 0.0414, acc: 83.50%\n",
      "threshold: 0.9100000000000001\n",
      "   [test] Average loss: 0.0414, acc: 83.50%\n",
      "threshold: 0.9200000000000002\n",
      "   [test] Average loss: 0.0414, acc: 83.00%\n",
      "threshold: 0.9300000000000002\n",
      "   [test] Average loss: 0.0414, acc: 82.50%\n",
      "threshold: 0.9400000000000002\n",
      "   [test] Average loss: 0.0414, acc: 83.50%\n",
      "threshold: 0.9500000000000002\n",
      "   [test] Average loss: 0.0414, acc: 83.50%\n",
      "threshold: 0.9600000000000002\n",
      "   [test] Average loss: 0.0414, acc: 85.50%\n",
      "threshold: 0.9700000000000002\n",
      "   [test] Average loss: 0.0414, acc: 85.50%\n",
      "threshold: 0.9800000000000002\n",
      "   [test] Average loss: 0.0414, acc: 86.00%\n",
      "threshold: 0.9900000000000002\n",
      "   [test] Average loss: 0.0414, acc: 86.50%\n",
      "threshold: 1.0000000000000002\n",
      "   [test] Average loss: 0.0414, acc: 85.50%\n",
      "threshold: 1.0100000000000002\n",
      "   [test] Average loss: 0.0414, acc: 86.50%\n",
      "threshold: 1.0200000000000002\n",
      "   [test] Average loss: 0.0414, acc: 87.00%\n",
      "threshold: 1.0300000000000002\n",
      "   [test] Average loss: 0.0414, acc: 87.00%\n",
      "threshold: 1.0400000000000003\n",
      "   [test] Average loss: 0.0414, acc: 87.00%\n",
      "threshold: 1.0500000000000003\n",
      "   [test] Average loss: 0.0414, acc: 86.50%\n",
      "threshold: 1.0600000000000003\n",
      "   [test] Average loss: 0.0414, acc: 85.00%\n",
      "threshold: 1.0700000000000003\n",
      "   [test] Average loss: 0.0414, acc: 85.50%\n",
      "threshold: 1.0800000000000003\n",
      "   [test] Average loss: 0.0414, acc: 85.00%\n",
      "threshold: 1.0900000000000003\n",
      "   [test] Average loss: 0.0414, acc: 84.50%\n",
      "threshold: 1.1000000000000003\n",
      "   [test] Average loss: 0.0414, acc: 84.00%\n",
      "threshold: 1.1100000000000003\n",
      "   [test] Average loss: 0.0414, acc: 84.50%\n",
      "threshold: 1.1200000000000003\n",
      "   [test] Average loss: 0.0414, acc: 84.00%\n",
      "threshold: 1.1300000000000003\n",
      "   [test] Average loss: 0.0414, acc: 84.00%\n",
      "threshold: 1.1400000000000003\n",
      "   [test] Average loss: 0.0414, acc: 83.50%\n",
      "threshold: 1.1500000000000004\n",
      "   [test] Average loss: 0.0414, acc: 83.00%\n",
      "threshold: 1.1600000000000004\n",
      "   [test] Average loss: 0.0414, acc: 82.50%\n",
      "threshold: 1.1700000000000004\n",
      "   [test] Average loss: 0.0414, acc: 81.00%\n",
      "threshold: 1.1800000000000004\n",
      "   [test] Average loss: 0.0414, acc: 80.50%\n",
      "threshold: 1.1900000000000004\n",
      "   [test] Average loss: 0.0414, acc: 79.50%\n",
      "threshold: 1.2000000000000004\n",
      "   [test] Average loss: 0.0414, acc: 79.50%\n",
      "threshold: 1.2100000000000004\n",
      "   [test] Average loss: 0.0414, acc: 79.50%\n",
      "threshold: 1.2200000000000004\n",
      "   [test] Average loss: 0.0414, acc: 77.50%\n",
      "threshold: 1.2300000000000004\n",
      "   [test] Average loss: 0.0414, acc: 77.50%\n",
      "threshold: 1.2400000000000004\n",
      "   [test] Average loss: 0.0414, acc: 77.50%\n",
      "threshold: 1.2500000000000004\n",
      "   [test] Average loss: 0.0414, acc: 78.00%\n",
      "threshold: 1.2600000000000005\n",
      "   [test] Average loss: 0.0414, acc: 78.00%\n",
      "threshold: 1.2700000000000005\n",
      "   [test] Average loss: 0.0414, acc: 76.50%\n",
      "threshold: 1.2800000000000005\n",
      "   [test] Average loss: 0.0414, acc: 76.50%\n",
      "threshold: 1.2900000000000005\n",
      "   [test] Average loss: 0.0414, acc: 77.00%\n",
      "threshold: 1.3000000000000005\n",
      "   [test] Average loss: 0.0414, acc: 77.00%\n",
      "threshold: 1.3100000000000005\n",
      "   [test] Average loss: 0.0414, acc: 74.50%\n",
      "threshold: 1.3200000000000005\n",
      "   [test] Average loss: 0.0414, acc: 73.50%\n",
      "threshold: 1.3300000000000005\n",
      "   [test] Average loss: 0.0414, acc: 73.00%\n",
      "threshold: 1.3400000000000005\n",
      "   [test] Average loss: 0.0414, acc: 73.00%\n",
      "threshold: 1.3500000000000005\n",
      "   [test] Average loss: 0.0414, acc: 72.00%\n",
      "threshold: 1.3600000000000005\n",
      "   [test] Average loss: 0.0414, acc: 72.00%\n",
      "threshold: 1.3700000000000006\n",
      "   [test] Average loss: 0.0414, acc: 71.00%\n",
      "threshold: 1.3800000000000006\n",
      "   [test] Average loss: 0.0414, acc: 69.50%\n",
      "threshold: 1.3900000000000006\n",
      "   [test] Average loss: 0.0414, acc: 69.50%\n",
      "threshold: 1.4000000000000006\n",
      "   [test] Average loss: 0.0414, acc: 69.50%\n",
      "threshold: 1.4100000000000006\n",
      "   [test] Average loss: 0.0414, acc: 68.50%\n",
      "threshold: 1.4200000000000006\n",
      "   [test] Average loss: 0.0414, acc: 68.50%\n",
      "threshold: 1.4300000000000006\n",
      "   [test] Average loss: 0.0414, acc: 67.50%\n",
      "threshold: 1.4400000000000006\n",
      "   [test] Average loss: 0.0414, acc: 67.50%\n",
      "threshold: 1.4500000000000006\n",
      "   [test] Average loss: 0.0414, acc: 67.00%\n",
      "threshold: 1.4600000000000006\n",
      "   [test] Average loss: 0.0414, acc: 66.50%\n",
      "threshold: 1.4700000000000006\n",
      "   [test] Average loss: 0.0414, acc: 65.50%\n",
      "threshold: 1.4800000000000006\n",
      "   [test] Average loss: 0.0414, acc: 65.50%\n",
      "threshold: 1.4900000000000007\n",
      "   [test] Average loss: 0.0414, acc: 64.50%\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0.8, 1.5, .01):\n",
    "    print('threshold:', threshold)\n",
    "    predict_with_threshold(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [test] Average loss: 0.0414, acc: 87.00%\n"
     ]
    }
   ],
   "source": [
    "predict_with_threshold(1.0300000000000002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
