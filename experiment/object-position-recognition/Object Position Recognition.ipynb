{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epinyoanun/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import getimages\n",
    "circle_nparray = getimages.load_images_in_folder_to_nparray(\"./data/circles/\")\n",
    "square_nparray = getimages.load_images_in_folder_to_nparray(\"./data/squares/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_rows = img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X = np.concatenate((circle_nparray, square_nparray), axis=0)\n",
    "X = X.astype('float32')/255\n",
    "y_c = np.array([0 for i in range(len(circle_nparray))])\n",
    "y_s = np.array([1 for i in range(len(square_nparray))])\n",
    "y = to_categorical(np.append(y_c, y_s)) # convert to onehot\n",
    "\n",
    "X_train = X\n",
    "X_test = X\n",
    "X_val = X\n",
    "\n",
    "y_train = y\n",
    "y_test = y\n",
    "y_val = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 2\n",
    "epochs = 50\n",
    "\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.7542 - acc: 0.5310 - val_loss: 0.6932 - val_acc: 0.5035\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 2s 859us/step - loss: 0.7021 - acc: 0.4875 - val_loss: 0.6933 - val_acc: 0.5025\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 2s 862us/step - loss: 0.6985 - acc: 0.4975 - val_loss: 0.6927 - val_acc: 0.5095\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 2s 863us/step - loss: 0.6980 - acc: 0.4865 - val_loss: 0.6924 - val_acc: 0.5200\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 2s 866us/step - loss: 0.6941 - acc: 0.5120 - val_loss: 0.6925 - val_acc: 0.5195\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 2s 865us/step - loss: 0.6937 - acc: 0.5020 - val_loss: 0.6923 - val_acc: 0.5220\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 2s 859us/step - loss: 0.6929 - acc: 0.5105 - val_loss: 0.6920 - val_acc: 0.5215\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 2s 865us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.5465\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 2s 897us/step - loss: 0.6919 - acc: 0.5120 - val_loss: 0.6921 - val_acc: 0.5510\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 2s 874us/step - loss: 0.6922 - acc: 0.5135 - val_loss: 0.6922 - val_acc: 0.5185\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 2s 860us/step - loss: 0.6943 - acc: 0.5165 - val_loss: 0.6924 - val_acc: 0.5170\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 2s 871us/step - loss: 0.6936 - acc: 0.5070 - val_loss: 0.6923 - val_acc: 0.5215\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 2s 850us/step - loss: 0.6922 - acc: 0.5220 - val_loss: 0.6914 - val_acc: 0.5575\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 2s 857us/step - loss: 0.6924 - acc: 0.5215 - val_loss: 0.6910 - val_acc: 0.5565\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 2s 849us/step - loss: 0.6916 - acc: 0.5230 - val_loss: 0.6892 - val_acc: 0.5900\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 2s 839us/step - loss: 0.6904 - acc: 0.5260 - val_loss: 0.6868 - val_acc: 0.6255\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 2s 856us/step - loss: 0.6908 - acc: 0.5285 - val_loss: 0.6859 - val_acc: 0.6255\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 2s 846us/step - loss: 0.6861 - acc: 0.5410 - val_loss: 0.6812 - val_acc: 0.6480\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 2s 852us/step - loss: 0.6836 - acc: 0.5510 - val_loss: 0.6791 - val_acc: 0.6385\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 2s 916us/step - loss: 0.6769 - acc: 0.5730 - val_loss: 0.6623 - val_acc: 0.5750\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 2s 917us/step - loss: 0.6818 - acc: 0.5470 - val_loss: 0.6643 - val_acc: 0.6380\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 2s 878us/step - loss: 0.6630 - acc: 0.6215 - val_loss: 0.6489 - val_acc: 0.7385\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 2s 845us/step - loss: 0.6397 - acc: 0.6445 - val_loss: 0.5873 - val_acc: 0.7870\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 2s 851us/step - loss: 0.6189 - acc: 0.6525 - val_loss: 0.5888 - val_acc: 0.7310\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 2s 850us/step - loss: 0.5861 - acc: 0.6695 - val_loss: 0.5306 - val_acc: 0.8155\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 2s 896us/step - loss: 0.5135 - acc: 0.7445 - val_loss: 0.4196 - val_acc: 0.8640\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 2s 872us/step - loss: 0.4818 - acc: 0.7470 - val_loss: 0.4024 - val_acc: 0.8665\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 2s 866us/step - loss: 0.4784 - acc: 0.7650 - val_loss: 0.4133 - val_acc: 0.8440\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 2s 858us/step - loss: 0.4420 - acc: 0.7855 - val_loss: 0.3924 - val_acc: 0.8920\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 2s 884us/step - loss: 0.3611 - acc: 0.8390 - val_loss: 0.2657 - val_acc: 0.9150\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 2s 873us/step - loss: 0.3133 - acc: 0.8485 - val_loss: 0.2217 - val_acc: 0.9270\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 2s 859us/step - loss: 0.2771 - acc: 0.8715 - val_loss: 0.2392 - val_acc: 0.9075\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 2s 881us/step - loss: 0.2797 - acc: 0.8700 - val_loss: 0.2148 - val_acc: 0.9270\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 2s 856us/step - loss: 0.2400 - acc: 0.8890 - val_loss: 0.1725 - val_acc: 0.9385\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 2s 857us/step - loss: 0.2023 - acc: 0.9060 - val_loss: 0.1397 - val_acc: 0.9400\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 2s 865us/step - loss: 0.2055 - acc: 0.9090 - val_loss: 0.1461 - val_acc: 0.9345\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 2s 896us/step - loss: 0.1839 - acc: 0.9135 - val_loss: 0.1545 - val_acc: 0.9265\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 2s 882us/step - loss: 0.1798 - acc: 0.9180 - val_loss: 0.1254 - val_acc: 0.9470\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 2s 876us/step - loss: 0.1425 - acc: 0.9400 - val_loss: 0.1202 - val_acc: 0.9350\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 2s 875us/step - loss: 0.1358 - acc: 0.9385 - val_loss: 0.1077 - val_acc: 0.9455\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 2s 850us/step - loss: 0.1305 - acc: 0.9465 - val_loss: 0.1069 - val_acc: 0.9430\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 2s 877us/step - loss: 0.1206 - acc: 0.9475 - val_loss: 0.0837 - val_acc: 0.9620\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 2s 867us/step - loss: 0.1510 - acc: 0.9335 - val_loss: 0.0941 - val_acc: 0.9555\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 2s 859us/step - loss: 0.1287 - acc: 0.9460 - val_loss: 0.0877 - val_acc: 0.9645\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 2s 885us/step - loss: 0.1279 - acc: 0.9475 - val_loss: 0.0790 - val_acc: 0.9720\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 2s 889us/step - loss: 0.1004 - acc: 0.9580 - val_loss: 0.0703 - val_acc: 0.9780\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 2s 871us/step - loss: 0.0966 - acc: 0.9635 - val_loss: 0.0569 - val_acc: 0.9850\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 2s 879us/step - loss: 0.0934 - acc: 0.9640 - val_loss: 0.0573 - val_acc: 0.9760\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 2s 883us/step - loss: 0.0892 - acc: 0.9595 - val_loss: 0.0505 - val_acc: 0.9805\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 2s 871us/step - loss: 0.0804 - acc: 0.9665 - val_loss: 0.0530 - val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05296890750527382, 0.98]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
