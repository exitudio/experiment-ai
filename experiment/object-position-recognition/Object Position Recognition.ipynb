{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import getimages\n",
    "circle_nparray = getimages.load_images_in_folder_to_nparray(\"./data/circles/\")\n",
    "square_nparray = getimages.load_images_in_folder_to_nparray(\"./data/squares/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "circle_locations = genfromtxt('./data/circles/locations.csv', delimiter=',')\n",
    "square_locations = genfromtxt('./data/squares/locations.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_rows = img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X = square_nparray # np.concatenate((circle_nparray, square_nparray), axis=0)\n",
    "X = X.astype('float32')/255\n",
    "# y_c = np.array([0 for i in range(len(circle_nparray))])\n",
    "# y_s = np.array([1 for i in range(len(square_nparray))])\n",
    "# y = to_categorical(np.append(y_c, y_s)) # convert to onehot\n",
    "y = square_locations # np.concatenate((circle_locations, square_locations))\n",
    "\n",
    "X_train = X\n",
    "X_test = X\n",
    "X_val = X\n",
    "\n",
    "y_train = y\n",
    "y_test = y\n",
    "y_val = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "model.add(Dense(4))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 512 samples\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 128.0199 - acc: 0.3164 - val_loss: 91.4318 - val_acc: 0.4727\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 883us/step - loss: 50.9800 - acc: 0.4453 - val_loss: 15.2903 - val_acc: 0.4727\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 854us/step - loss: 32.6552 - acc: 0.4551 - val_loss: 14.5173 - val_acc: 0.4727\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 876us/step - loss: 12.4009 - acc: 0.5078 - val_loss: 39.0781 - val_acc: 0.5273\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 874us/step - loss: 19.5461 - acc: 0.5156 - val_loss: 41.7428 - val_acc: 0.5273\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 869us/step - loss: 19.7499 - acc: 0.5215 - val_loss: 28.8083 - val_acc: 0.5273\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 891us/step - loss: 14.4679 - acc: 0.5137 - val_loss: 15.6430 - val_acc: 0.5273\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 941us/step - loss: 12.9480 - acc: 0.5410 - val_loss: 14.1600 - val_acc: 0.5273\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 893us/step - loss: 10.6664 - acc: 0.5195 - val_loss: 21.6593 - val_acc: 0.4727\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 928us/step - loss: 8.8100 - acc: 0.4727 - val_loss: 27.4123 - val_acc: 0.4727\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 951us/step - loss: 11.1519 - acc: 0.4434 - val_loss: 24.7201 - val_acc: 0.4727\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 942us/step - loss: 10.4162 - acc: 0.4551 - val_loss: 18.5186 - val_acc: 0.4727\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 911us/step - loss: 9.7876 - acc: 0.4688 - val_loss: 16.0613 - val_acc: 0.4727\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 926us/step - loss: 9.9521 - acc: 0.4883 - val_loss: 20.2074 - val_acc: 0.4727\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 931us/step - loss: 8.7222 - acc: 0.4668 - val_loss: 24.3188 - val_acc: 0.4727\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 928us/step - loss: 8.7722 - acc: 0.4922 - val_loss: 22.9641 - val_acc: 0.4727\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 8.2371 - acc: 0.4902 - val_loss: 19.2332 - val_acc: 0.5273\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 916us/step - loss: 8.3161 - acc: 0.4980 - val_loss: 18.0375 - val_acc: 0.5273\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 928us/step - loss: 8.4294 - acc: 0.5215 - val_loss: 21.8196 - val_acc: 0.5273\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 923us/step - loss: 8.6372 - acc: 0.4805 - val_loss: 24.5127 - val_acc: 0.5273\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 878us/step - loss: 8.6512 - acc: 0.5137 - val_loss: 22.3053 - val_acc: 0.5273\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 886us/step - loss: 8.5201 - acc: 0.5039 - val_loss: 18.4269 - val_acc: 0.5273\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 929us/step - loss: 8.5987 - acc: 0.4590 - val_loss: 20.3976 - val_acc: 0.5273\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 883us/step - loss: 8.0080 - acc: 0.5254 - val_loss: 24.9116 - val_acc: 0.4727\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 915us/step - loss: 8.4672 - acc: 0.4980 - val_loss: 24.9683 - val_acc: 0.4727\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 7.7630 - acc: 0.4746 - val_loss: 21.8169 - val_acc: 0.4727\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 7.9753 - acc: 0.5156 - val_loss: 20.8521 - val_acc: 0.4727\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 869us/step - loss: 7.8812 - acc: 0.4570 - val_loss: 22.2272 - val_acc: 0.4727\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 906us/step - loss: 7.6219 - acc: 0.4922 - val_loss: 24.1195 - val_acc: 0.4727\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 904us/step - loss: 7.4514 - acc: 0.5059 - val_loss: 23.8579 - val_acc: 0.4727\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 943us/step - loss: 7.6180 - acc: 0.4805 - val_loss: 22.7309 - val_acc: 0.4727\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 945us/step - loss: 7.5516 - acc: 0.5059 - val_loss: 22.4021 - val_acc: 0.4727\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 926us/step - loss: 7.5207 - acc: 0.4902 - val_loss: 24.4142 - val_acc: 0.4727\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 1s 981us/step - loss: 7.1774 - acc: 0.5059 - val_loss: 24.5217 - val_acc: 0.4707\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 7.0590 - acc: 0.5176 - val_loss: 23.5659 - val_acc: 0.4648\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 912us/step - loss: 7.3301 - acc: 0.4805 - val_loss: 23.6355 - val_acc: 0.4688\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 910us/step - loss: 7.3470 - acc: 0.4707 - val_loss: 24.4990 - val_acc: 0.4688\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 878us/step - loss: 7.4237 - acc: 0.4648 - val_loss: 25.0180 - val_acc: 0.4727\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 868us/step - loss: 7.4263 - acc: 0.4766 - val_loss: 25.3113 - val_acc: 0.4727\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 882us/step - loss: 6.9372 - acc: 0.5059 - val_loss: 26.3142 - val_acc: 0.4727\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 849us/step - loss: 6.9536 - acc: 0.4727 - val_loss: 25.1956 - val_acc: 0.4727\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 873us/step - loss: 7.2635 - acc: 0.5098 - val_loss: 24.7048 - val_acc: 0.4727\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 866us/step - loss: 7.0150 - acc: 0.4941 - val_loss: 26.6229 - val_acc: 0.4727\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 873us/step - loss: 7.2609 - acc: 0.4824 - val_loss: 26.9776 - val_acc: 0.4727\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 865us/step - loss: 6.9491 - acc: 0.5059 - val_loss: 23.9678 - val_acc: 0.4727\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 876us/step - loss: 7.5033 - acc: 0.4824 - val_loss: 27.8666 - val_acc: 0.4727\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 882us/step - loss: 7.2312 - acc: 0.4746 - val_loss: 28.4263 - val_acc: 0.4766\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 880us/step - loss: 7.1141 - acc: 0.5215 - val_loss: 25.7973 - val_acc: 0.4648\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 890us/step - loss: 7.2798 - acc: 0.4883 - val_loss: 27.0807 - val_acc: 0.4629\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 898us/step - loss: 7.1491 - acc: 0.4688 - val_loss: 28.0568 - val_acc: 0.4668\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 927us/step - loss: 6.8639 - acc: 0.5332 - val_loss: 26.1821 - val_acc: 0.4766\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 920us/step - loss: 7.0260 - acc: 0.5059 - val_loss: 29.7042 - val_acc: 0.4727\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 890us/step - loss: 7.2077 - acc: 0.5352 - val_loss: 28.7060 - val_acc: 0.4727\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 936us/step - loss: 6.8704 - acc: 0.5156 - val_loss: 26.6568 - val_acc: 0.4727\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 953us/step - loss: 6.9121 - acc: 0.5098 - val_loss: 31.1058 - val_acc: 0.4727\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 952us/step - loss: 7.1159 - acc: 0.4980 - val_loss: 29.9633 - val_acc: 0.4727\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 894us/step - loss: 6.8356 - acc: 0.5254 - val_loss: 27.7574 - val_acc: 0.4727\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 935us/step - loss: 6.6328 - acc: 0.4961 - val_loss: 29.0223 - val_acc: 0.4785\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 918us/step - loss: 7.4221 - acc: 0.4688 - val_loss: 31.4151 - val_acc: 0.4688\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 960us/step - loss: 6.5590 - acc: 0.5078 - val_loss: 26.8184 - val_acc: 0.4746\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 6.7513 - acc: 0.5273 - val_loss: 32.4678 - val_acc: 0.4707\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 893us/step - loss: 6.8300 - acc: 0.5156 - val_loss: 31.0451 - val_acc: 0.4766\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 952us/step - loss: 6.8943 - acc: 0.4707 - val_loss: 27.4041 - val_acc: 0.4766\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 903us/step - loss: 6.4628 - acc: 0.4727 - val_loss: 31.7820 - val_acc: 0.4785\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 904us/step - loss: 6.5223 - acc: 0.5234 - val_loss: 31.6195 - val_acc: 0.4746\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 882us/step - loss: 6.8033 - acc: 0.4668 - val_loss: 29.9757 - val_acc: 0.4727\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 888us/step - loss: 6.7852 - acc: 0.4863 - val_loss: 30.1815 - val_acc: 0.4727\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 868us/step - loss: 6.6013 - acc: 0.5059 - val_loss: 29.4198 - val_acc: 0.4746\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 883us/step - loss: 6.6287 - acc: 0.5039 - val_loss: 30.9719 - val_acc: 0.4727\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 891us/step - loss: 6.3650 - acc: 0.5234 - val_loss: 31.4002 - val_acc: 0.4746\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 870us/step - loss: 6.6584 - acc: 0.5352 - val_loss: 30.8374 - val_acc: 0.4785\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 877us/step - loss: 6.6237 - acc: 0.4922 - val_loss: 30.2367 - val_acc: 0.4785\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 897us/step - loss: 6.6809 - acc: 0.5020 - val_loss: 31.5101 - val_acc: 0.4746\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 885us/step - loss: 6.3147 - acc: 0.5195 - val_loss: 30.4050 - val_acc: 0.4746\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 875us/step - loss: 6.6659 - acc: 0.5059 - val_loss: 31.4398 - val_acc: 0.4727\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 870us/step - loss: 6.2961 - acc: 0.4707 - val_loss: 31.3241 - val_acc: 0.4727\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 890us/step - loss: 6.5221 - acc: 0.4766 - val_loss: 29.1034 - val_acc: 0.4727\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 874us/step - loss: 6.4663 - acc: 0.4961 - val_loss: 33.0131 - val_acc: 0.4746\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 853us/step - loss: 6.8129 - acc: 0.5176 - val_loss: 32.3761 - val_acc: 0.4785\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 869us/step - loss: 6.7233 - acc: 0.4980 - val_loss: 30.0522 - val_acc: 0.4785\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 916us/step - loss: 6.4450 - acc: 0.5098 - val_loss: 33.9491 - val_acc: 0.4805\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 938us/step - loss: 6.4785 - acc: 0.4629 - val_loss: 33.7259 - val_acc: 0.4766\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 917us/step - loss: 6.3898 - acc: 0.4766 - val_loss: 30.6572 - val_acc: 0.4785\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 917us/step - loss: 6.3321 - acc: 0.4863 - val_loss: 35.6049 - val_acc: 0.4766\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 918us/step - loss: 6.4605 - acc: 0.5078 - val_loss: 31.9739 - val_acc: 0.4766\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 6.6285 - acc: 0.4609 - val_loss: 31.8445 - val_acc: 0.4766\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 974us/step - loss: 6.8114 - acc: 0.4805 - val_loss: 37.4030 - val_acc: 0.4805\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 1s 996us/step - loss: 6.6248 - acc: 0.4590 - val_loss: 27.1169 - val_acc: 0.4805\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 6.6370 - acc: 0.4941 - val_loss: 35.4178 - val_acc: 0.4785\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 884us/step - loss: 6.5792 - acc: 0.5039 - val_loss: 33.5538 - val_acc: 0.4805\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 941us/step - loss: 6.7927 - acc: 0.5098 - val_loss: 30.3351 - val_acc: 0.4805\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 1s 980us/step - loss: 6.9375 - acc: 0.5293 - val_loss: 38.0230 - val_acc: 0.4805\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 919us/step - loss: 6.6803 - acc: 0.4883 - val_loss: 28.3545 - val_acc: 0.4746\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 885us/step - loss: 6.6680 - acc: 0.5195 - val_loss: 36.6660 - val_acc: 0.4941\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 874us/step - loss: 6.8020 - acc: 0.4961 - val_loss: 34.3212 - val_acc: 0.4805\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 875us/step - loss: 6.5453 - acc: 0.5254 - val_loss: 27.9147 - val_acc: 0.4824\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 907us/step - loss: 6.2829 - acc: 0.5059 - val_loss: 36.9605 - val_acc: 0.4805\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 908us/step - loss: 6.8094 - acc: 0.5137 - val_loss: 31.4431 - val_acc: 0.4785\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 881us/step - loss: 6.5477 - acc: 0.5195 - val_loss: 32.0517 - val_acc: 0.4766\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 869us/step - loss: 6.3923 - acc: 0.4785 - val_loss: 35.8880 - val_acc: 0.4766\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[404.5686340332031, 0.5]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1488c3fd0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.127011, 7.120087, 4.087321, 4.039061]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17., 12.,  8.,  8.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_locations[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
