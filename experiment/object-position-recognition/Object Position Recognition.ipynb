{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import getimages\n",
    "circle_nparray = getimages.load_images_in_folder_to_nparray(\"./data/circles/\")\n",
    "square_nparray = getimages.load_images_in_folder_to_nparray(\"./data/squares/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "circle_locations = genfromtxt('./data/circles/locations.csv', delimiter=',')\n",
    "square_locations = genfromtxt('./data/squares/locations.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_rows = img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X = square_nparray # np.concatenate((circle_nparray, square_nparray), axis=0)\n",
    "X = X.astype('float32')/255\n",
    "# y_c = np.array([0 for i in range(len(circle_nparray))])\n",
    "# y_s = np.array([1 for i in range(len(square_nparray))])\n",
    "# y = to_categorical(np.append(y_c, y_s)) # convert to onehot\n",
    "y = square_locations # np.concatenate((circle_locations, square_locations))\n",
    "\n",
    "X_train = X\n",
    "X_test = X\n",
    "X_val = X\n",
    "\n",
    "y_train = y\n",
    "y_test = y\n",
    "y_val = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "model.add(Dense(4))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 512 samples\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 179.0389 - acc: 0.4434 - val_loss: 132.2708 - val_acc: 0.1602\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.16016, saving model to data/weights/model-0.16.h5\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 879us/step - loss: 90.7389 - acc: 0.3203 - val_loss: 48.6984 - val_acc: 0.3789\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.16016 to 0.37891, saving model to data/weights/model-0.38.h5\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 918us/step - loss: 63.5385 - acc: 0.3457 - val_loss: 31.4111 - val_acc: 0.5977\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37891 to 0.59766, saving model to data/weights/model-0.60.h5\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 885us/step - loss: 47.6811 - acc: 0.3027 - val_loss: 49.8493 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.59766\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 928us/step - loss: 37.4904 - acc: 0.2070 - val_loss: 66.1465 - val_acc: 0.0469\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.59766\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 884us/step - loss: 42.7660 - acc: 0.2207 - val_loss: 60.0833 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.59766\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 879us/step - loss: 33.7033 - acc: 0.2031 - val_loss: 39.0404 - val_acc: 0.0469\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.59766\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 971us/step - loss: 26.1728 - acc: 0.2207 - val_loss: 22.0444 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.59766\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 949us/step - loss: 26.9418 - acc: 0.2500 - val_loss: 22.3370 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.59766\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 1s 984us/step - loss: 21.2419 - acc: 0.2344 - val_loss: 31.8122 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.59766\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 975us/step - loss: 20.3722 - acc: 0.2305 - val_loss: 39.2217 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.59766\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 963us/step - loss: 21.5326 - acc: 0.2812 - val_loss: 38.3977 - val_acc: 0.5977\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.59766\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 960us/step - loss: 21.2544 - acc: 0.3340 - val_loss: 31.1431 - val_acc: 0.5977\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.59766\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 974us/step - loss: 20.2282 - acc: 0.2832 - val_loss: 25.0244 - val_acc: 0.5977\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.59766\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 930us/step - loss: 19.5115 - acc: 0.3105 - val_loss: 23.9560 - val_acc: 0.5977\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.59766\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 962us/step - loss: 19.2459 - acc: 0.2773 - val_loss: 28.1636 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.59766\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 18.0922 - acc: 0.2754 - val_loss: 32.3138 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.59766\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 966us/step - loss: 18.4381 - acc: 0.2734 - val_loss: 31.5212 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.59766\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 968us/step - loss: 17.9154 - acc: 0.2227 - val_loss: 26.3447 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.59766\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 933us/step - loss: 17.4510 - acc: 0.2812 - val_loss: 22.2992 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.59766\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 891us/step - loss: 18.1858 - acc: 0.2266 - val_loss: 23.3291 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.59766\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 901us/step - loss: 18.6548 - acc: 0.2383 - val_loss: 28.2510 - val_acc: 0.1582\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.59766\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 1s 984us/step - loss: 17.3248 - acc: 0.2480 - val_loss: 31.3134 - val_acc: 0.2871\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.59766\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 951us/step - loss: 17.3363 - acc: 0.2520 - val_loss: 29.0232 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.59766\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 951us/step - loss: 17.5902 - acc: 0.2754 - val_loss: 24.9862 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.59766\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 951us/step - loss: 16.9132 - acc: 0.2559 - val_loss: 23.1676 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.59766\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 917us/step - loss: 16.7661 - acc: 0.2812 - val_loss: 26.1501 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.59766\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 17.0974 - acc: 0.2500 - val_loss: 28.8307 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.59766\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 1s 999us/step - loss: 16.5870 - acc: 0.2891 - val_loss: 29.0438 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.59766\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 1s 986us/step - loss: 16.8817 - acc: 0.2793 - val_loss: 27.4075 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.59766\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 16.5299 - acc: 0.2773 - val_loss: 26.1739 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.59766\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 923us/step - loss: 16.7367 - acc: 0.2598 - val_loss: 26.2479 - val_acc: 0.3652\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.59766\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 948us/step - loss: 16.1900 - acc: 0.2500 - val_loss: 28.4425 - val_acc: 0.1465\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.59766\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 933us/step - loss: 15.6901 - acc: 0.2324 - val_loss: 28.0214 - val_acc: 0.1465\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.59766\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 920us/step - loss: 16.7828 - acc: 0.2344 - val_loss: 27.8693 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.59766\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 950us/step - loss: 16.3594 - acc: 0.2617 - val_loss: 26.3677 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.59766\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 881us/step - loss: 16.2932 - acc: 0.2871 - val_loss: 26.0262 - val_acc: 0.1582\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.59766\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 906us/step - loss: 16.1701 - acc: 0.2637 - val_loss: 27.9607 - val_acc: 0.2227\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.59766\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 950us/step - loss: 16.3557 - acc: 0.2539 - val_loss: 30.2460 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.59766\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 951us/step - loss: 16.1531 - acc: 0.2441 - val_loss: 29.7922 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.59766\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 908us/step - loss: 16.5328 - acc: 0.2324 - val_loss: 25.7827 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.59766\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 947us/step - loss: 16.0959 - acc: 0.2852 - val_loss: 25.7329 - val_acc: 0.3789\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.59766\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 925us/step - loss: 15.9712 - acc: 0.2734 - val_loss: 29.7959 - val_acc: 0.3789\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.59766\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 15.6744 - acc: 0.2871 - val_loss: 29.8990 - val_acc: 0.3789\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.59766\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 938us/step - loss: 15.7067 - acc: 0.2754 - val_loss: 26.6819 - val_acc: 0.3789\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.59766\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 903us/step - loss: 16.1089 - acc: 0.2598 - val_loss: 27.8648 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.59766\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 939us/step - loss: 16.1489 - acc: 0.2871 - val_loss: 29.4873 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.59766\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 861us/step - loss: 15.6756 - acc: 0.2559 - val_loss: 29.9723 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.59766\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 901us/step - loss: 15.5978 - acc: 0.2949 - val_loss: 29.5678 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.59766\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 918us/step - loss: 15.4697 - acc: 0.2598 - val_loss: 29.3228 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.59766\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 911us/step - loss: 15.5008 - acc: 0.2930 - val_loss: 28.7407 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.59766\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 942us/step - loss: 15.9795 - acc: 0.3047 - val_loss: 29.9270 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.59766\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 914us/step - loss: 15.3522 - acc: 0.3008 - val_loss: 29.4183 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.59766\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 904us/step - loss: 15.3710 - acc: 0.2559 - val_loss: 29.2283 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.59766\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 915us/step - loss: 15.4557 - acc: 0.2617 - val_loss: 30.2642 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.59766\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 14.8840 - acc: 0.2520 - val_loss: 31.1528 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.59766\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 914us/step - loss: 15.2719 - acc: 0.3027 - val_loss: 30.0876 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.59766\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 851us/step - loss: 15.4612 - acc: 0.2715 - val_loss: 28.7359 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.59766\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 865us/step - loss: 15.4041 - acc: 0.2637 - val_loss: 31.3942 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.59766\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 897us/step - loss: 15.3006 - acc: 0.2578 - val_loss: 31.7336 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.59766\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 15.3173 - acc: 0.2422 - val_loss: 31.6566 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.59766\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 913us/step - loss: 14.9052 - acc: 0.2715 - val_loss: 30.6700 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.59766\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 15.1752 - acc: 0.2676 - val_loss: 31.9261 - val_acc: 0.3652\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.59766\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 918us/step - loss: 14.4048 - acc: 0.3340 - val_loss: 32.3548 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.59766\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 950us/step - loss: 15.1387 - acc: 0.2754 - val_loss: 29.2315 - val_acc: 0.1602\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.59766\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 970us/step - loss: 15.0885 - acc: 0.2695 - val_loss: 31.5712 - val_acc: 0.1602\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.59766\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 912us/step - loss: 14.8778 - acc: 0.2988 - val_loss: 34.1119 - val_acc: 0.1602\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.59766\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 15.1103 - acc: 0.3008 - val_loss: 31.0090 - val_acc: 0.0781\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.59766\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 922us/step - loss: 14.5859 - acc: 0.2871 - val_loss: 28.0466 - val_acc: 0.1602\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.59766\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 896us/step - loss: 14.7771 - acc: 0.2324 - val_loss: 33.8475 - val_acc: 0.1602\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.59766\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 892us/step - loss: 15.2654 - acc: 0.2988 - val_loss: 34.3974 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.59766\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 894us/step - loss: 15.6144 - acc: 0.2539 - val_loss: 31.1064 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.59766\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 924us/step - loss: 14.7017 - acc: 0.2559 - val_loss: 30.5928 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.59766\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 897us/step - loss: 15.5951 - acc: 0.2461 - val_loss: 34.9957 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.59766\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 886us/step - loss: 14.7684 - acc: 0.2520 - val_loss: 31.7371 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.59766\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 883us/step - loss: 15.1016 - acc: 0.2852 - val_loss: 32.6131 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.59766\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 898us/step - loss: 14.5000 - acc: 0.2988 - val_loss: 34.8781 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.59766\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 921us/step - loss: 15.3139 - acc: 0.2676 - val_loss: 31.8649 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.59766\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 901us/step - loss: 14.5673 - acc: 0.3086 - val_loss: 32.5463 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.59766\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 918us/step - loss: 15.1855 - acc: 0.3027 - val_loss: 38.2845 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.59766\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 935us/step - loss: 15.5122 - acc: 0.2949 - val_loss: 29.9747 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.59766\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 942us/step - loss: 15.2991 - acc: 0.2715 - val_loss: 33.0664 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.59766\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 927us/step - loss: 15.0707 - acc: 0.2637 - val_loss: 38.7511 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.59766\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 937us/step - loss: 14.8206 - acc: 0.2734 - val_loss: 33.0850 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.59766\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 905us/step - loss: 13.7164 - acc: 0.2793 - val_loss: 29.7142 - val_acc: 0.4551\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.59766\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 882us/step - loss: 14.6568 - acc: 0.2598 - val_loss: 35.6185 - val_acc: 0.4551\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.59766\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 891us/step - loss: 14.5096 - acc: 0.2793 - val_loss: 33.7100 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.59766\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 936us/step - loss: 14.2958 - acc: 0.2812 - val_loss: 30.3295 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.59766\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 937us/step - loss: 14.1476 - acc: 0.2559 - val_loss: 35.0652 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.59766\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 946us/step - loss: 14.9278 - acc: 0.2578 - val_loss: 35.6670 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.59766\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 950us/step - loss: 15.0159 - acc: 0.2754 - val_loss: 30.6405 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.59766\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 942us/step - loss: 14.4629 - acc: 0.2871 - val_loss: 33.1733 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.59766\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 15.1007 - acc: 0.2754 - val_loss: 36.6968 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.59766\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 941us/step - loss: 14.6467 - acc: 0.2539 - val_loss: 33.9641 - val_acc: 0.2363\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.59766\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 973us/step - loss: 13.7321 - acc: 0.2617 - val_loss: 32.8495 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.59766\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 1s 981us/step - loss: 14.2541 - acc: 0.2793 - val_loss: 36.7992 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.59766\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 948us/step - loss: 14.5371 - acc: 0.3047 - val_loss: 33.4303 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.59766\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 1s 990us/step - loss: 14.9888 - acc: 0.2734 - val_loss: 33.9994 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.59766\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 14.2792 - acc: 0.2559 - val_loss: 37.3083 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.59766\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 1s 1ms/step - loss: 14.0464 - acc: 0.2676 - val_loss: 31.6790 - val_acc: 0.3008\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.59766\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"data/weights/model-{val_acc:.2f}.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=True, mode=\"auto\", period=1)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks=[checkpoint])\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[404.5686340332031, 0.5]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1488c3fd0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACplJREFUeJzt3U+InPd9x/H3p3ZycXKQ660Qjl2lwRRMoUpZRCGmpKQJii9yLiE+BBUMSiGGBHKoSQ92b6Y0CT2UBKUWUUvqUEiMdTBuXBMwgRK8Nq4t223lGoVIyNIKH+KcUjvfHvZx2Ni72vXOM/OM+n2/YJiZZ57d58ugt+Yv+0tVIamf35p6AEnTMH6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmrp+kQe76aab6uDBg4s8pNTKuXPnuHLlSnaz70zxJzkC/B1wHfAPVfXg1fY/ePAga2trsxxS0lWsrq7uet89P+1Pch3w98CngduBu5PcvtffJ2mxZnnNfxh4paperapfAt8Djo4zlqR5myX+m4Gfbbp+ftj2G5IcT7KWZG19fX2Gw0ka09zf7a+qE1W1WlWrKysr8z6cpF2aJf4LwC2brn9o2CbpGjBL/E8DtyX5cJL3A58DTo8zlqR52/NHfVX1ZpJ7gX9l46O+k1X14miTSZqrmT7nr6rHgMdGmkXSAvn1Xqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qamZVulNcg54A3gLeLOqVscYStL8zRT/4E+r6soIv0fSAvm0X2pq1vgL+GGSZ5IcH2MgSYsx69P+O6rqQpLfAZ5I8p9V9dTmHYb/FI4D3HrrrTMeTtJYZnrkr6oLw/ll4BHg8Bb7nKiq1apaXVlZmeVwkka05/iT3JDkg29fBj4FnBlrMEnzNcvT/v3AI0ne/j3/XFWPjzKVpLnbc/xV9SrwhyPOImmB/KhPasr4paaMX2rK+KWmjF9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpoxfasr4pabG+Ou9uoYd+eu/mHqEpfT4/d+aeoS585Ffasr4paaMX2rK+KWmjF9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpoxfasr4paaMX2pqx/iTnExyOcmZTdtuTPJEkrPD+b75jilpbLt55P8OcOQd2+4Dnqyq24Anh+uSriE7xl9VTwGvv2PzUeDUcPkUcNfIc0mas72+5t9fVReHy68B+0eaR9KCzPyGX1UVUNvdnuR4krUka+vr67MeTtJI9hr/pSQHAIbzy9vtWFUnqmq1qlZXVlb2eDhJY9tr/KeBY8PlY8Cj44wjaVF281Hfw8C/A7+f5HySe4AHgU8mOQv82XBd0jVkx7/bX1V3b3PTJ0aeRdIC+Q0/qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmjJ+qSnjl5oyfqkp45eaMn6pKeOXmtox/iQnk1xOcmbTtgeSXEjy3HC6c75jShrbbh75vwMc2WL7N6rq0HB6bNyxJM3bjvFX1VPA6wuYRdICzfKa/94kzw8vC/aNNpGkhdhr/N8EPgIcAi4CX9tuxyTHk6wlWVtfX9/j4SSNbU/xV9Wlqnqrqn4FfBs4fJV9T1TValWtrqys7HVOSSPbU/xJDmy6+hngzHb7SlpO1++0Q5KHgY8DNyU5D9wPfDzJIaCAc8AX5jijpDnYMf6qunuLzQ/NYRZJC+Q3/KSmjF9qyvilpoxfasr4paaMX2pqx4/69P/b4/d/a+oRNBEf+aWmjF9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpoxfasr4paZ2jD/JLUl+lOSlJC8m+dKw/cYkTyQ5O5zvm/+4ksaym0f+N4GvVNXtwB8DX0xyO3Af8GRV3QY8OVyXdI3YMf6qulhVzw6X3wBeBm4GjgKnht1OAXfNa0hJ43tPr/mTHAQ+CvwE2F9VF4ebXgP2jzqZpLnadfxJPgB8H/hyVf18821VVUBt83PHk6wlWVtfX59pWEnj2VX8Sd7HRvjfraofDJsvJTkw3H4AuLzVz1bViapararVlZWVMWaWNILdvNsf4CHg5ar6+qabTgPHhsvHgEfHH0/SvOxmie6PAZ8HXkjy3LDtq8CDwL8kuQf4KfDZ+YwoaR52jL+qfgxkm5s/Me44khbFb/hJTRm/1JTxS00Zv9SU8UtNGb/UlPFLTRm/1JTxS00Zv9SU8UtNGb/UlPFLTRm/1JTxS00Zv9SU8UtNGb/UlPFLTRm/1JTxS00Zv9SU8UtNGb/UlPFLTRm/1JTxS00Zv9SU8UtNGb/U1I7xJ7klyY+SvJTkxSRfGrY/kORCkueG053zH1fSWK7fxT5vAl+pqmeTfBB4JskTw23fqKq/nd94kuZlx/ir6iJwcbj8RpKXgZvnPZik+XpPr/mTHAQ+Cvxk2HRvkueTnEyyb5ufOZ5kLcna+vr6TMNKGs+u40/yAeD7wJer6ufAN4GPAIfYeGbwta1+rqpOVNVqVa2urKyMMLKkMewq/iTvYyP871bVDwCq6lJVvVVVvwK+DRye35iSxrabd/sDPAS8XFVf37T9wKbdPgOcGX88SfOym3f7PwZ8HnghyXPDtq8Cdyc5BBRwDvjCXCaUNBe7ebf/x0C2uOmx8ceRtCh+w09qyvilpoxfasr4paaMX2rK+KWmjF9qyvilpoxfasr4paaMX2rK+KWmjF9qyvilplJViztYsg78dNOmm4ArCxvgvVnW2ZZ1LnC2vRpztt+tql39vbyFxv+ugydrVbU62QBXsayzLetc4Gx7NdVsPu2XmjJ+qamp4z8x8fGvZllnW9a5wNn2apLZJn3NL2k6Uz/yS5rIJPEnOZLkv5K8kuS+KWbYTpJzSV4YVh5em3iWk0kuJzmzaduNSZ5IcnY433KZtIlmW4qVm6+ysvSk992yrXi98Kf9Sa4D/hv4JHAeeBq4u6peWugg20hyDlitqsk/E07yJ8AvgH+sqj8Ytv0N8HpVPTj8x7mvqv5ySWZ7APjF1Cs3DwvKHNi8sjRwF/DnTHjfXWWuzzLB/TbFI/9h4JWqerWqfgl8Dzg6wRxLr6qeAl5/x+ajwKnh8ik2/vEs3DazLYWqulhVzw6X3wDeXll60vvuKnNNYor4bwZ+tun6eZZrye8CfpjkmSTHpx5mC/uHZdMBXgP2TznMFnZcuXmR3rGy9NLcd3tZ8XpsvuH3bndU1R8Bnwa+ODy9XUq18ZptmT6u2dXKzYuyxcrSvzblfbfXFa/HNkX8F4BbNl3/0LBtKVTVheH8MvAIy7f68KW3F0kdzi9PPM+vLdPKzVutLM0S3HfLtOL1FPE/DdyW5MNJ3g98Djg9wRzvkuSG4Y0YktwAfIrlW334NHBsuHwMeHTCWX7DsqzcvN3K0kx83y3ditdVtfATcCcb7/j/D/BXU8ywzVy/B/zHcHpx6tmAh9l4Gvi/bLw3cg/w28CTwFng34Abl2i2fwJeAJ5nI7QDE812BxtP6Z8HnhtOd059311lrknuN7/hJzXlG35SU8YvNWX8UlPGLzVl/FJTxi81ZfxSU8YvNfV/Q/xbjtDeCTUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.127011, 7.120087, 4.087321, 4.039061]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17., 12.,  8.,  8.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_locations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
