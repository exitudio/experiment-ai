{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw NN\n",
    "[https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6)\n",
    "\n",
    "\n",
    "TODO\n",
    "- understand why using dot product\n",
    "  - is that the same as A*B np.dot(A',B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2699923583351507\n",
      "loss: 1.0332002795447481\n",
      "loss: 0.9971457132462278\n",
      "loss: 0.9969287548943392\n",
      "loss: 0.9967430937522036\n",
      "loss: 0.9965493470863622\n",
      "loss: 0.9963470062793567\n",
      "loss: 0.9961355495881313\n",
      "loss: 0.9959144249725354\n",
      "loss: 0.9956830484727086\n",
      "loss: 0.9954408025206711\n",
      "loss: 0.995187034213123\n",
      "loss: 0.9949210535518078\n",
      "loss: 0.9946421316598112\n",
      "loss: 0.9943494989836104\n",
      "loss: 0.9940423434922735\n",
      "loss: 0.9937198088868322\n",
      "loss: 0.993380992834523\n",
      "loss: 0.9930249452442574\n",
      "loss: 0.9926506666013032\n",
      "loss: 0.9922571063806912\n",
      "loss: 0.9918431615602181\n",
      "loss: 0.9914076752550585\n",
      "loss: 0.9909494354968046\n",
      "loss: 0.9904671741801907\n",
      "loss: 0.9899595662006799\n",
      "loss: 0.9894252288054501\n",
      "loss: 0.9888627211790147\n",
      "loss: 0.9882705442826591\n",
      "loss: 0.9876471409640393\n",
      "loss: 0.9869908963496188\n",
      "loss: 0.9863001385281144\n",
      "loss: 0.985573139527834\n",
      "loss: 0.9848081165848015\n",
      "loss: 0.9840032336920114\n",
      "loss: 0.9831566034132724\n",
      "loss: 0.9822662889381225\n",
      "loss: 0.9813303063475789\n",
      "loss: 0.9803466270544179\n",
      "loss: 0.9793131803766655\n",
      "loss: 0.9782278561995111\n",
      "loss: 0.9770885076793953\n",
      "loss: 0.975892953944983\n",
      "loss: 0.9746389827535862\n",
      "loss: 0.973324353068589\n",
      "loss: 0.9719467975338307\n",
      "loss: 0.9705040248347414\n",
      "loss: 0.9689937219532514\n",
      "loss: 0.9674135563437999\n",
      "loss: 0.965761178080714\n",
      "loss: 0.9640342220521582\n",
      "loss: 0.9622303103019068\n",
      "loss: 0.9603470546464186\n",
      "loss: 0.9583820597198929\n",
      "loss: 0.9563329266229786\n",
      "loss: 0.9541972573702343\n",
      "loss: 0.9519726603459628\n",
      "loss: 0.9496567569863386\n",
      "loss: 0.9472471899064676\n",
      "loss: 0.9447416326829852\n",
      "loss: 0.9421378014848567\n",
      "loss: 0.9394334687162864\n",
      "loss: 0.9366264787953054\n",
      "loss: 0.9337147661392535\n",
      "loss: 0.9306963753639143\n",
      "loss: 0.9275694836267954\n",
      "loss: 0.9243324249579274\n",
      "loss: 0.9209837163250372\n",
      "loss: 0.9175220850763637\n",
      "loss: 0.9139464972968127\n",
      "loss: 0.9102561865055101\n",
      "loss: 0.9064506820199835\n",
      "loss: 0.9025298362196583\n",
      "loss: 0.898493849865243\n",
      "loss: 0.8943432945772172\n",
      "loss: 0.8900791315522227\n",
      "loss: 0.8857027256062355\n",
      "loss: 0.8812158536822295\n",
      "loss: 0.8766207070502541\n",
      "loss: 0.8719198865596014\n",
      "loss: 0.8671163904736976\n",
      "loss: 0.8622135946232261\n",
      "loss: 0.8572152248437802\n",
      "loss: 0.8521253219105921\n",
      "loss: 0.8469481994323249\n",
      "loss: 0.8416883954054484\n",
      "loss: 0.8363506183471366\n",
      "loss: 0.8309396891060612\n",
      "loss: 0.8254604795870052\n",
      "loss: 0.8199178497099711\n",
      "loss: 0.8143165839539301\n",
      "loss: 0.8086613288096492\n",
      "loss: 0.8029565323888065\n",
      "loss: 0.7972063873144645\n",
      "loss: 0.7914147778600049\n",
      "loss: 0.7855852321203395\n",
      "loss: 0.7797208798019768\n",
      "loss: 0.7738244160184695\n",
      "loss: 0.7678980712853223\n",
      "loss: 0.7619435877327833\n",
      "loss: 0.7559622014034542\n",
      "loss: 0.7499546303801254\n",
      "loss: 0.7439210684014366\n",
      "loss: 0.737861183571068\n",
      "loss: 0.7317741217507291\n",
      "loss: 0.7256585142474331\n",
      "loss: 0.7195124894594547\n",
      "loss: 0.713333688229979\n",
      "loss: 0.7071192827688045\n",
      "loss: 0.7008659991356876\n",
      "loss: 0.694570143428131\n",
      "loss: 0.6882276319745158\n",
      "loss: 0.6818340259919982\n",
      "loss: 0.6753845713173409\n",
      "loss: 0.6688742439457931\n",
      "loss: 0.6622978022040882\n",
      "loss: 0.6556498464225053\n",
      "loss: 0.6489248869400106\n",
      "loss: 0.6421174211573182\n",
      "loss: 0.6352220201276957\n",
      "loss: 0.6282334248299731\n",
      "loss: 0.6211466517941953\n",
      "loss: 0.6139571071492405\n",
      "loss: 0.6066607074489836\n",
      "loss: 0.5992540048422388\n",
      "loss: 0.5917343133345535\n",
      "loss: 0.5840998321193971\n",
      "loss: 0.5763497613205801\n",
      "loss: 0.5684844050824407\n",
      "loss: 0.5605052568597848\n",
      "loss: 0.5524150620649355\n",
      "loss: 0.5442178539559717\n",
      "loss: 0.535918959779035\n",
      "loss: 0.5275249756322176\n",
      "loss: 0.5190437101706058\n",
      "loss: 0.5104840989568513\n",
      "loss: 0.5018560928034482\n",
      "loss: 0.4931705246945809\n",
      "loss: 0.484438960704902\n",
      "loss: 0.4756735407003351\n",
      "loss: 0.4668868145285424\n",
      "loss: 0.458091578956656\n",
      "loss: 0.44930071989971543\n",
      "loss: 0.440527063624762\n",
      "loss: 0.4317832397219771\n",
      "loss: 0.4230815577891115\n",
      "loss: 0.4144338990305487\n",
      "loss: 0.40585162334964153\n",
      "loss: 0.39734549201185687\n",
      "loss: 0.3889256055628203\n",
      "loss: 0.38060135638062653\n",
      "loss: 0.37238139500791045\n",
      "loss: 0.36427360923234375\n",
      "loss: 0.35628511475528035\n",
      "loss: 0.3484222562019408\n",
      "loss: 0.34069061717948057\n",
      "loss: 0.3330950380789628\n",
      "loss: 0.32563964034046666\n",
      "loss: 0.3183278559531469\n",
      "loss: 0.3111624610388052\n",
      "loss: 0.3041456124625379\n",
      "loss: 0.29727888652116946\n",
      "loss: 0.29056331887361475\n",
      "loss: 0.28399944499188906\n",
      "loss: 0.2775873405229387\n",
      "loss: 0.27132666105659764\n",
      "loss: 0.26521668089160944\n",
      "loss: 0.2592563304784665\n",
      "loss: 0.25344423229433655\n",
      "loss: 0.24777873497160902\n",
      "loss: 0.2422579455580558\n",
      "loss: 0.23687975983407447\n",
      "loss: 0.23164189065177943\n",
      "loss: 0.22654189429283345\n",
      "loss: 0.22157719486778615\n",
      "loss: 0.21674510680015924\n",
      "loss: 0.21204285545444407\n",
      "loss: 0.20746759597922187\n",
      "loss: 0.20301643044543682\n",
      "loss: 0.19868642336597664\n",
      "loss: 0.1944746156865883\n",
      "loss: 0.1903780373402256\n",
      "loss: 0.18639371845744496\n",
      "loss: 0.18251869932480266\n",
      "loss: 0.17875003918154636\n",
      "loss: 0.17508482394245614\n",
      "loss: 0.17152017293166438\n",
      "loss: 0.16805324470879995\n",
      "loss: 0.16468124206497703\n",
      "loss: 0.16140141626213217\n",
      "loss: 0.15821107058502792\n",
      "loss: 0.15510756327102063\n",
      "loss: 0.15208830987846392\n",
      "loss: 0.1491507851504431\n",
      "loss: 0.1462925244264561\n",
      "loss: 0.14351112465069726\n",
      "loss: 0.1408042450217998\n",
      "loss: 0.13816960732524547\n",
      "loss: 0.13560499598619474\n",
      "loss: 0.133108257877226\n",
      "loss: 0.13067730191238672\n",
      "loss: 0.12831009845608396\n",
      "loss: 0.12600467857264974\n",
      "loss: 0.12375913313991903\n",
      "loss: 0.12157161184783824\n",
      "loss: 0.11944032210098526\n",
      "loss: 0.1173635278419175\n",
      "loss: 0.11533954831044191\n",
      "loss: 0.11336675675226347\n",
      "loss: 0.11144357908894374\n",
      "loss: 0.10956849255972678\n",
      "loss: 0.10774002434454005\n",
      "loss: 0.10595675017633971\n",
      "loss: 0.10421729294994356\n",
      "loss: 0.10252032133356717\n",
      "loss: 0.1008645483884447\n",
      "loss: 0.0992487302011613\n",
      "loss: 0.09767166453265765\n",
      "loss: 0.09613218948725602\n",
      "loss: 0.09462918220452698\n",
      "loss: 0.09316155757633257\n",
      "loss: 0.0917282669909565\n",
      "loss: 0.09032829710585566\n",
      "loss: 0.08896066865023594\n",
      "loss: 0.08762443525835568\n",
      "loss: 0.08631868233420786\n",
      "loss: 0.08504252594800371\n",
      "loss: 0.08379511176468418\n",
      "loss: 0.08257561400451374\n",
      "loss: 0.08138323443566248\n",
      "loss: 0.08021720139855956\n",
      "loss: 0.07907676886168563\n",
      "loss: 0.07796121550838754\n",
      "loss: 0.07686984385421236\n",
      "loss: 0.07580197939420247\n",
      "loss: 0.07475696977953361\n",
      "loss: 0.07373418402283731\n",
      "loss: 0.07273301173151693\n",
      "loss: 0.07175286236833751\n",
      "loss: 0.07079316453855329\n",
      "loss: 0.06985336530282174\n",
      "loss: 0.06893292951514612\n",
      "loss: 0.06803133918508475\n",
      "loss: 0.06714809286346847\n",
      "loss: 0.06628270505086578\n",
      "loss: 0.06543470562804843\n",
      "loss: 0.06460363930771784\n",
      "loss: 0.06378906510675993\n",
      "loss: 0.06299055583831595\n",
      "loss: 0.062207697622966324\n",
      "loss: 0.06144008941834106\n",
      "loss: 0.06068734256648995\n",
      "loss: 0.059949080358357956\n",
      "loss: 0.05922493761473391\n",
      "loss: 0.058514560283054684\n",
      "loss: 0.057817605049469735\n",
      "loss: 0.05713373896558408\n",
      "loss: 0.056462639089321226\n",
      "loss: 0.05580399213936294\n",
      "loss: 0.05515749416264242\n",
      "loss: 0.05452285021438398\n",
      "loss: 0.05389977405020267\n",
      "loss: 0.05328798782979138\n",
      "loss: 0.05268722183174279\n",
      "loss: 0.05209721417906932\n",
      "loss: 0.051517710574999535\n",
      "loss: 0.05094846404864681\n",
      "loss: 0.05038923471016134\n",
      "loss: 0.04983978951498921\n",
      "loss: 0.04929990203688171\n",
      "loss: 0.04876935224930529\n",
      "loss: 0.048247926314923764\n",
      "loss: 0.04773541638282994\n",
      "loss: 0.04723162039322419\n",
      "loss: 0.04673634188924234\n",
      "loss: 0.046249389835652244\n",
      "loss: 0.04577057844414896\n",
      "loss: 0.0452997270049867\n",
      "loss: 0.04483665972469873\n",
      "loss: 0.04438120556966733\n",
      "loss: 0.04393319811531207\n",
      "loss: 0.04349247540067851\n",
      "loss: 0.04305887978821377\n",
      "loss: 0.04263225782852911\n",
      "loss: 0.04221246012995336\n",
      "loss: 0.04179934123269159\n",
      "loss: 0.04139275948741056\n",
      "loss: 0.04099257693808038\n",
      "loss: 0.04059865920890614\n",
      "loss: 0.040210875395194384\n",
      "loss: 0.03982909795800178\n",
      "loss: 0.03945320262242173\n",
      "loss: 0.03908306827937054\n",
      "loss: 0.038718576890738245\n",
      "loss: 0.038359613397778776\n",
      "loss: 0.038006065632614314\n",
      "loss: 0.03765782423273858\n",
      "loss: 0.03731478255840442\n",
      "loss: 0.036976836612788444\n",
      "loss: 0.03664388496482923\n",
      "loss: 0.0363158286746381\n",
      "loss: 0.03599257122138838\n",
      "loss: 0.035674018433590665\n",
      "loss: 0.0353600784216659\n",
      "loss: 0.03505066151273259\n",
      "loss: 0.03474568018752561\n",
      "loss: 0.034445049019370344\n",
      "loss: 0.034148684615135746\n",
      "loss: 0.03385650555809655\n",
      "loss: 0.033568432352633286\n",
      "loss: 0.03328438737070575\n",
      "loss: 0.03300429480003521\n",
      "loss: 0.0327280805939349\n",
      "loss: 0.032455672422729724\n",
      "loss: 0.03218699962670848\n",
      "loss: 0.031921993170555454\n",
      "loss: 0.03166058559920753\n",
      "loss: 0.031402710995088755\n",
      "loss: 0.03114830493667166\n",
      "loss: 0.03089730445832269\n",
      "loss: 0.03064964801138227\n",
      "loss: 0.03040527542644219\n",
      "loss: 0.03016412787677404\n",
      "loss: 0.02992614784287275\n",
      "loss: 0.029691279078075384\n",
      "loss: 0.029459466575218474\n",
      "loss: 0.02923065653429937\n",
      "loss: 0.029004796331107523\n",
      "loss: 0.02878183448679139\n",
      "loss: 0.028561720638332552\n",
      "loss: 0.028344405509893277\n",
      "loss: 0.028129840885011186\n",
      "loss: 0.027917979579611008\n",
      "loss: 0.027708775415807706\n",
      "loss: 0.027502183196473334\n",
      "loss: 0.027298158680544003\n",
      "loss: 0.027096658559042364\n",
      "loss: 0.026897640431791082\n",
      "loss: 0.026701062784796663\n",
      "loss: 0.026506884968280305\n",
      "loss: 0.026315067175336278\n",
      "loss: 0.02612557042119622\n",
      "loss: 0.02593835652308133\n",
      "loss: 0.02575338808062256\n",
      "loss: 0.025570628456831355\n",
      "loss: 0.02539004175960332\n",
      "loss: 0.02521159282373837\n",
      "loss: 0.025035247193459852\n",
      "loss: 0.024860971105418864\n",
      "loss: 0.02468873147216688\n",
      "loss: 0.024518495866083304\n",
      "loss: 0.024350232503743262\n",
      "loss: 0.024183910230711793\n",
      "loss: 0.024019498506752023\n",
      "loss: 0.023856967391434586\n",
      "loss: 0.023696287530134426\n",
      "loss: 0.02353743014040589\n",
      "loss: 0.02338036699872217\n",
      "loss: 0.023225070427569224\n",
      "loss: 0.02307151328288378\n",
      "loss: 0.022919668941824036\n",
      "loss: 0.02276951129086372\n",
      "loss: 0.022621014714200062\n",
      "loss: 0.02247415408246605\n",
      "loss: 0.022328904741737758\n",
      "loss: 0.022185242502828197\n",
      "loss: 0.022043143630859706\n",
      "loss: 0.02190258483510595\n",
      "loss: 0.021763543259095856\n",
      "loss: 0.021625996470972575\n",
      "loss: 0.021489922454098837\n",
      "loss: 0.021355299597902538\n",
      "loss: 0.021222106688955376\n",
      "loss: 0.02109032290227739\n",
      "loss: 0.020959927792861502\n",
      "loss: 0.020830901287411864\n",
      "loss: 0.020703223676289077\n",
      "loss: 0.02057687560565715\n",
      "loss: 0.020451838069826686\n",
      "loss: 0.02032809240378787\n",
      "loss: 0.02020562027592849\n",
      "loss: 0.020084403680932197\n",
      "loss: 0.01996442493285109\n",
      "loss: 0.019845666658348325\n",
      "loss: 0.019728111790106057\n",
      "loss: 0.01961174356039398\n",
      "loss: 0.019496545494793793\n",
      "loss: 0.019382501406076124\n",
      "loss: 0.019269595388224682\n",
      "loss: 0.01915781181060433\n",
      "loss: 0.019047135312269297\n",
      "loss: 0.018937550796406903\n",
      "loss: 0.01882904342491373\n",
      "loss: 0.018721598613101093\n",
      "loss: 0.018615202024525084\n",
      "loss: 0.018509839565939074\n",
      "loss: 0.018405497382364865\n",
      "loss: 0.018302161852279238\n",
      "loss: 0.018199819582913047\n",
      "loss: 0.018098457405660042\n",
      "loss: 0.017998062371591857\n",
      "loss: 0.017898621747077317\n",
      "loss: 0.017800123009502723\n",
      "loss: 0.017702553843089906\n",
      "loss: 0.017605902134811762\n",
      "loss: 0.017510155970399312\n",
      "loss: 0.017415303630441113\n",
      "loss: 0.017321333586570724\n",
      "loss: 0.017228234497740844\n",
      "loss: 0.017135995206581114\n",
      "loss: 0.017044604735838343\n",
      "loss: 0.016954052284896704\n",
      "loss: 0.016864327226375486\n",
      "loss: 0.016775419102802596\n",
      "loss: 0.016687317623362875\n",
      "loss: 0.01660001266071761\n",
      "loss: 0.016513494247894615\n",
      "loss: 0.016427752575247513\n",
      "loss: 0.016342777987480676\n",
      "loss: 0.016258560980740352\n",
      "loss: 0.01617509219976895\n",
      "loss: 0.016092362435121126\n",
      "loss: 0.016010362620440716\n",
      "loss: 0.015929083829796315\n",
      "loss: 0.015848517275074504\n",
      "loss: 0.015768654303429202\n",
      "loss: 0.015689486394785714\n",
      "loss: 0.015611005159398065\n",
      "loss: 0.01553320233545898\n",
      "loss: 0.015456069786759771\n",
      "loss: 0.015379599500400923\n",
      "loss: 0.01530378358455015\n",
      "loss: 0.015228614266248386\n",
      "loss: 0.015154083889261696\n",
      "loss: 0.015080184911978281\n",
      "loss: 0.015006909905349163\n",
      "loss: 0.014934251550872213\n",
      "loss: 0.014862202638617858\n",
      "loss: 0.014790756065295826\n",
      "loss: 0.014719904832361767\n",
      "loss: 0.014649642044162832\n",
      "loss: 0.014579960906121459\n",
      "loss: 0.014510854722956613\n",
      "loss: 0.014442316896940862\n",
      "loss: 0.014374340926193333\n",
      "loss: 0.014306920403007468\n",
      "loss: 0.014240049012212257\n",
      "loss: 0.014173720529566912\n",
      "loss: 0.014107928820187842\n",
      "loss: 0.014042667837007129\n",
      "loss: 0.013977931619262047\n",
      "loss: 0.013913714291014703\n",
      "loss: 0.013850010059700914\n",
      "loss: 0.013786813214708767\n",
      "loss: 0.013724118125984085\n",
      "loss: 0.013661919242664671\n",
      "loss: 0.013600211091740793\n",
      "loss: 0.013538988276742069\n",
      "loss: 0.013478245476450275\n",
      "loss: 0.013417977443637406\n",
      "loss: 0.013358179003827771\n",
      "loss: 0.013298845054085056\n",
      "loss: 0.013239970561822217\n",
      "loss: 0.013181550563634323\n",
      "loss: 0.013123580164154864\n",
      "loss: 0.013066054534932706\n",
      "loss: 0.013008968913331767\n",
      "loss: 0.012952318601451079\n",
      "loss: 0.012896098965065574\n",
      "loss: 0.012840305432587375\n",
      "loss: 0.012784933494046313\n",
      "loss: 0.012729978700089978\n",
      "loss: 0.012675436661002935\n",
      "loss: 0.01262130304574369\n",
      "loss: 0.012567573581000661\n",
      "loss: 0.012514244050265133\n",
      "loss: 0.012461310292921583\n",
      "loss: 0.012408768203355573\n",
      "loss: 0.012356613730077523\n",
      "loss: 0.012304842874863074\n",
      "loss: 0.01225345169190942\n",
      "loss: 0.012202436287006749\n",
      "loss: 0.012151792816725694\n",
      "loss: 0.012101517487618917\n",
      "loss: 0.012051606555437761\n",
      "loss: 0.012002056324363086\n",
      "loss: 0.01195286314625011\n",
      "loss: 0.011904023419887177\n",
      "loss: 0.011855533590267284\n",
      "loss: 0.011807390147873641\n",
      "loss: 0.011759589627977657\n",
      "loss: 0.011712128609949319\n",
      "loss: 0.011665003716580784\n",
      "loss: 0.011618211613420871\n",
      "loss: 0.011571749008122464\n",
      "loss: 0.011525612649801039\n",
      "loss: 0.011479799328404684\n",
      "loss: 0.011434305874095371\n",
      "loss: 0.011389129156640733\n",
      "loss: 0.011344266084817305\n",
      "loss: 0.01129971360582364\n",
      "loss: 0.01125546870470383\n",
      "loss: 0.01121152840378141\n",
      "loss: 0.011167889762102768\n",
      "loss: 0.011124549874890477\n",
      "loss: 0.011081505873005958\n",
      "loss: 0.011038754922421724\n",
      "loss: 0.010996294223702364\n",
      "loss: 0.010954121011494816\n",
      "loss: 0.010912232554027068\n",
      "loss: 0.01087062615261594\n",
      "loss: 0.010829299141182695\n",
      "loss: 0.010788248885777438\n",
      "loss: 0.010747472784111159\n",
      "loss: 0.010706968265096437\n",
      "loss: 0.010666732788394842\n",
      "loss: 0.010626763843972962\n",
      "loss: 0.010587058951665508\n",
      "loss: 0.010547615660745932\n",
      "loss: 0.010508431549503724\n",
      "loss: 0.01046950422482973\n",
      "loss: 0.010430831321807528\n",
      "loss: 0.010392410503312112\n",
      "loss: 0.01035423945961495\n",
      "loss: 0.01031631590799591\n",
      "loss: 0.010278637592361303\n",
      "loss: 0.010241202282868388\n",
      "loss: 0.010204007775556174\n",
      "loss: 0.010167051891981882\n",
      "loss: 0.010130332478863914\n",
      "loss: 0.01009384740773014\n",
      "loss: 0.01005759457457244\n",
      "loss: 0.01002157189950625\n",
      "loss: 0.009985777326436369\n",
      "loss: 0.009950208822727562\n",
      "loss: 0.0099148643788806\n",
      "loss: 0.009879742008214041\n",
      "loss: 0.009844839746550363\n",
      "loss: 0.009810155651907768\n",
      "loss: 0.009775687804196454\n",
      "loss: 0.009741434304920119\n",
      "loss: 0.009707393276882081\n",
      "loss: 0.009673562863895771\n",
      "loss: 0.009639941230500455\n",
      "loss: 0.009606526561680932\n",
      "loss: 0.009573317062591786\n",
      "loss: 0.009540310958286136\n",
      "loss: 0.009507506493448548\n",
      "loss: 0.009474901932132008\n",
      "loss: 0.009442495557499311\n",
      "loss: 0.009410285671568201\n",
      "loss: 0.009378270594960741\n",
      "loss: 0.009346448666656232\n",
      "loss: 0.009314818243748406\n",
      "loss: 0.009283377701205995\n",
      "loss: 0.009252125431637273\n",
      "loss: 0.009221059845058006\n",
      "loss: 0.009190179368663223\n",
      "loss: 0.009159482446602078\n",
      "loss: 0.00912896753975678\n",
      "loss: 0.009098633125524226\n",
      "loss: 0.009068477697601472\n",
      "loss: 0.009038499765774288\n",
      "loss: 0.009008697855708755\n",
      "loss: 0.008979070508746348\n",
      "loss: 0.008949616281701753\n",
      "loss: 0.008920333746664198\n",
      "loss: 0.008891221490801255\n",
      "loss: 0.008862278116165882\n",
      "loss: 0.00883350223950646\n",
      "loss: 0.008804892492079275\n",
      "loss: 0.008776447519464265\n",
      "loss: 0.008748165981383081\n",
      "loss: 0.008720046551520321\n",
      "loss: 0.008692087917346741\n",
      "loss: 0.008664288779945892\n",
      "loss: 0.008636647853842687\n",
      "loss: 0.008609163866834706\n",
      "loss: 0.00858183555982618\n",
      "loss: 0.008554661686663924\n",
      "loss: 0.008527641013976161\n",
      "loss: 0.008500772321013584\n",
      "loss: 0.008474054399492276\n",
      "loss: 0.008447486053439788\n",
      "loss: 0.008421066099042553\n",
      "loss: 0.00839479336449609\n",
      "loss: 0.008368666689857206\n",
      "loss: 0.008342684926898207\n",
      "loss: 0.008316846938963358\n",
      "loss: 0.008291151600827391\n",
      "loss: 0.008265597798556002\n",
      "loss: 0.008240184429368322\n",
      "loss: 0.008214910401501373\n",
      "loss: 0.008189774634076531\n",
      "loss: 0.008164776056967596\n",
      "loss: 0.008139913610671283\n",
      "loss: 0.008115186246179\n",
      "loss: 0.00809059292485059\n",
      "loss: 0.008066132618290084\n",
      "loss: 0.008041804308222999\n",
      "loss: 0.008017606986375157\n",
      "loss: 0.007993539654353798\n",
      "loss: 0.007969601323529772\n",
      "loss: 0.00794579101492155\n",
      "loss: 0.007922107759081065\n",
      "loss: 0.007898550595980785\n",
      "loss: 0.007875118574902596\n",
      "loss: 0.007851810754328295\n",
      "loss: 0.00782862620183119\n",
      "loss: 0.00780556399396974\n",
      "loss: 0.007782623216182161\n",
      "loss: 0.007759802962682822\n",
      "loss: 0.007737102336359898\n",
      "loss: 0.007714520448674418\n",
      "loss: 0.00769205641956083\n",
      "loss: 0.0076697093773287015\n",
      "loss: 0.007647478458566021\n",
      "loss: 0.007625362808043507\n",
      "loss: 0.007603361578620527\n",
      "loss: 0.007581473931151992\n",
      "loss: 0.007559699034396634\n",
      "loss: 0.007538036064926761\n",
      "loss: 0.00751648420703872\n",
      "loss: 0.007495042652665004\n",
      "loss: 0.007473710601287278\n",
      "loss: 0.007452487259850566\n",
      "loss: 0.007431371842679025\n",
      "loss: 0.007410363571391987\n",
      "loss: 0.007389461674821974\n",
      "loss: 0.007368665388933224\n",
      "loss: 0.007347973956741714\n",
      "loss: 0.007327386628235746\n",
      "loss: 0.007306902660298164\n",
      "loss: 0.0072865213166289815\n",
      "loss: 0.0072662418676696545\n",
      "loss: 0.00724606359052771\n",
      "loss: 0.007225985768902957\n",
      "loss: 0.007206007693014115\n",
      "loss: 0.0071861286595269\n",
      "loss: 0.007166347971482551\n",
      "loss: 0.007146664938227801\n",
      "loss: 0.007127078875345282\n",
      "loss: 0.007107589104585112\n",
      "loss: 0.007088194953797282\n",
      "loss: 0.0070688957568650155\n",
      "loss: 0.007049690853638681\n",
      "loss: 0.007030579589870886\n",
      "loss: 0.007011561317152349\n",
      "loss: 0.006992635392848314\n",
      "loss: 0.00697380118003616\n",
      "loss: 0.0069550580474435466\n",
      "loss: 0.006936405369387363\n",
      "loss: 0.006917842525713648\n",
      "loss: 0.0068993689017380014\n",
      "loss: 0.006880983888186946\n",
      "loss: 0.006862686881139895\n",
      "loss: 0.006844477281972024\n",
      "loss: 0.0068263544972976325\n",
      "loss: 0.006808317938914406\n",
      "loss: 0.006790367023748275\n",
      "loss: 0.0067725011737989685\n",
      "loss: 0.006754719816086371\n",
      "loss: 0.006737022382597286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00671940831023312\n",
      "loss: 0.0067018770407581\n",
      "loss: 0.00668442802074822\n",
      "loss: 0.006667060701540552\n",
      "loss: 0.0066497745391834815\n",
      "loss: 0.006632568994387536\n",
      "loss: 0.006615443532476634\n",
      "loss: 0.006598397623339993\n",
      "loss: 0.006581430741384706\n",
      "loss: 0.00656454236548888\n",
      "loss: 0.006547731978955336\n",
      "loss: 0.006530999069465703\n",
      "loss: 0.006514343129035387\n",
      "loss: 0.006497763653968873\n",
      "loss: 0.0064812601448156065\n",
      "loss: 0.0064648321063263126\n",
      "loss: 0.0064484790474101635\n",
      "loss: 0.006432200481092184\n",
      "loss: 0.0064159959244709935\n",
      "loss: 0.006399864898677594\n",
      "loss: 0.0063838069288341985\n",
      "loss: 0.0063678215440137916\n",
      "loss: 0.006351908277199952\n",
      "loss: 0.006336066665247402\n",
      "loss: 0.006320296248842871\n",
      "loss: 0.006304596572466466\n",
      "loss: 0.006288967184353475\n",
      "loss: 0.006273407636456684\n",
      "loss: 0.006257917484409067\n",
      "loss: 0.0062424962874870205\n",
      "loss: 0.006227143608573774\n",
      "loss: 0.00621185901412361\n",
      "loss: 0.006196642074126268\n",
      "loss: 0.006181492362071763\n",
      "loss: 0.006166409454915582\n",
      "loss: 0.006151392933044611\n",
      "loss: 0.006136442380242926\n",
      "loss: 0.006121557383658391\n",
      "loss: 0.006106737533769593\n",
      "loss: 0.006091982424352981\n",
      "loss: 0.006077291652450464\n",
      "loss: 0.006062664818337565\n",
      "loss: 0.006048101525491593\n",
      "loss: 0.006033601380560582\n",
      "loss: 0.006019163993332087\n",
      "loss: 0.006004788976703001\n",
      "loss: 0.005990475946649025\n",
      "loss: 0.005976224522195032\n",
      "loss: 0.0059620343253853625\n",
      "loss: 0.005947904981254757\n",
      "loss: 0.005933836117799569\n",
      "loss: 0.0059198273659489785\n",
      "loss: 0.005905878359537119\n",
      "loss: 0.005891988735274942\n",
      "loss: 0.005878158132722788\n",
      "loss: 0.005864386194263068\n",
      "loss: 0.005850672565073293\n",
      "loss: 0.005837016893099612\n",
      "loss: 0.005823418829030112\n",
      "loss: 0.005809878026269167\n",
      "loss: 0.0057963941409113155\n",
      "loss: 0.005782966831716077\n",
      "loss: 0.005769595760082554\n",
      "loss: 0.005756280590024637\n",
      "loss: 0.00574302098814633\n",
      "loss: 0.005729816623617441\n",
      "loss: 0.005716667168149342\n",
      "loss: 0.005703572295971409\n",
      "loss: 0.00569053168380712\n",
      "loss: 0.00567754501085109\n",
      "loss: 0.0056646119587457945\n",
      "loss: 0.005651732211558867\n",
      "loss: 0.005638905455760524\n",
      "loss: 0.005626131380201331\n",
      "loss: 0.005613409676090083\n",
      "loss: 0.005600740036971988\n",
      "loss: 0.0055881221587071525\n",
      "loss: 0.005575555739449187\n",
      "loss: 0.0055630404796241555\n",
      "loss: 0.0055505760819096125\n",
      "loss: 0.005538162251214011\n",
      "loss: 0.0055257986946562684\n",
      "loss: 0.005513485121545543\n",
      "loss: 0.005501221243361205\n",
      "loss: 0.005489006773733148\n",
      "loss: 0.005476841428422105\n",
      "loss: 0.005464724925300422\n",
      "loss: 0.005452656984332829\n",
      "loss: 0.005440637327557453\n",
      "loss: 0.005428665679067232\n",
      "loss: 0.005416741764991144\n",
      "loss: 0.005404865313476116\n",
      "loss: 0.005393036054668666\n",
      "loss: 0.005381253720697059\n",
      "loss: 0.005369518045653472\n",
      "loss: 0.00535782876557649\n",
      "loss: 0.005346185618433565\n",
      "loss: 0.005334588344104043\n",
      "loss: 0.005323036684361886\n",
      "loss: 0.005311530382858929\n",
      "loss: 0.005300069185108223\n",
      "loss: 0.005288652838467519\n",
      "loss: 0.005277281092122903\n",
      "loss: 0.005265953697072607\n",
      "loss: 0.005254670406111193\n",
      "loss: 0.005243430973813495\n",
      "loss: 0.005232235156519077\n",
      "loss: 0.005221082712316812\n",
      "loss: 0.005209973401029326\n",
      "loss: 0.005198906984198028\n",
      "loss: 0.005187883225068019\n",
      "loss: 0.0051769018885731675\n",
      "loss: 0.005165962741321445\n",
      "loss: 0.005155065551580372\n",
      "loss: 0.005144210089262578\n",
      "loss: 0.005133396125911545\n",
      "loss: 0.005122623434687432\n",
      "loss: 0.005111891790353208\n",
      "loss: 0.005101200969260721\n",
      "loss: 0.005090550749337062\n",
      "loss: 0.005079940910070945\n",
      "loss: 0.005069371232499401\n",
      "loss: 0.00505884149919429\n",
      "loss: 0.005048351494249452\n",
      "loss: 0.005037901003267377\n",
      "loss: 0.005027489813346579\n",
      "loss: 0.005017117713068672\n",
      "loss: 0.005006784492485828\n",
      "loss: 0.004996489943108227\n",
      "loss: 0.00498623385789173\n",
      "loss: 0.004976016031225577\n",
      "loss: 0.004965836258920354\n",
      "loss: 0.004955694338195892\n",
      "loss: 0.0049455900676693716\n",
      "loss: 0.004935523247343594\n",
      "loss: 0.004925493678595405\n",
      "loss: 0.004915501164164001\n",
      "loss: 0.004905545508139554\n",
      "loss: 0.004895626515952034\n",
      "loss: 0.0048857439943598285\n",
      "loss: 0.004875897751438759\n",
      "loss: 0.004866087596571053\n",
      "loss: 0.004856313340434555\n",
      "loss: 0.00484657479499185\n",
      "loss: 0.004836871773479659\n",
      "loss: 0.004827204090398308\n",
      "loss: 0.00481757156150122\n",
      "loss: 0.004807974003784638\n",
      "loss: 0.004798411235477312\n",
      "loss: 0.00478888307603034\n",
      "loss: 0.004779389346107251\n",
      "loss: 0.0047699298675738105\n",
      "loss: 0.004760504463488407\n",
      "loss: 0.004751112958092149\n",
      "loss: 0.004741755176799251\n",
      "loss: 0.004732430946187473\n",
      "loss: 0.004723140093988514\n",
      "loss: 0.004713882449078791\n",
      "loss: 0.004704657841470068\n",
      "loss: 0.004695466102300219\n",
      "loss: 0.0046863070638241185\n",
      "loss: 0.0046771805594046385\n",
      "loss: 0.00466808642350365\n",
      "loss: 0.004659024491673193\n",
      "loss: 0.004649994600546661\n",
      "loss: 0.0046409965878301315\n",
      "loss: 0.004632030292293807\n",
      "loss: 0.0046230955537633536\n",
      "loss: 0.004614192213111508\n",
      "loss: 0.004605320112249794\n",
      "loss: 0.004596479094120035\n",
      "loss: 0.004587669002686368\n",
      "loss: 0.004578889682926916\n",
      "loss: 0.004570140980825787\n",
      "loss: 0.004561422743365162\n",
      "loss: 0.004552734818517313\n",
      "loss: 0.00454407705523674\n",
      "loss: 0.004535449303452437\n",
      "loss: 0.0045268514140602645\n",
      "loss: 0.004518283238915193\n",
      "loss: 0.004509744630823894\n",
      "loss: 0.004501235443537138\n",
      "loss: 0.004492755531742552\n",
      "loss: 0.004484304751057062\n",
      "loss: 0.004475882958019744\n",
      "loss: 0.004467490010084658\n",
      "loss: 0.004459125765613638\n",
      "loss: 0.004450790083869135\n",
      "loss: 0.004442482825007493\n",
      "loss: 0.004434203850071627\n",
      "loss: 0.004425953020984461\n",
      "loss: 0.004417730200541945\n",
      "loss: 0.004409535252406291\n",
      "loss: 0.0044013680410994165\n",
      "loss: 0.004393228431996097\n",
      "loss: 0.004385116291317638\n",
      "loss: 0.0043770314861251575\n",
      "loss: 0.004368973884313286\n",
      "loss: 0.004360943354603624\n",
      "loss: 0.004352939766538517\n",
      "loss: 0.004344962990474769\n",
      "loss: 0.004337012897577326\n",
      "loss: 0.004329089359813245\n",
      "loss: 0.004321192249945452\n",
      "loss: 0.004313321441526813\n",
      "loss: 0.00430547680889399\n",
      "loss: 0.004297658227161609\n",
      "loss: 0.004289865572216318\n",
      "loss: 0.004282098720710934\n",
      "loss: 0.004274357550058664\n",
      "loss: 0.004266641938427419\n",
      "loss: 0.00425895176473405\n",
      "loss: 0.004251286908638723\n",
      "loss: 0.0042436472505393615\n",
      "loss: 0.004236032671566123\n",
      "loss: 0.004228443053575838\n",
      "loss: 0.00422087827914666\n",
      "loss: 0.004213338231572583\n",
      "loss: 0.004205822794858246\n",
      "loss: 0.004198331853713417\n",
      "loss: 0.004190865293547919\n",
      "loss: 0.004183423000466395\n",
      "loss: 0.004176004861263081\n",
      "loss: 0.004168610763416774\n",
      "loss: 0.004161240595085702\n",
      "loss: 0.0041538942451025025\n",
      "loss: 0.004146571602969339\n",
      "loss: 0.004139272558852799\n",
      "loss: 0.0041319970035791805\n",
      "loss: 0.0041247448286294616\n",
      "loss: 0.004117515926134652\n",
      "loss: 0.00411031018887095\n",
      "loss: 0.004103127510254941\n",
      "loss: 0.004095967784339109\n",
      "loss: 0.004088830905807\n",
      "loss: 0.0040817167699687\n",
      "loss: 0.004074625272756303\n",
      "loss: 0.004067556310719278\n",
      "loss: 0.004060509781020125\n",
      "loss: 0.0040534855814298035\n",
      "loss: 0.004046483610323374\n",
      "loss: 0.00403950376667563\n",
      "loss: 0.004032545950056757\n",
      "loss: 0.0040256100606280085\n",
      "loss: 0.004018695999137524\n",
      "loss: 0.004011803666915981\n",
      "loss: 0.0040049329658725305\n",
      "loss: 0.003998083798490534\n",
      "loss: 0.003991256067823533\n",
      "loss: 0.003984449677491113\n",
      "loss: 0.003977664531674868\n",
      "loss: 0.003970900535114403\n",
      "loss: 0.00396415759310332\n",
      "loss: 0.003957435611485314\n",
      "loss: 0.0039507344966502244\n",
      "loss: 0.003944054155530151\n",
      "loss: 0.003937394495595582\n",
      "loss: 0.003930755424851696\n",
      "loss: 0.003924136851834495\n",
      "loss: 0.003917538685606951\n",
      "loss: 0.003910960835755457\n",
      "loss: 0.0039044032123860747\n",
      "loss: 0.003897865726120819\n",
      "loss: 0.0038913482880941234\n",
      "loss: 0.0038848508099491395\n",
      "loss: 0.003878373203834276\n",
      "loss: 0.0038719153823995626\n",
      "loss: 0.0038654772587931735\n",
      "loss: 0.0038590587466580378\n",
      "loss: 0.0038526597601281553\n",
      "loss: 0.003846280213825476\n",
      "loss: 0.0038399200228562205\n",
      "loss: 0.003833579102807743\n",
      "loss: 0.0038272573697449774\n",
      "loss: 0.003820954740207349\n",
      "loss: 0.0038146711312052987\n",
      "loss: 0.0038084064602170956\n",
      "loss: 0.0038021606451856963\n",
      "loss: 0.0037959336045153306\n",
      "loss: 0.003789725257068502\n",
      "loss: 0.0037835355221628023\n",
      "loss: 0.003777364319567705\n",
      "loss: 0.0037712115695015427\n",
      "loss: 0.003765077192628371\n",
      "loss: 0.00375896111005501\n",
      "loss: 0.003752863243327854\n",
      "loss: 0.0037467835144300568\n",
      "loss: 0.0037407218457784107\n",
      "loss: 0.003734678160220448\n",
      "loss: 0.003728652381031493\n",
      "loss: 0.00372264443191183\n",
      "loss: 0.0037166542369836304\n",
      "loss: 0.0037106817207883573\n",
      "loss: 0.0037047268082836594\n",
      "loss: 0.0036987894248407625\n",
      "loss: 0.0036928694962415675\n",
      "loss: 0.003686966948675896\n",
      "loss: 0.0036810817087387327\n",
      "loss: 0.0036752137034275845\n",
      "loss: 0.003669362860139637\n",
      "loss: 0.003663529106669174\n",
      "loss: 0.0036577123712049015\n",
      "loss: 0.003651912582327255\n",
      "loss: 0.0036461296690057775\n",
      "loss: 0.0036403635605966756\n",
      "loss: 0.003634614186839996\n",
      "loss: 0.003628881477857249\n",
      "loss: 0.003623165364148793\n",
      "loss: 0.0036174657765913475\n",
      "loss: 0.0036117826464354343\n",
      "loss: 0.0036061159053030045\n",
      "loss: 0.003600465485184912\n",
      "loss: 0.0035948313184383978\n",
      "loss: 0.0035892133377848894\n",
      "loss: 0.003583611476307322\n",
      "loss: 0.00357802566744796\n",
      "loss: 0.0035724558450059857\n",
      "loss: 0.0035669019431350314\n",
      "loss: 0.0035613638963410575\n",
      "loss: 0.003555841639479882\n",
      "loss: 0.0035503351077549256\n",
      "loss: 0.0035448442367149867\n",
      "loss: 0.0035393689622519294\n",
      "loss: 0.003533909220598439\n",
      "loss: 0.003528464948325894\n",
      "loss: 0.0035230360823419998\n",
      "loss: 0.003517622559888747\n",
      "loss: 0.003512224318540167\n",
      "loss: 0.0035068412962001774\n",
      "loss: 0.003501473431100502\n",
      "loss: 0.003496120661798459\n",
      "loss: 0.003490782927174937\n",
      "loss: 0.0034854601664322375\n",
      "loss: 0.0034801523190920664\n",
      "loss: 0.0034748593249934083\n",
      "loss: 0.0034695811242905486\n",
      "loss: 0.0034643176574510014\n",
      "loss: 0.0034590688652535633\n",
      "loss: 0.003453834688786148\n",
      "loss: 0.0034486150694440975\n",
      "loss: 0.0034434099489278735\n",
      "loss: 0.003438219269241425\n",
      "loss: 0.0034330429726900044\n",
      "loss: 0.0034278810018783697\n",
      "loss: 0.003422733299708905\n",
      "loss: 0.0034175998093796097\n",
      "loss: 0.003412480474382318\n",
      "loss: 0.0034073752385008066\n",
      "loss: 0.0034022840458089393\n",
      "loss: 0.003397206840668834\n",
      "loss: 0.0033921435677290285\n",
      "loss: 0.003387094171922688\n",
      "loss: 0.0033820585984658054\n",
      "loss: 0.0033770367928554193\n",
      "loss: 0.003372028700867836\n",
      "loss: 0.003367034268556875\n",
      "loss: 0.003362053442252165\n",
      "loss: 0.0033570861685573083\n",
      "loss: 0.003352132394348312\n",
      "loss: 0.003347192066771795\n",
      "loss: 0.0033422651332432416\n",
      "loss: 0.003337351541445469\n",
      "loss: 0.0033324512393268545\n",
      "loss: 0.003327564175099688\n",
      "loss: 0.0033226902972385893\n",
      "loss: 0.003317829554478816\n",
      "loss: 0.003312981895814654\n",
      "loss: 0.003308147270497863\n",
      "loss: 0.0033033256280359936\n",
      "loss: 0.0032985169181908754\n",
      "loss: 0.003293721090977055\n",
      "loss: 0.00328893809666018\n",
      "loss: 0.003284167885755477\n",
      "loss: 0.003279410409026212\n",
      "loss: 0.0032746656174821934\n",
      "loss: 0.003269933462378167\n",
      "loss: 0.003265213895212482\n",
      "loss: 0.0032605068677253836\n",
      "loss: 0.003255812331897715\n",
      "loss: 0.003251130239949314\n",
      "loss: 0.0032464605443376666\n",
      "loss: 0.0032418031977563527\n",
      "loss: 0.003237158153133649\n",
      "loss: 0.0032325253636311816\n",
      "loss: 0.0032279047826423357\n",
      "loss: 0.003223296363790994\n",
      "loss: 0.0032187000609300697\n",
      "loss: 0.0032141158281401346\n",
      "loss: 0.00320954361972803\n",
      "loss: 0.0032049833902255253\n",
      "loss: 0.0032004350943879325\n",
      "loss: 0.0031958986871927627\n",
      "loss: 0.0031913741238383713\n",
      "loss: 0.003186861359742714\n",
      "loss: 0.0031823603505418607\n",
      "loss: 0.003177871052088838\n",
      "loss: 0.003173393420452294\n",
      "loss: 0.003168927411915123\n",
      "loss: 0.0031644729829733136\n",
      "loss: 0.003160030090334511\n",
      "loss: 0.003155598690916925\n",
      "loss: 0.003151178741847945\n",
      "loss: 0.003146770200462953\n",
      "loss: 0.0031423730243041\n",
      "loss: 0.003137987171119006\n",
      "loss: 0.003133612598859595\n",
      "loss: 0.0031292492656808816\n",
      "loss: 0.003124897129939723\n",
      "loss: 0.0031205561501936718\n",
      "loss: 0.003116226285199796\n",
      "loss: 0.003111907493913407\n",
      "loss: 0.003107599735487049\n",
      "loss: 0.0031033029692691385\n",
      "loss: 0.0030990171548030115\n",
      "loss: 0.0030947422518256\n",
      "loss: 0.0030904782202664347\n",
      "loss: 0.003086225020246408\n",
      "loss: 0.0030819826120767327\n",
      "loss: 0.003077750956257768\n",
      "loss: 0.003073530013477946\n",
      "loss: 0.0030693197446126615\n",
      "loss: 0.003065120110723175\n",
      "loss: 0.003060931073055531\n",
      "loss: 0.003056752593039501\n",
      "loss: 0.0030525846322874603\n",
      "loss: 0.0030484271525934217\n",
      "loss: 0.0030442801159318803\n",
      "loss: 0.0030401434844567784\n",
      "loss: 0.0030360172205005785\n",
      "loss: 0.0030319012865730926\n",
      "loss: 0.0030277956453604662\n",
      "loss: 0.0030237002597242875\n",
      "loss: 0.0030196150927004643\n",
      "loss: 0.003015540107498213\n",
      "loss: 0.0030114752674991153\n",
      "loss: 0.0030074205362561127\n",
      "loss: 0.0030033758774924762\n",
      "loss: 0.002999341255100922\n",
      "loss: 0.0029953166331425246\n",
      "loss: 0.0029913019758458304\n",
      "loss: 0.002987297247605895\n",
      "loss: 0.0029833024129833005\n",
      "loss: 0.0029793174367032456\n",
      "loss: 0.002975342283654539\n",
      "loss: 0.0029713769188887545\n",
      "loss: 0.0029674213076192526\n",
      "loss: 0.002963475415220261\n",
      "loss: 0.0029595392072260204\n",
      "loss: 0.002955612649329745\n",
      "loss: 0.00295169570738289\n",
      "loss: 0.002947788347394088\n",
      "loss: 0.0029438905355284066\n",
      "loss: 0.0029400022381063547\n",
      "loss: 0.0029361234216031045\n",
      "loss: 0.00293225405264748\n",
      "loss: 0.002928394098021281\n",
      "loss: 0.002924543524658203\n",
      "loss: 0.002920702299643191\n",
      "loss: 0.0029168703902114693\n",
      "loss: 0.0029130477637476777\n",
      "loss: 0.002909234387785154\n",
      "loss: 0.002905430230004981\n",
      "loss: 0.0029016352582352445\n",
      "loss: 0.0028978494404501166\n",
      "loss: 0.0028940727447692148\n",
      "loss: 0.002890305139456524\n",
      "loss: 0.002886546592919856\n",
      "loss: 0.0028827970737099144\n",
      "loss: 0.0028790565505195194\n",
      "loss: 0.0028753249921827967\n",
      "loss: 0.002871602367674455\n",
      "loss: 0.00286788864610897\n",
      "loss: 0.0028641837967397776\n",
      "loss: 0.0028604877889586173\n",
      "loss: 0.0028568005922946114\n",
      "loss: 0.0028531221764136307\n",
      "loss: 0.0028494525111175126\n",
      "loss: 0.002845791566343217\n",
      "loss: 0.0028421393121622696\n",
      "loss: 0.0028384957187798663\n",
      "loss: 0.002834860756534174\n",
      "loss: 0.0028312343958956446\n",
      "loss: 0.0028276166074662342\n",
      "loss: 0.0028240073619787464\n",
      "loss: 0.002820406630296054\n",
      "loss: 0.0028168143834104266\n",
      "loss: 0.002813230592442855\n",
      "loss: 0.0028096552286422157\n",
      "loss: 0.00280608826338476\n",
      "loss: 0.002802529668173269\n",
      "loss: 0.002798979414636445\n",
      "loss: 0.0027954374745282505\n",
      "loss: 0.0027919038197270893\n",
      "loss: 0.0027883784222353164\n",
      "loss: 0.0027848612541784548\n",
      "loss: 0.0027813522878045683\n",
      "loss: 0.0027778514954835366\n",
      "loss: 0.0027743588497065163\n",
      "loss: 0.0027708743230851355\n",
      "loss: 0.0027673978883510225\n",
      "loss: 0.0027639295183550083\n",
      "loss: 0.0027604691860665604\n",
      "loss: 0.0027570168645731094\n",
      "loss: 0.002753572527079449\n",
      "loss: 0.0027501361469070918\n",
      "loss: 0.002746707697493662\n",
      "loss: 0.00274328715239222\n",
      "loss: 0.002739874485270761\n",
      "loss: 0.0027364696699114016\n",
      "loss: 0.0027330726802100172\n",
      "loss: 0.0027296834901754134\n",
      "loss: 0.0027263020739289163\n",
      "loss: 0.0027229284057036047\n",
      "loss: 0.0027195624598438436\n",
      "loss: 0.0027162042108046184\n",
      "loss: 0.002712853633150972\n",
      "loss: 0.002709510701557446\n",
      "loss: 0.0027061753908074783\n",
      "loss: 0.0027028476757928\n",
      "loss: 0.0026995275315129324\n",
      "loss: 0.002696214933074538\n",
      "loss: 0.002692909855690943\n",
      "loss: 0.002689612274681466\n",
      "loss: 0.002686322165470995\n",
      "loss: 0.0026830395035893143\n",
      "loss: 0.0026797642646705956\n",
      "loss: 0.0026764964244528878\n",
      "loss: 0.0026732359587775213\n",
      "loss: 0.002669982843588599\n",
      "loss: 0.0026667370549324403\n",
      "loss: 0.002663498568957046\n",
      "loss: 0.0026602673619115762\n",
      "loss: 0.002657043410145843\n",
      "loss: 0.0026538266901097356\n",
      "loss: 0.002650617178352756\n",
      "loss: 0.0026474148515234445\n",
      "loss: 0.00264421968636893\n",
      "loss: 0.0026410316597343534\n",
      "loss: 0.002637850748562393\n",
      "loss: 0.0026346769298928032\n",
      "loss: 0.002631510180861781\n",
      "loss: 0.0026283504787016033\n",
      "loss: 0.0026251978007400924\n",
      "loss: 0.0026220521244000976\n",
      "loss: 0.002618913427198984\n",
      "loss: 0.0026157816867482075\n",
      "loss: 0.00261265688075282\n",
      "loss: 0.002609538987010918\n",
      "loss: 0.002606427983413306\n",
      "loss: 0.00260332384794281\n",
      "loss: 0.00260022655867405\n",
      "loss: 0.0025971360937727555\n",
      "loss: 0.002594052431495454\n",
      "loss: 0.002590975550188947\n",
      "loss: 0.00258790542828979\n",
      "loss: 0.0025848420443239455\n",
      "loss: 0.002581785376906248\n",
      "loss: 0.0025787354047400045\n",
      "loss: 0.0025756921066164952\n",
      "loss: 0.0025726554614145425\n",
      "loss: 0.0025696254481001038\n",
      "loss: 0.002566602045725795\n",
      "loss: 0.0025635852334304154\n",
      "loss: 0.002560574990438596\n",
      "loss: 0.0025575712960603137\n",
      "loss: 0.002554574129690452\n",
      "loss: 0.0025515834708084153\n",
      "loss: 0.0025485992989776295\n",
      "loss: 0.002545621593845228\n",
      "loss: 0.002542650335141499\n",
      "loss: 0.002539685502679604\n",
      "loss: 0.0025367270763550355\n",
      "loss: 0.002533775036145296\n",
      "loss: 0.002530829362109443\n",
      "loss: 0.002527890034387692\n",
      "loss: 0.002524957033200977\n",
      "loss: 0.002522030338850635\n",
      "loss: 0.002519109931717888\n",
      "loss: 0.002516195792263591\n",
      "loss: 0.002513287901027619\n",
      "loss: 0.0025103862386287126\n",
      "loss: 0.002507490785763921\n",
      "loss: 0.0025046015232082796\n",
      "loss: 0.0025017184318144032\n",
      "loss: 0.0024988414925121213\n",
      "loss: 0.002495970686308071\n",
      "loss: 0.002493105994285303\n",
      "loss: 0.002490247397602962\n",
      "loss: 0.0024873948774958767\n",
      "loss: 0.002484548415274161\n",
      "loss: 0.0024817079923228603\n",
      "loss: 0.002478873590101607\n",
      "loss: 0.0024760451901442355\n",
      "loss: 0.0024732227740583827\n",
      "loss: 0.002470406323525225\n",
      "loss: 0.002467595820298941\n",
      "loss: 0.0024647912462065647\n",
      "loss: 0.002461992583147476\n",
      "loss: 0.0024591998130930924\n",
      "loss: 0.002456412918086536\n",
      "loss: 0.0024536318802422415\n",
      "loss: 0.002450856681745661\n",
      "loss: 0.002448087304852866\n",
      "loss: 0.002445323731890248\n",
      "loss: 0.002442565945254103\n",
      "loss: 0.0024398139274104\n",
      "loss: 0.0024370676608943377\n",
      "loss: 0.0024343271283100965\n",
      "loss: 0.0024315923123304157\n",
      "loss: 0.002428863195696323\n",
      "loss: 0.002426139761216799\n",
      "loss: 0.0024234219917684133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.002420709870295037\n",
      "loss: 0.002418003379807484\n",
      "loss: 0.0024153025033832078\n",
      "loss: 0.002412607224165969\n",
      "loss: 0.0024099175253655602\n",
      "loss: 0.0024072333902573945\n",
      "loss: 0.0024045548021822795\n",
      "loss: 0.0024018817445460535\n",
      "loss: 0.0023992142008193084\n",
      "loss: 0.002396552154537018\n",
      "loss: 0.002393895589298303\n",
      "loss: 0.002391244488766083\n",
      "loss: 0.002388598836666787\n",
      "loss: 0.002385958616790019\n",
      "loss: 0.0023833238129883074\n",
      "loss: 0.002380694409176726\n",
      "loss: 0.002378070389332707\n",
      "loss: 0.0023754517374956455\n",
      "loss: 0.0023728384377666237\n",
      "loss: 0.002370230474308212\n",
      "loss: 0.002367627831344003\n",
      "loss: 0.0023650304931584635\n",
      "loss: 0.002362438444096614\n",
      "loss: 0.0023598516685637053\n",
      "loss: 0.002357270151024968\n",
      "loss: 0.002354693876005327\n",
      "loss: 0.0023521228280890746\n",
      "loss: 0.002349556991919639\n",
      "loss: 0.0023469963521993023\n",
      "loss: 0.0023444408936889303\n",
      "loss: 0.0023418906012076216\n",
      "loss: 0.0023393454596325456\n",
      "loss: 0.0023368054538985897\n",
      "loss: 0.00233427056899808\n",
      "loss: 0.0023317407899806054\n",
      "loss: 0.0023292161019526397\n",
      "loss: 0.0023266964900773533\n",
      "loss: 0.0023241819395742954\n",
      "loss: 0.002321672435719152\n",
      "loss: 0.002319167963843519\n",
      "loss: 0.0023166685093345524\n",
      "loss: 0.0023141740576347962\n",
      "loss: 0.0023116845942418897\n",
      "loss: 0.00230920010470829\n",
      "loss: 0.0023067205746410695\n",
      "loss: 0.002304245989701571\n",
      "loss: 0.0023017763356053206\n",
      "loss: 0.002299311598121543\n",
      "loss: 0.002296851763073149\n",
      "loss: 0.0022943968163363147\n",
      "loss: 0.0022919467438403318\n",
      "loss: 0.002289501531567301\n",
      "loss: 0.0022870611655519306\n",
      "loss: 0.0022846256318812784\n",
      "loss: 0.0022821949166945323\n",
      "loss: 0.002279769006182681\n",
      "loss: 0.0022773478865883994\n",
      "loss: 0.002274931544205763\n",
      "loss: 0.0022725199653799324\n",
      "loss: 0.0022701131365071023\n",
      "loss: 0.0022677110440340216\n",
      "loss: 0.0022653136744580104\n",
      "loss: 0.0022629210143265107\n",
      "loss: 0.002260533050237054\n",
      "loss: 0.0022581497688368385\n",
      "loss: 0.0022557711568226765\n",
      "loss: 0.002253397200940675\n",
      "loss: 0.0022510278879860047\n",
      "loss: 0.002248663204802693\n",
      "loss: 0.002246303138283427\n",
      "loss: 0.0022439476753693096\n",
      "loss: 0.0022415968030496504\n",
      "loss: 0.0022392505083617255\n",
      "loss: 0.002236908778390532\n",
      "loss: 0.0022345716002687027\n",
      "loss: 0.002232238961176125\n",
      "loss: 0.002229910848339834\n",
      "loss: 0.0022275872490337394\n",
      "loss: 0.002225268150578486\n",
      "loss: 0.002222953540341129\n",
      "loss: 0.0022206434057350766\n",
      "loss: 0.002218337734219729\n",
      "loss: 0.0022160365133003564\n",
      "loss: 0.002213739730527918\n",
      "loss: 0.0022114473734987407\n",
      "loss: 0.0022091594298544615\n",
      "loss: 0.0022068758872816853\n",
      "loss: 0.002204596733511887\n",
      "loss: 0.002202321956321188\n",
      "loss: 0.002200051543530104\n",
      "loss: 0.0021977854830034136\n",
      "loss: 0.0021955237626498938\n",
      "loss: 0.002193266370422177\n",
      "loss: 0.0021910132943165563\n",
      "loss: 0.002188764522372756\n",
      "loss: 0.0021865200426737503\n",
      "loss: 0.0021842798433455877\n",
      "loss: 0.0021820439125571573\n",
      "loss: 0.0021798122385200784\n",
      "loss: 0.0021775848094884114\n",
      "loss: 0.0021753616137585455\n",
      "loss: 0.0021731426396689665\n",
      "loss: 0.0021709278756001293\n",
      "loss: 0.002168717309974137\n",
      "loss: 0.002166510931254762\n",
      "loss: 0.0021643087279470726\n",
      "loss: 0.0021621106885973567\n",
      "loss: 0.0021599168017929007\n",
      "loss: 0.0021577270561618424\n",
      "loss: 0.0021555414403729364\n",
      "loss: 0.002153359943135429\n",
      "loss: 0.002151182553198835\n",
      "loss: 0.0021490092593528347\n",
      "loss: 0.002146840050426955\n",
      "loss: 0.002144674915290588\n",
      "loss: 0.0021425138428526488\n",
      "loss: 0.0021403568220614783\n",
      "loss: 0.002138203841904689\n",
      "loss: 0.0021360548914089355\n",
      "loss: 0.002133909959639766\n",
      "loss: 0.0021317690357014964\n",
      "loss: 0.0021296321087369728\n",
      "loss: 0.0021274991679274694\n",
      "loss: 0.0021253702024924244\n",
      "loss: 0.002123245201689411\n",
      "loss: 0.0021211241548138348\n",
      "loss: 0.002119007051198887\n",
      "loss: 0.0021168938802152873\n",
      "loss: 0.0021147846312711423\n",
      "loss: 0.002112679293811855\n",
      "loss: 0.0021105778573198837\n",
      "loss: 0.0021084803113145954\n",
      "loss: 0.0021063866453521186\n",
      "loss: 0.0021042968490252063\n",
      "loss: 0.002102210911963027\n",
      "loss: 0.0021001288238310547\n",
      "loss: 0.0020980505743308834\n",
      "loss: 0.0020959761532000874\n",
      "loss: 0.0020939055502120674\n",
      "loss: 0.0020918387551758554\n",
      "loss: 0.00208977575793604\n",
      "loss: 0.0020877165483725534\n",
      "loss: 0.002085661116400543\n",
      "loss: 0.0020836094519701876\n",
      "loss: 0.002081561545066604\n",
      "loss: 0.0020795173857096412\n",
      "loss: 0.002077476963953799\n",
      "loss: 0.002075440269887977\n",
      "loss: 0.002073407293635442\n",
      "loss: 0.00207137802535364\n",
      "loss: 0.002069352455233986\n",
      "loss: 0.0020673305735017904\n",
      "loss: 0.0020653123704161293\n",
      "loss: 0.002063297836269636\n",
      "loss: 0.002061286961388398\n",
      "loss: 0.0020592797361318276\n",
      "loss: 0.002057276150892495\n",
      "loss: 0.0020552761960959693\n",
      "loss: 0.0020532798622007404\n",
      "loss: 0.0020512871396980176\n",
      "loss: 0.0020492980191116226\n",
      "loss: 0.0020473124909978664\n",
      "loss: 0.002045330545945365\n",
      "loss: 0.002043352174574938\n",
      "loss: 0.0020413773675394815\n",
      "loss: 0.0020394061155237938\n",
      "loss: 0.0020374384092444933\n",
      "loss: 0.002035474239449818\n",
      "loss: 0.002033513596919553\n",
      "loss: 0.0020315564724648835\n",
      "loss: 0.002029602856928235\n",
      "loss: 0.0020276527411831665\n",
      "loss: 0.002025706116134262\n",
      "loss: 0.0020237629727169527\n",
      "loss: 0.0020218233018973776\n",
      "loss: 0.0020198870946723665\n",
      "loss: 0.002017954342069164\n",
      "loss: 0.002016025035145392\n",
      "loss: 0.0020140991649889306\n",
      "loss: 0.002012176722717739\n",
      "loss: 0.0020102576994797377\n",
      "loss: 0.0020083420864527362\n",
      "loss: 0.0020064298748442644\n",
      "loss: 0.0020045210558914573\n",
      "loss: 0.002002615620860939\n",
      "loss: 0.0020007135610486844\n",
      "loss: 0.0019988148677799137\n",
      "loss: 0.0019969195324089613\n",
      "loss: 0.0019950275463191834\n",
      "loss: 0.001993138900922806\n",
      "loss: 0.0019912535876607995\n",
      "loss: 0.0019893715980027946\n",
      "loss: 0.001987492923446936\n",
      "loss: 0.00198561755551977\n",
      "loss: 0.001983745485776137\n",
      "loss: 0.001981876705799052\n",
      "loss: 0.0019800112071995998\n",
      "loss: 0.0019781489816168073\n",
      "loss: 0.001976290020717464\n",
      "loss: 0.0019744343161961636\n",
      "loss: 0.0019725818597750655\n",
      "loss: 0.001970732643203787\n",
      "loss: 0.0019688866582593324\n",
      "loss: 0.0019670438967460163\n",
      "loss: 0.0019652043504952378\n",
      "loss: 0.0019633680113654794\n",
      "loss: 0.0019615348712421214\n",
      "loss: 0.001959704922037404\n",
      "loss: 0.0019578781556902312\n",
      "loss: 0.001956054564166146\n",
      "loss: 0.0019542341394571676\n",
      "loss: 0.0019524168735817363\n",
      "loss: 0.0019506027585844748\n",
      "loss: 0.001948791786536305\n",
      "loss: 0.0019469839495341369\n",
      "loss: 0.0019451792397008698\n",
      "loss: 0.0019433776491852165\n",
      "loss: 0.001941579170161732\n",
      "loss: 0.0019397837948305057\n",
      "loss: 0.001937991515417251\n",
      "loss: 0.0019362023241730998\n",
      "loss: 0.0019344162133745136\n",
      "loss: 0.0019326331753231989\n",
      "loss: 0.0019308532023459817\n",
      "loss: 0.0019290762867947527\n",
      "[[0.01050157]\n",
      " [0.97527922]\n",
      " [0.97761927]\n",
      " [0.02658532]]\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetworkClassification:\n",
    "    def __init__(self, x, y):\n",
    "        self.input      = x\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],4) \n",
    "        self.weights2   = np.random.rand(4,1)                 \n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        \n",
    "        print('loss:', np.sum(np.power(self.y - self.output, 2)) )\n",
    "\n",
    "    def backprop(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, \n",
    "                            (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  \n",
    "                            (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), \n",
    "                                    self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "nn = NeuralNetworkClassification(X,y)\n",
    "\n",
    "for i in range(1500):\n",
    "    nn.feedforward()\n",
    "    nn.backprop()\n",
    "\n",
    "print(nn.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.21598802358951\n",
      "36.05626388745858\n",
      "28.752488756643334\n",
      "22.92858781314558\n",
      "18.284692199162617\n",
      "14.581696953757113\n",
      "11.628948069161298\n",
      "9.27442459391439\n",
      "7.396910196121693\n",
      "5.899751050283111\n",
      "4.705878601188056\n",
      "3.753840895064164\n",
      "2.9946381058067546\n",
      "2.3891992973109204\n",
      "1.9063704843111597\n",
      "1.5213103841898274\n",
      "1.214211246849686\n",
      "0.9692788901078078\n",
      "0.7739194162267158\n",
      "0.6180907285377348\n",
      "0.4937854537249309\n",
      "0.3946186422566049\n",
      "0.3154990151474423\n",
      "0.2523668275673025\n",
      "0.20198485033732388\n",
      "0.16177170573033017\n",
      "0.12966897508269434\n",
      "0.10403523484724084\n",
      "0.08356156443014569\n",
      "0.06720417486992021\n",
      "0.054130689073841075\n",
      "0.04367730732885279\n",
      "0.0353146523521226\n",
      "0.028620535107273214\n",
      "0.023258239002774725\n",
      "0.018959204261877454\n",
      "0.015509220842687818\n",
      "0.01273741896107695\n",
      "0.010507490332129346\n",
      "0.008710688116502083\n",
      "0.007260245151818269\n",
      "0.00608692308278695\n",
      "0.005135463238093242\n",
      "0.004361756536100788\n",
      "0.0037305867262210817\n",
      "0.00321383079507285\n",
      "0.0027890239065697106\n",
      "0.00243821501505073\n",
      "0.002147054257088352\n",
      "0.0019040651613919973\n",
      "0.00170006423180816\n",
      "0.0015276980458189457\n",
      "0.0013810740608762024\n",
      "0.0012554661449221825\n",
      "0.0011470796939596262\n",
      "0.0010528642666132845\n",
      "0.0009703641112217488\n",
      "0.0008975989110352661\n",
      "0.000832968628001702\n",
      "0.0007751775654561718\n",
      "0.0007231737586415024\n",
      "0.0006761005902780037\n",
      "0.0006332581569668829\n",
      "0.0005940724134165043\n",
      "0.0005580705211301263\n",
      "0.000524861146870948\n",
      "0.0004941187103260959\n",
      "0.00046557078301671576\n",
      "0.0004389880020715511\n",
      "0.0004141759913204353\n",
      "0.00039096888490047657\n",
      "0.0003692241304924552\n",
      "0.00034881831463415064\n",
      "0.00032964380465393903\n",
      "0.00031160604331245987\n",
      "0.00029462136537140155\n",
      "0.00027861523173027317\n",
      "0.0002635207978440894\n",
      "0.00024927774994138076\n",
      "0.00023583135596553094\n",
      "0.00022313168885516378\n",
      "0.00021113298830719194\n",
      "0.00019979313396997447\n",
      "0.00018907320844201614\n",
      "0.0001789371327826017\n",
      "0.00016935136069691592\n",
      "0.00016028462031603905\n",
      "0.0001517076946948547\n",
      "0.00014359323390798152\n",
      "0.000135915593028422\n",
      "0.0001286506913947678\n",
      "0.00012177588946905174\n",
      "0.00011526988030395942\n",
      "0.00010911259321091519\n",
      "0.0001032851076792118\n",
      "9.776957596369761e-05\n",
      "9.254915305256652e-05\n",
      "8.760793296318494e-05\n",
      "8.293089050309544e-05\n",
      "7.850382778616381e-05\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.network = []\n",
    "    def sequence(self, *args):\n",
    "        self.network = args\n",
    "        self.init_weight()\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "    def set_expect_output(self, output):\n",
    "        self.output = output\n",
    "    def dense(self, num_unit, activation=None):\n",
    "        def _dense(input, weight, bias):\n",
    "            return np.dot(input, weight) + bias\n",
    "        return {\n",
    "            'layer_function':_dense,\n",
    "            'num_unit': num_unit\n",
    "        }\n",
    "    def init_weight(self):\n",
    "        input_num = self.input.shape[1]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for layer in self.network:\n",
    "            output_num = layer['num_unit']\n",
    "            # weight\n",
    "            weight = np.random.rand(input_num, output_num)\n",
    "            self.weights.append(weight)\n",
    "            # bias\n",
    "            bias = np.random.rand(input_num, output_num)\n",
    "            self.biases.append(bias)\n",
    "            input_num = output_num\n",
    "    def feed_forward(self):\n",
    "        output_layer = self.input\n",
    "        for i, layer in enumerate(self.network):\n",
    "            output_layer = layer['layer_function'](output_layer, self.weights[i], self.biases[i])\n",
    "        return output_layer\n",
    "    def back_propagate(self, predict_output):\n",
    "        num_batch = predict_output.shape[0]\n",
    "        loss_derivative = -2*(self.output - predict_output) / num_batch\n",
    "        dw = np.dot(self.input.T, loss_derivative)\n",
    "        db = np.sum(loss_derivative)\n",
    "        self.weights[0] -= self.learning_rate*dw\n",
    "        self.biases[0] -= self.learning_rate*db       \n",
    "    def compile(self, learning_rate=0.08):\n",
    "        self.learning_rate = learning_rate\n",
    "        predict_output = self.feed_forward()\n",
    "        \n",
    "        loss = np.sum(np.square(predict_output - self.output)) / predict_output.shape[0]\n",
    "        self.back_propagate(predict_output)\n",
    "        return {\n",
    "            'predict_output': predict_output,\n",
    "            'loss': loss,\n",
    "        }\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "input = np.array([[1],\n",
    "                  [2],\n",
    "                  [3],\n",
    "                  [4],\n",
    "                  [5] ])\n",
    "output = input*2+1\n",
    "nn.set_input(input)\n",
    "nn.sequence(\n",
    "    nn.dense(1),\n",
    ")\n",
    "nn.set_expect_output(output)\n",
    "for i in range(100):\n",
    "    print(nn.compile()['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epinyoanun/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log10\n",
      "  \n",
      "/Users/epinyoanun/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log10\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120dfd630>]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,1, 100)\n",
    "y1 = np.log10(x)\n",
    "y2 = np.log10(1-x)\n",
    "plt.plot(x,y1)\n",
    "plt.plot(x,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot([[1,2],[3,4]], [[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4],\n",
       "       [ 9, 16]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[3,4]]) * np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
