{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw NN\n",
    "[https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6)\n",
    "\n",
    "cross entropy (loss) equation in np\n",
    "- [https://www.youtube.com/watch?v=DzE0eSdy5Hk&feature=youtu.be&t=1h3m8s&ab_channel=JeremyHoward](https://www.youtube.com/watch?v=DzE0eSdy5Hk&feature=youtu.be&t=1h3m8s&ab_channel=JeremyHoward)\n",
    "\n",
    "TODO\n",
    "- understand why using dot product\n",
    "  - is that the same as A*B np.dot(A',B)\n",
    "- L2 loss is minus???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class Layer(ABC):\n",
    "    @abstractmethod\n",
    "    def init_weights(self, num_input):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def feed_forward(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def back_prob(self):\n",
    "        pass\n",
    "    \n",
    "class Loss(ABC):\n",
    "    def __init__(self, expected_output, predict_output):\n",
    "        self.expected_output = expected_output\n",
    "        self.predict_output = predict_output\n",
    "    @abstractmethod\n",
    "    def get_loss(self):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def get_derivative_loss(self):\n",
    "        pass\n",
    "    \n",
    "class Activation(ABC):\n",
    "    @abstractmethod\n",
    "    def feed_forward(self, input):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def back_prob(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.00000001\n",
    "class Cross_entropy(Loss):\n",
    "    def __init__(self, expected_output, predict_output):\n",
    "        super().__init__(expected_output, predict_output)\n",
    "    def get_loss(self):\n",
    "        loss= np.mean( -(self.expected_output*np.log(self.predict_output) + \n",
    "                          (1-self.expected_output) * np.log(1-self.predict_output+EPSILON)))\n",
    "        return loss\n",
    "    def get_derivative_loss(self):\n",
    "        return (-(self.expected_output/ (self.predict_output+EPSILON)) + \n",
    "                (1-self.expected_output)/(1-self.predict_output-EPSILON))\n",
    "\n",
    "class L2(Loss):\n",
    "    def __init__(self, expected_output, predict_output):\n",
    "        super().__init__(expected_output, predict_output)\n",
    "    def get_loss(self):\n",
    "        return np.mean(np.square(self.predict_output - self.expected_output))\n",
    "    def get_derivative_loss(self):\n",
    "        return 2*(self.predict_output - self.expected_output)\n",
    "    \n",
    "class Sigmoid(Activation):\n",
    "    def feed_forward(self, input):\n",
    "        self.output = 1.0/(1+ np.exp(-input))\n",
    "        return self.output\n",
    "    def back_prob(self):\n",
    "        return self.output * (1.0 - self.output)\n",
    "    \n",
    "class Relu(Activation):\n",
    "    def feed_forward(self, input):\n",
    "        self.input= input\n",
    "        output = np.maximum(0, input)\n",
    "        return output\n",
    "    def back_prob(self):\n",
    "        return (self.input > 0) * 1\n",
    "\n",
    "class Dense(Layer):\n",
    "    def __init__(self, num_output, Activation_function):\n",
    "        self._num_output = num_output\n",
    "        self.activation_function = Activation_function()\n",
    "    def init_weights(self, num_input):\n",
    "        self._num_input = num_input\n",
    "        self._weights = np.random.rand(num_input, self._num_output)\n",
    "        self._bias = np.random.rand(1, self._num_output)\n",
    "    def feed_forward(self, input):\n",
    "        z = np.dot(input, self._weights) + self._bias\n",
    "        output = self.activation_function.feed_forward(z)\n",
    "        self._input = input\n",
    "        self._output = output\n",
    "        return output\n",
    "    def back_prob(self, last_derivative, learning_rate):\n",
    "        dz = last_derivative * self.activation_function.back_prob()\n",
    "\n",
    "        dw = np.dot(self._input.T, dz)/self._num_input\n",
    "        db = np.mean(dz)\n",
    "\n",
    "        current_derivative = np.dot(dz, self._weights.T) # X input\n",
    "        self._weights -= learning_rate*dw\n",
    "        self._bias -= learning_rate*db\n",
    "\n",
    "        return current_derivative\n",
    "    \n",
    "    @property\n",
    "    def num_output(self):\n",
    "        return self._num_output\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.network = []\n",
    "    def sequence(self, num_input_feature, *args):\n",
    "        self.network = args\n",
    "        num_input = num_input_feature\n",
    "        for i, layer in enumerate(self.network):\n",
    "            layer.init_weights(num_input)\n",
    "            num_input = layer.num_output\n",
    "    def compile(self, input, expected_output, Loss_function, learning_rate=0.1):\n",
    "        # feed forward\n",
    "        output_from_layer = input\n",
    "        for i, layer in enumerate(self.network):\n",
    "            output_from_layer = layer.feed_forward(output_from_layer)\n",
    "\n",
    "        # loss\n",
    "        loss_function = Loss_function(expected_output, output_from_layer)\n",
    "        \n",
    "        # back prop\n",
    "        derivative = loss_function.get_derivative_loss()\n",
    "        for i, layer in reversed(list(enumerate(self.network))):\n",
    "            derivative = layer.back_prob(derivative, learning_rate)\n",
    "        return {\n",
    "            'output_from_layer':output_from_layer, \n",
    "            'loss': loss_function.get_loss()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 17.989427531857952\n",
      "loss: 17.105788938895955\n",
      "loss: 1.977400939779963\n",
      "loss: 0.8998081066955276\n",
      "loss: 0.5198004669077607\n",
      "loss: 0.34518485530771587\n",
      "loss: 0.2486006259487966\n",
      "loss: 0.18908101205174557\n",
      "loss: 0.14965590385499697\n",
      "loss: 0.12211273529883533\n",
      "loss: 0.10205548898411353\n",
      "loss: 0.08695402782146844\n",
      "loss: 0.07526784174247471\n",
      "loss: 0.06601513583886856\n",
      "loss: 0.05854588605533037\n",
      "loss: 0.05241556021159015\n",
      "loss: 0.04731156036853008\n",
      "loss: 0.043008669178516146\n",
      "loss: 0.03934113496799784\n",
      "loss: 0.0361846550434436\n",
      "loss: 0.03344443822878653\n",
      "loss: 0.03104710822843781\n",
      "loss: 0.02893509570509872\n",
      "loss: 0.027062680006192618\n",
      "loss: 0.025393147044706653\n",
      "loss: 0.02389671658284088\n",
      "loss: 0.022549008984725456\n",
      "loss: 0.021329896151996177\n",
      "loss: 0.020222629994543575\n",
      "loss: 0.019213174052707255\n",
      "loss: 0.018289685645231955\n",
      "loss: 0.01744211081601033\n",
      "loss: 0.016661864699794245\n",
      "loss: 0.01594157720833495\n",
      "loss: 0.015274889125431228\n",
      "loss: 0.014656287437056876\n",
      "loss: 0.014080971445092379\n",
      "loss: 0.013544743216062622\n",
      "loss: 0.013043917403827977\n",
      "loss: 0.01257524659984972\n",
      "loss: 0.012135859206967319\n",
      "loss: 0.011723207474187225\n",
      "loss: 0.011335023822325846\n",
      "loss: 0.010969283970866928\n",
      "loss: 0.010624175672473913\n",
      "loss: 0.010298072093461614\n",
      "loss: 0.009989509061210222\n",
      "loss: 0.009697165544273755\n",
      "loss: 0.00941984684628926\n",
      "loss: 0.0091564700872111\n",
      "loss: 0.008906051619786071\n",
      "loss: 0.008667696089385087\n",
      "loss: 0.008440586894219674\n",
      "loss: 0.008223977842911418\n",
      "loss: 0.008017185839118117\n",
      "loss: 0.00781958444987284\n",
      "loss: 0.007630598236559408\n",
      "loss: 0.00744969774592093\n",
      "loss: 0.007276395073875414\n",
      "loss: 0.007110239927759662\n",
      "loss: 0.006950816123387921\n",
      "loss: 0.006797738462367522\n",
      "loss: 0.006650649942748716\n",
      "loss: 0.006509219262549662\n",
      "loss: 0.006373138581176221\n",
      "loss: 0.006242121508425199\n",
      "loss: 0.006115901294736075\n",
      "loss: 0.005994229199761203\n",
      "loss: 0.005876873019246965\n",
      "loss: 0.005763615752724207\n",
      "loss: 0.005654254396672254\n",
      "loss: 0.005548598849688558\n",
      "loss: 0.005446470917812355\n",
      "loss: 0.005347703409554676\n",
      "loss: 0.005252139311407627\n",
      "loss: 0.005159631035666189\n",
      "loss: 0.005070039733326975\n",
      "loss: 0.004983234665635437\n",
      "loss: 0.0048990926285689485\n",
      "loss: 0.00481749742516151\n",
      "loss: 0.004738339381130039\n",
      "loss: 0.004661514899742176\n",
      "loss: 0.004586926052293075\n",
      "loss: 0.004514480200935887\n",
      "loss: 0.0044440896509447565\n",
      "loss: 0.004375671329784616\n",
      "loss: 0.0043091464906235\n",
      "loss: 0.004244440438161244\n",
      "loss: 0.004181482274849603\n",
      "loss: 0.004120204665772701\n",
      "loss: 0.004060543620614414\n",
      "loss: 0.00400243829129396\n",
      "loss: 0.003945830783979823\n",
      "loss: 0.0038906659843134512\n",
      "loss: 0.003836891394778255\n",
      "loss: 0.0037844569832502987\n",
      "loss: 0.0037333150418470064\n",
      "loss: 0.0036834200552747693\n",
      "loss: 0.0036347285779408543\n",
      "loss: 0.0035871991191626803\n",
      "loss: 0.0035407920358625344\n",
      "loss: 0.0034954694321878495\n",
      "loss: 0.0034511950655459742\n",
      "loss: 0.0034079342585822485\n",
      "loss: 0.0033656538166714563\n",
      "loss: 0.003324321950525634\n",
      "loss: 0.0032839082035557537\n",
      "loss: 0.0032443833836513\n",
      "loss: 0.0032057194990697856\n",
      "loss: 0.003167889698152493\n",
      "loss: 0.003130868212604834\n",
      "loss: 0.0030946303040976955\n",
      "loss: 0.003059152213969151\n",
      "loss: 0.0030244111158181735\n",
      "loss: 0.0029903850708000628\n",
      "loss: 0.00295705298544678\n",
      "loss: 0.002924394571848839\n",
      "loss: 0.0028923903100465565\n",
      "loss: 0.0028610214124897533\n",
      "loss: 0.0028302697904360893\n",
      "loss: 0.002800118022165618\n",
      "loss: 0.0027705493228994613\n",
      "loss: 0.0027415475163174506\n",
      "loss: 0.0027130970075767424\n",
      "loss: 0.0026851827577420305\n",
      "loss: 0.002657790259539967\n",
      "loss: 0.0026309055143610605\n",
      "loss: 0.00260451501043537\n",
      "loss: 0.002578605702111059\n",
      "loss: 0.00255316499017439\n",
      "loss: 0.0025281807031487798\n",
      "loss: 0.002503641079518934\n",
      "loss: 0.002479534750825469\n",
      "loss: 0.002455850725582444\n",
      "loss: 0.0024325783739714206\n",
      "loss: 0.0024097074132684404\n",
      "loss: 0.002387227893964273\n",
      "loss: 0.002365130186539503\n",
      "loss: 0.00234340496885876\n",
      "loss: 0.002322043214152161\n",
      "loss: 0.0023010361795499914\n",
      "loss: 0.0022803753951439565\n",
      "loss: 0.0022600526535451887\n",
      "loss: 0.0022400599999146155\n",
      "loss: 0.002220389722439667\n",
      "loss: 0.002201034343235206\n",
      "loss: 0.0021819866096474687\n",
      "loss: 0.0021632394859382397\n",
      "loss: 0.0021447861453333284\n",
      "loss: 0.0021266199624144708\n",
      "loss: 0.0021087345058379632\n",
      "loss: 0.0020911235313654177\n",
      "loss: 0.0020737809751893875\n",
      "loss: 0.0020567009475405034\n",
      "loss: 0.0020398777265622325\n",
      "loss: 0.0020233057524402217\n",
      "loss: 0.002006979621774607\n",
      "loss: 0.001990894082182466\n",
      "loss: 0.0019750440271210303\n",
      "loss: 0.001959424490920645\n",
      "loss: 0.001944030644017298\n",
      "loss: 0.0019288577883759704\n",
      "loss: 0.0019139013530960506\n",
      "loss: 0.0018991568901901\n",
      "loss: 0.0018846200705282161\n",
      "loss: 0.0018702866799413902\n",
      "loss: 0.0018561526154744503\n",
      "loss: 0.0018422138817848926\n",
      "loss: 0.0018284665876785206\n",
      "loss: 0.0018149069427776485\n",
      "loss: 0.0018015312543146885\n",
      "loss: 0.0017883359240469826\n",
      "loss: 0.0017753174452869453\n",
      "loss: 0.0017624724000413615\n",
      "loss: 0.0017497974562583655\n",
      "loss: 0.0017372893651738468\n",
      "loss: 0.0017249449587554623\n",
      "loss: 0.0017127611472394547\n",
      "loss: 0.0017007349167560257\n",
      "loss: 0.0016888633270406767\n",
      "loss: 0.001677143509225938\n",
      "loss: 0.0016655726637131308\n",
      "loss: 0.0016541480581172476\n",
      "loss: 0.0016428670252861476\n",
      "loss: 0.001631726961386836\n",
      "loss: 0.0016207253240592375\n",
      "loss: 0.0016098596306338981\n",
      "loss: 0.0015991274564097137\n",
      "loss: 0.0015885264329918722\n",
      "loss: 0.001578054246684798\n",
      "loss: 0.0015677086369406145\n",
      "loss: 0.001557487394858901\n",
      "loss: 0.0015473883617368469\n",
      "loss: 0.0015374094276675466\n",
      "loss: 0.0015275485301847848\n",
      "loss: 0.001517803652951944\n",
      "loss: 0.0015081728244943674\n",
      "loss: 0.0014986541169725017\n",
      "loss: 0.0014892456449951338\n",
      "loss: 0.0014799455644701682\n",
      "loss: 0.0014707520714937036\n",
      "loss: 0.0014616634012721878\n",
      "loss: 0.001452677827081521\n",
      "loss: 0.0014437936592563302\n",
      "loss: 0.0014350092442131834\n",
      "loss: 0.0014263229635027345\n",
      "loss: 0.0014177332328924592\n",
      "loss: 0.0014092385014768684\n",
      "loss: 0.0014008372508158532\n",
      "loss: 0.0013925279940990522\n",
      "loss: 0.0013843092753354491\n",
      "loss: 0.0013761796685683168\n",
      "loss: 0.0013681377771128254\n",
      "loss: 0.0013601822328176535\n",
      "loss: 0.001352311695348033\n",
      "loss: 0.0013445248514897862\n",
      "loss: 0.0013368204144750106\n",
      "loss: 0.0013291971233268627\n",
      "loss: 0.0013216537422237557\n",
      "loss: 0.0013141890598819814\n",
      "loss: 0.0013068018889567442\n",
      "loss: 0.0012994910654600502\n",
      "loss: 0.0012922554481954525\n",
      "loss: 0.0012850939182094223\n",
      "loss: 0.0012780053782576746\n",
      "loss: 0.0012709887522869018\n",
      "loss: 0.0012640429849321182\n",
      "loss: 0.001257167041026183\n",
      "loss: 0.0012503599051251577\n",
      "loss: 0.001243620581045274\n",
      "loss: 0.001236948091414073\n",
      "loss: 0.0012303414772328123\n",
      "loss: 0.0012237997974517058\n",
      "loss: 0.001217322128556542\n",
      "loss: 0.001210907564166577\n",
      "loss: 0.001204555214643354\n",
      "loss: 0.0011982642067101257\n",
      "loss: 0.00119203368308143\n",
      "loss: 0.001185862802103147\n",
      "loss: 0.001179750737401153\n",
      "loss: 0.0011736966775403453\n",
      "loss: 0.0011676998256918093\n",
      "loss: 0.0011617593993096926\n",
      "loss: 0.0011558746298158849\n",
      "loss: 0.0011500447622930703\n",
      "loss: 0.0011442690551858\n",
      "loss: 0.0011385467800097155\n",
      "loss: 0.001132877221067573\n",
      "loss: 0.0011272596751730742\n",
      "loss: 0.0011216934513815044\n",
      "loss: 0.0011161778707274997\n",
      "loss: 0.0011107122659697378\n",
      "loss: 0.0011052959813407578\n",
      "loss: 0.001099928372304913\n",
      "loss: 0.0010946088053210184\n",
      "loss: 0.0010893366576119016\n",
      "loss: 0.0010841113169386472\n",
      "loss: 0.001078932181381413\n",
      "loss: 0.0010737986591251565\n",
      "loss: 0.001068710168250823\n",
      "loss: 0.0010636661365316616\n",
      "loss: 0.0010586660012338964\n",
      "loss: 0.0010537092089236335\n",
      "loss: 0.0010487952152770058\n",
      "loss: 0.0010439234848954458\n",
      "loss: 0.0010390934911258653\n",
      "loss: 0.0010343047158846202\n",
      "loss: 0.0010295566494852742\n",
      "loss: 0.0010248487904718202\n",
      "loss: 0.0010201806454541301\n",
      "loss: 0.0010155517289488715\n",
      "loss: 0.0010109615632227628\n",
      "loss: 0.0010064096781410659\n",
      "loss: 0.0010018956110175359\n",
      "loss: 0.0009974189064703774\n",
      "loss: 0.0009929791162789933\n",
      "loss: 0.0009885757992461905\n",
      "loss: 0.0009842085210619437\n",
      "loss: 0.000979876854171287\n",
      "loss: 0.0009755803776449937\n",
      "loss: 0.0009713186770527008\n",
      "loss: 0.0009670913443397193\n",
      "loss: 0.0009628979777056252\n",
      "loss: 0.0009587381814868606\n",
      "loss: 0.0009546115660406758\n",
      "loss: 0.0009505177476326346\n",
      "loss: 0.000946456348325906\n",
      "loss: 0.0009424269958735618\n",
      "loss: 0.000938429323613105\n",
      "loss: 0.0009344629703628934\n",
      "loss: 0.0009305275803213469\n",
      "loss: 0.0009266228029683846\n",
      "loss: 0.0009227482929687573\n",
      "loss: 0.0009189037100771621\n",
      "loss: 0.0009150887190463662\n",
      "loss: 0.0009113029895363323\n",
      "loss: 0.0009075461960256858\n",
      "loss: 0.0009038180177254093\n",
      "loss: 0.0009001181384938748\n",
      "loss: 0.0008964462467537695\n",
      "loss: 0.0008928020354108074\n",
      "loss: 0.0008891852017747732\n",
      "loss: 0.0008855954474809112\n",
      "loss: 0.0008820324784144244\n",
      "loss: 0.0008784960046353138\n",
      "loss: 0.0008749857403058865\n",
      "loss: 0.0008715014036184946\n",
      "loss: 0.0008680427167262729\n",
      "loss: 0.0008646094056741052\n",
      "loss: 0.0008612012003312616\n",
      "loss: 0.0008578178343260388\n",
      "loss: 0.0008544590449809579\n",
      "loss: 0.0008511245732497464\n",
      "loss: 0.0008478141636555441\n",
      "loss: 0.000844527564229667\n",
      "loss: 0.000841264526453377\n",
      "loss: 0.0008380248051983179\n",
      "loss: 0.0008348081586706247\n",
      "loss: 0.0008316143483541437\n",
      "loss: 0.0008284431389564349\n",
      "loss: 0.0008252942983541112\n",
      "loss: 0.0008221675975414001\n",
      "loss: 0.0008190628105772657\n",
      "loss: 0.0008159797145357546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0008129180894560102\n",
      "loss: 0.0008098777182937365\n",
      "loss: 0.0008068583868735493\n",
      "loss: 0.0008038598838418875\n",
      "loss: 0.0008008820006217052\n",
      "loss: 0.000797924531367163\n",
      "loss: 0.0007949872729195475\n",
      "loss: 0.0007920700247640767\n",
      "loss: 0.0007891725889874908\n",
      "loss: 0.0007862947702363072\n",
      "loss: 0.00078343637567619\n",
      "loss: 0.0007805972149516556\n",
      "loss: 0.0007777771001470005\n",
      "loss: 0.0007749758457475653\n",
      "loss: 0.0007721932686021113\n",
      "loss: 0.000769429187885421\n",
      "loss: 0.0007666834250618992\n",
      "loss: 0.0007639558038500666\n",
      "loss: 0.0007612461501872743\n",
      "loss: 0.0007585542921953123\n",
      "loss: 0.0007558800601464593\n",
      "loss: 0.0007532232864304274\n",
      "loss: 0.0007505838055219715\n",
      "loss: 0.0007479614539485015\n",
      "loss: 0.0007453560702589177\n",
      "loss: 0.0007427674949925585\n",
      "loss: 0.0007401955706494827\n",
      "loss: 0.0007376401416600862\n",
      "loss: 0.0007351010543561648\n",
      "loss: 0.0007325781569425322\n",
      "loss: 0.0007300712994681976\n",
      "loss: 0.0007275803337996517\n",
      "loss: 0.0007251051135926014\n",
      "loss: 0.0007226454942662591\n",
      "loss: 0.0007202013329766333\n",
      "loss: 0.0007177724885909329\n",
      "loss: 0.0007153588216620814\n",
      "loss: 0.0007129601944044546\n",
      "loss: 0.0007105764706686207\n",
      "loss: 0.0007082075159179693\n",
      "loss: 0.0007058531972048949\n",
      "loss: 0.0007035133831479851\n",
      "loss: 0.0007011879439086513\n",
      "loss: 0.0006988767511693151\n",
      "loss: 0.000696579678111154\n",
      "loss: 0.0006942965993925126\n",
      "loss: 0.0006920273911279799\n",
      "loss: 0.0006897719308670262\n",
      "loss: 0.0006875300975737492\n",
      "loss: 0.000685301771606955\n",
      "loss: 0.0006830868346996839\n",
      "loss: 0.0006808851699405149\n",
      "loss: 0.0006786966617536488\n",
      "loss: 0.0006765211958807694\n",
      "loss: 0.0006743586593619051\n",
      "loss: 0.000672208940517736\n",
      "loss: 0.0006700719289312343\n",
      "loss: 0.0006679475154303061\n",
      "loss: 0.000665835592070655\n",
      "loss: 0.0006637360521180925\n",
      "loss: 0.0006616487900325114\n",
      "loss: 0.0006595737014511994\n",
      "loss: 0.0006575106831722584\n",
      "loss: 0.0006554596331391383\n",
      "loss: 0.0006534204504247272\n",
      "loss: 0.0006513930352158844\n",
      "loss: 0.0006493772887985317\n",
      "loss: 0.0006473731135422986\n",
      "loss: 0.0006453804128861704\n",
      "loss: 0.0006433990913239112\n",
      "loss: 0.0006414290543900462\n",
      "loss: 0.0006394702086455095\n",
      "loss: 0.0006375224616639584\n",
      "loss: 0.0006355857220185329\n",
      "loss: 0.000633659899268284\n",
      "loss: 0.0006317449039448219\n",
      "loss: 0.0006298406475400768\n",
      "loss: 0.0006279470424928386\n",
      "loss: 0.0006260640021766296\n",
      "loss: 0.0006241914408873541\n",
      "loss: 0.0006223292738312846\n",
      "loss: 0.0006204774171127119\n",
      "loss: 0.0006186357877228195\n",
      "loss: 0.0006168043035274468\n",
      "loss: 0.0006149828832564083\n",
      "loss: 0.0006131714464915904\n",
      "loss: 0.0006113699136564929\n",
      "loss: 0.000609578206004883\n",
      "loss: 0.0006077962456104485\n",
      "loss: 0.0006060239553561176\n",
      "loss: 0.0006042612589239354\n",
      "loss: 0.0006025080807840528\n",
      "loss: 0.0006007643461859341\n",
      "loss: 0.0005990299811471249\n",
      "loss: 0.000597304912444573\n",
      "loss: 0.0005955890676042835\n",
      "loss: 0.0005938823748921962\n",
      "loss: 0.0005921847633048428\n",
      "loss: 0.0005904961625601115\n",
      "loss: 0.0005888165030880162\n",
      "loss: 0.0005871457160223515\n",
      "loss: 0.0005854837331910175\n",
      "loss: 0.0005838304871083409\n",
      "loss: 0.0005821859109659559\n",
      "loss: 0.0005805499386242386\n",
      "loss: 0.0005789225046048529\n",
      "loss: 0.0005773035440816306\n",
      "loss: 0.0005756929928733393\n",
      "loss: 0.0005740907874352306\n",
      "loss: 0.000572496864851363\n",
      "loss: 0.0005709111628272616\n",
      "loss: 0.0005693336196819089\n",
      "loss: 0.000567764174340403\n",
      "loss: 0.0005662027663268396\n",
      "loss: 0.0005646493357566364\n",
      "loss: 0.0005631038233297484\n",
      "loss: 0.0005615661703234369\n",
      "loss: 0.0005600363185854859\n",
      "loss: 0.0005585142105271932\n",
      "loss: 0.0005569997891166983\n",
      "loss: 0.0005554929978724181\n",
      "loss: 0.000553993780856375\n",
      "loss: 0.0005525020826676323\n",
      "loss: 0.0005510178484361797\n",
      "loss: 0.000549541023816479\n",
      "loss: 0.0005480715549814607\n",
      "loss: 0.0005466093886160706\n",
      "loss: 0.0005451544719117101\n",
      "loss: 0.0005437067525597851\n",
      "loss: 0.0005422661787463665\n",
      "loss: 0.0005408326991460734\n",
      "loss: 0.0005394062629164008\n",
      "loss: 0.0005379868196923808\n",
      "loss: 0.0005365743195806883\n",
      "loss: 0.000535168713154413\n",
      "loss: 0.0005337699514474987\n",
      "loss: 0.0005323779859498492\n",
      "loss: 0.0005309927686015461\n",
      "loss: 0.0005296142517880652\n",
      "loss: 0.0005282423883348268\n",
      "loss: 0.000526877131502637\n",
      "loss: 0.000525518434982237\n",
      "loss: 0.0005241662528900763\n",
      "loss: 0.0005228205397625317\n",
      "loss: 0.0005214812505521232\n",
      "loss: 0.0005201483406220668\n",
      "loss: 0.0005188217657423802\n",
      "loss: 0.0005175014820843239\n",
      "loss: 0.0005161874462169517\n",
      "loss: 0.0005148796151018847\n",
      "loss: 0.000513577946089419\n",
      "loss: 0.0005122823969137434\n",
      "loss: 0.0005109929256891574\n",
      "loss: 0.0005097094909054021\n",
      "loss: 0.000508432051423877\n",
      "loss: 0.0005071605664731933\n",
      "loss: 0.0005058949956453914\n",
      "loss: 0.0005046352988918274\n",
      "loss: 0.0005033814365191685\n",
      "loss: 0.0005021333691856126\n",
      "loss: 0.000500891057896996\n",
      "loss: 0.0004996544640031229\n",
      "loss: 0.0004984235491935409\n",
      "loss: 0.0004971982754946477\n",
      "loss: 0.0004959786052653561\n",
      "loss: 0.0004947645011935336\n",
      "loss: 0.0004935559262931123\n",
      "loss: 0.0004923528438996409\n",
      "loss: 0.0004911552176677252\n",
      "loss: 0.000489963011566805\n",
      "loss: 0.0004887761898782602\n",
      "loss: 0.00048759471719207655\n",
      "loss: 0.00048641855840328674\n",
      "loss: 0.00048524767870896724\n",
      "loss: 0.00048408204360479213\n",
      "loss: 0.00048292161888225207\n",
      "loss: 0.0004817663706252077\n",
      "loss: 0.0004806162652065538\n",
      "loss: 0.00047947126928588323\n",
      "loss: 0.00047833134980604044\n",
      "loss: 0.0004771964739898969\n",
      "loss: 0.00047606660933801546\n",
      "loss: 0.00047494172362531407\n",
      "loss: 0.00047382178489828713\n",
      "loss: 0.0004727067614723353\n",
      "loss: 0.0004715966219288749\n",
      "loss: 0.0004704913351123365\n",
      "loss: 0.0004693908701278286\n",
      "loss: 0.00046829519633824685\n",
      "loss: 0.00046720428336171683\n",
      "loss: 0.0004661181010689254\n",
      "loss: 0.0004650366195802292\n",
      "loss: 0.00046395980926365344\n",
      "loss: 0.0004628876407320015\n",
      "loss: 0.0004618200848402962\n",
      "loss: 0.00046075711268377904\n",
      "loss: 0.00045969869559468626\n",
      "loss: 0.00045864480514057945\n",
      "loss: 0.00045759541312156716\n",
      "loss: 0.00045655049156808047\n",
      "loss: 0.00045551001273864874\n",
      "loss: 0.0004544739491173433\n",
      "loss: 0.00045344227341144195\n",
      "loss: 0.0004524149585498716\n",
      "loss: 0.0004513919776800964\n",
      "loss: 0.00045037330416667064\n",
      "loss: 0.0004493589115884607\n",
      "loss: 0.000448348773736865\n",
      "loss: 0.00044734286461381266\n",
      "loss: 0.00044634115842931773\n",
      "loss: 0.0004453436295998113\n",
      "loss: 0.00044435025274558416\n",
      "loss: 0.000443361002689341\n",
      "loss: 0.00044237585445375575\n",
      "loss: 0.0004413947832600238\n",
      "loss: 0.00044041776452519567\n",
      "loss: 0.00043944477386095306\n",
      "loss: 0.00043847578707127406\n",
      "loss: 0.0004375107801506544\n",
      "loss: 0.00043654972928255047\n",
      "loss: 0.00043559261083693404\n",
      "loss: 0.00043463940136917906\n",
      "loss: 0.00043369007761772874\n",
      "loss: 0.00043274461650242636\n",
      "loss: 0.0004318029951230703\n",
      "loss: 0.00043086519075752393\n",
      "loss: 0.00042993118085982564\n",
      "loss: 0.00042900094305852154\n",
      "loss: 0.0004280744551553303\n",
      "loss: 0.00042715169512303147\n",
      "loss: 0.0004262326411044645\n",
      "loss: 0.0004253172714099725\n",
      "loss: 0.00042440556451684466\n",
      "loss: 0.00042349749906698284\n",
      "loss: 0.00042259305386545634\n",
      "loss: 0.00042169220787950033\n",
      "loss: 0.0004207949402362928\n",
      "loss: 0.000419901230221843\n",
      "loss: 0.0004190110572792127\n",
      "loss: 0.0004181244010076255\n",
      "loss: 0.0004172412411602456\n",
      "loss: 0.0004163615576432859\n",
      "loss: 0.0004154853305143424\n",
      "loss: 0.00041461253998094756\n",
      "loss: 0.0004137431663994591\n",
      "loss: 0.0004128771902732817\n",
      "loss: 0.00041201459225186516\n",
      "loss: 0.000411155353129149\n",
      "loss: 0.00041029945384222827\n",
      "loss: 0.0004094468754700192\n",
      "loss: 0.00040859759923225823\n",
      "loss: 0.00040775160648783557\n",
      "loss: 0.0004069088787334603\n",
      "loss: 0.0004060693976028821\n",
      "loss: 0.00040523314486522394\n",
      "loss: 0.0004044001024238706\n",
      "loss: 0.0004035702523152452\n",
      "loss: 0.0004027435767075869\n",
      "loss: 0.00040192005789983884\n",
      "loss: 0.00040109967832031423\n",
      "loss: 0.00040028242052569544\n",
      "loss: 0.0003994682671995898\n",
      "loss: 0.00039865720115197254\n",
      "loss: 0.00039784920531718646\n",
      "loss: 0.0003970442627536083\n",
      "loss: 0.00039624235664220355\n",
      "loss: 0.00039544347028541477\n",
      "loss: 0.00039464758710604957\n",
      "loss: 0.00039385469064639203\n",
      "loss: 0.0003930647645669789\n",
      "loss: 0.000392277792645489\n",
      "loss: 0.00039149375877607515\n",
      "loss: 0.0003907126469678085\n",
      "loss: 0.0003899344413439006\n",
      "loss: 0.00038915912614092445\n",
      "loss: 0.0003883866857075919\n",
      "loss: 0.0003876171045035317\n",
      "loss: 0.0003868503670988434\n",
      "loss: 0.00038608645817276454\n",
      "loss: 0.0003853253625125589\n",
      "loss: 0.00038456706501329314\n",
      "loss: 0.0003838115506760595\n",
      "loss: 0.0003830588046074192\n",
      "loss: 0.00038230881201873555\n",
      "loss: 0.0003815615582247292\n",
      "loss: 0.00038081702864303275\n",
      "loss: 0.00038007520879308044\n",
      "loss: 0.0003793360842952171\n",
      "loss: 0.00037859964087003274\n",
      "loss: 0.00037786586433725\n",
      "loss: 0.0003771347406149464\n",
      "loss: 0.00037640625571877615\n",
      "loss: 0.00037568039576119187\n",
      "loss: 0.0003749571469504446\n",
      "loss: 0.00037423649558991596\n",
      "loss: 0.0003735184280770078\n",
      "loss: 0.00037280293090291865\n",
      "loss: 0.0003720899906513106\n",
      "loss: 0.00037137959399764206\n",
      "loss: 0.000370671727708612\n",
      "loss: 0.0003699663786411595\n",
      "loss: 0.00036926353374190787\n",
      "loss: 0.0003685631800461647\n",
      "loss: 0.00036786530467725417\n",
      "loss: 0.0003671698948459618\n",
      "loss: 0.00036647693784953395\n",
      "loss: 0.00036578642107123295\n",
      "loss: 0.00036509833197933704\n",
      "loss: 0.00036441265812658426\n",
      "loss: 0.00036372938714939476\n",
      "loss: 0.0003630485067674256\n",
      "loss: 0.00036237000478234855\n",
      "loss: 0.00036169386907784984\n",
      "loss: 0.00036102008761829644\n",
      "loss: 0.00036034864844862474\n",
      "loss: 0.00035967953969334027\n",
      "loss: 0.00035901274955585073\n",
      "loss: 0.00035834826631791025\n",
      "loss: 0.00035768607833928587\n",
      "loss: 0.0003570261740563127\n",
      "loss: 0.00035636854198222714\n",
      "loss: 0.0003557131707057222\n",
      "loss: 0.0003550600488909469\n",
      "loss: 0.00035440916527650686\n",
      "loss: 0.0003537605086749076\n",
      "loss: 0.0003531140679723326\n",
      "loss: 0.00035246983212730993\n",
      "loss: 0.0003518277901708224\n",
      "loss: 0.0003511879312055305\n",
      "loss: 0.0003505502444049935\n",
      "loss: 0.00034991471901300376\n",
      "loss: 0.0003492813443438069\n",
      "loss: 0.0003486501097803262\n",
      "loss: 0.00034802100477482686\n",
      "loss: 0.00034739401884736166\n",
      "loss: 0.00034676914158599236\n",
      "loss: 0.0003461463626455677\n",
      "loss: 0.0003455256717478339\n",
      "loss: 0.0003449070586805458\n",
      "loss: 0.0003442905132968001\n",
      "loss: 0.0003436760255149238\n",
      "loss: 0.0003430635853175856\n",
      "loss: 0.0003424531827517951\n",
      "loss: 0.00034184480792768103\n",
      "loss: 0.0003412384510183796\n",
      "loss: 0.00034063410225981203\n",
      "loss: 0.00034003175194968494\n",
      "loss: 0.00033943139044715617\n",
      "loss: 0.0003388330081726129\n",
      "loss: 0.00033823659560689335\n",
      "loss: 0.0003376421432909538\n",
      "loss: 0.00033704964182520124\n",
      "loss: 0.00033645908186949333\n",
      "loss: 0.00033587045414213866\n",
      "loss: 0.00033528374941967396\n",
      "loss: 0.00033469895853664196\n",
      "loss: 0.0003341160723847021\n",
      "loss: 0.0003335350819124085\n",
      "loss: 0.00033295597812487614\n",
      "loss: 0.0003323787520832259\n",
      "loss: 0.0003318033949040278\n",
      "loss: 0.00033122989775919055\n",
      "loss: 0.00033065825187518337\n",
      "loss: 0.0003300884485328139\n",
      "loss: 0.00032952047906700544\n",
      "loss: 0.00032895433486590785\n",
      "loss: 0.0003283900073707875\n",
      "loss: 0.00032782748807569194\n",
      "loss: 0.0003272667685268959\n",
      "loss: 0.00032670784032245596\n",
      "loss: 0.0003261506951120992\n",
      "loss: 0.0003255953245963347\n",
      "loss: 0.00032504172052678644\n",
      "loss: 0.0003244898747049708\n",
      "loss: 0.00032393977898263055\n",
      "loss: 0.00032339142526106694\n",
      "loss: 0.00032284480549058523\n",
      "loss: 0.00032229991167049367\n",
      "loss: 0.0003217567358484371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000321215270120175\n",
      "loss: 0.00032067550662924716\n",
      "loss: 0.00032013743756664125\n",
      "loss: 0.0003196010551701254\n",
      "loss: 0.0003190663517243592\n",
      "loss: 0.0003185333195602276\n",
      "loss: 0.000318001951054618\n",
      "loss: 0.00031747223863019775\n",
      "loss: 0.0003169441747545263\n",
      "loss: 0.00031641775194060905\n",
      "loss: 0.00031589296274589865\n",
      "loss: 0.00031536979977196114\n",
      "loss: 0.00031484825566469764\n",
      "loss: 0.0003143283231133448\n",
      "loss: 0.00031380999485069696\n",
      "loss: 0.00031329326365255007\n",
      "loss: 0.00031277812233714686\n",
      "loss: 0.00031226456376550875\n",
      "loss: 0.0003117525808404374\n",
      "loss: 0.00031124216650651353\n",
      "loss: 0.00031073331375009713\n",
      "loss: 0.00031022601559843854\n",
      "loss: 0.00030972026511967863\n",
      "loss: 0.00030921605542251485\n",
      "loss: 0.0003087133796562018\n",
      "loss: 0.0003082122310095505\n",
      "loss: 0.0003077126027113734\n",
      "loss: 0.00030721448802981723\n",
      "loss: 0.00030671788027225203\n",
      "loss: 0.00030622277278460425\n",
      "loss: 0.0003057291589516902\n",
      "loss: 0.0003052370321964382\n",
      "loss: 0.00030474638597977744\n",
      "loss: 0.0003042572138007485\n",
      "loss: 0.000303769509195171\n",
      "loss: 0.00030328326573686486\n",
      "loss: 0.00030279847703598397\n",
      "loss: 0.0003023151367395716\n",
      "loss: 0.00030183323853122705\n",
      "loss: 0.0003013527761305503\n",
      "loss: 0.00030087374329303005\n",
      "loss: 0.00030039613381004467\n",
      "loss: 0.0002999199415079725\n",
      "loss: 0.00029944516024874804\n",
      "loss: 0.0002989717839290833\n",
      "loss: 0.000298499806480024\n",
      "loss: 0.00029802922186761586\n",
      "loss: 0.00029756002409157134\n",
      "loss: 0.0002970922071859364\n",
      "loss: 0.0002966257652179789\n",
      "loss: 0.0002961606922889667\n",
      "loss: 0.0002956969825329454\n",
      "loss: 0.00029523463011718257\n",
      "loss: 0.0002947736292417233\n",
      "loss: 0.0002943139741391682\n",
      "loss: 0.0002938556590742284\n",
      "loss: 0.0002933986783438372\n",
      "loss: 0.0002929430262769275\n",
      "loss: 0.00029248869723387603\n",
      "loss: 0.0002920356856065037\n",
      "loss: 0.00029158398581796425\n",
      "loss: 0.00029113359232241096\n",
      "loss: 0.00029068449960455205\n",
      "loss: 0.00029023670217998406\n",
      "loss: 0.00028979019459441426\n",
      "loss: 0.0002893449714238823\n",
      "loss: 0.0002889010272742049\n",
      "loss: 0.0002884583567810875\n",
      "loss: 0.00028801695460967857\n",
      "loss: 0.0002875768154545707\n",
      "loss: 0.0002871379340393556\n",
      "loss: 0.0002867003051168462\n",
      "loss: 0.0002862639234680772\n",
      "loss: 0.00028582878390319297\n",
      "loss: 0.0002853948812604487\n",
      "loss: 0.00028496221040620915\n",
      "loss: 0.00028453076623483883\n",
      "loss: 0.0002841005436687005\n",
      "loss: 0.0002836715376573787\n",
      "loss: 0.0002832437431782344\n",
      "loss: 0.00028281715523562767\n",
      "loss: 0.00028239176886113974\n",
      "loss: 0.0002819675791130173\n",
      "loss: 0.0002815445810762837\n",
      "loss: 0.0002811227698626277\n",
      "loss: 0.0002807021406097373\n",
      "loss: 0.0002802826884817432\n",
      "loss: 0.00027986440866877526\n",
      "loss: 0.0002794472963865173\n",
      "loss: 0.0002790313468764302\n",
      "loss: 0.00027861655540541754\n",
      "loss: 0.0002782029172658261\n",
      "loss: 0.0002777904277748903\n",
      "loss: 0.0002773790822750657\n",
      "loss: 0.0002769688761333617\n",
      "loss: 0.00027655980474167516\n",
      "loss: 0.00027615186351601307\n",
      "loss: 0.0002757450478971583\n",
      "loss: 0.0002753393533497815\n",
      "loss: 0.00027493477536244066\n",
      "loss: 0.0002745313094479145\n",
      "loss: 0.0002741289511422026\n",
      "loss: 0.0002737276960051919\n",
      "loss: 0.00027332753961998993\n",
      "loss: 0.0002729284775929248\n",
      "loss: 0.00027253050555343467\n",
      "loss: 0.00027213361915395557\n",
      "loss: 0.000271737814069478\n",
      "loss: 0.0002713430859978794\n",
      "loss: 0.00027094943065925813\n",
      "loss: 0.00027055684379626623\n",
      "loss: 0.00027016532117355417\n",
      "loss: 0.00026977485857810436\n",
      "loss: 0.00026938545181856376\n",
      "loss: 0.0002689970967252448\n",
      "loss: 0.0002686097891503469\n",
      "loss: 0.0002682235249675122\n",
      "loss: 0.0002678383000716033\n",
      "loss: 0.0002674541103788149\n",
      "loss: 0.00026707095182622824\n",
      "loss: 0.00026668882037214533\n",
      "loss: 0.000266307711995311\n",
      "loss: 0.0002659276226955791\n",
      "loss: 0.0002655485484931354\n",
      "loss: 0.00026517048542838603\n",
      "loss: 0.00026479342956229056\n",
      "loss: 0.0002644173769759186\n",
      "loss: 0.00026404232377022594\n",
      "loss: 0.0002636682660662784\n",
      "loss: 0.0002632952000048063\n",
      "loss: 0.00026292312174609376\n",
      "loss: 0.0002625520274699787\n",
      "loss: 0.0002621819133759637\n",
      "loss: 0.00026181277568254965\n",
      "loss: 0.00026144461062745756\n",
      "loss: 0.00026107741446740714\n",
      "loss: 0.00026071118347833745\n",
      "loss: 0.0002603459139545201\n",
      "loss: 0.0002599816022092242\n",
      "loss: 0.0002596182445742725\n",
      "loss: 0.00025925583739970845\n",
      "loss: 0.00025889437705435087\n",
      "loss: 0.00025853385992479476\n",
      "loss: 0.00025817428241596676\n",
      "loss: 0.00025781564095067984\n",
      "loss: 0.0002574579319698567\n",
      "loss: 0.00025710115193186225\n",
      "loss: 0.0002567452973130597\n",
      "loss: 0.0002563903646071436\n",
      "loss: 0.0002560363503253618\n",
      "loss: 0.0002556832509962937\n",
      "loss: 0.0002553310631656282\n",
      "loss: 0.00025497978339638505\n",
      "loss: 0.0002546294082684713\n",
      "loss: 0.0002542799343787918\n",
      "loss: 0.00025393135834102725\n",
      "loss: 0.000253583676785412\n",
      "loss: 0.0002532368863591784\n",
      "loss: 0.00025289098372566785\n",
      "loss: 0.00025254596556499766\n",
      "loss: 0.0002522018285731719\n",
      "loss: 0.0002518585694627484\n",
      "loss: 0.0002515161849622826\n",
      "loss: 0.00025117467181621724\n",
      "loss: 0.0002508340267852153\n",
      "loss: 0.0002504942466454928\n",
      "loss: 0.00025015532818915316\n",
      "loss: 0.00024981726822374215\n",
      "loss: 0.0002494800635723589\n",
      "loss: 0.0002491437110738782\n",
      "loss: 0.00024880820758217334\n",
      "loss: 0.0002484735499664483\n",
      "loss: 0.00024813973511112787\n",
      "loss: 0.0002478067599157454\n",
      "loss: 0.0002474746212947212\n",
      "loss: 0.000247143316177363\n",
      "loss: 0.00024681284150786465\n",
      "loss: 0.0002464831942451961\n",
      "loss: 0.00024615437136276975\n",
      "loss: 0.0002458263698486625\n",
      "loss: 0.00024549918670528284\n",
      "loss: 0.00024517281894970334\n",
      "loss: 0.00024484726361288404\n",
      "loss: 0.0002445225177403382\n",
      "loss: 0.00024419857839146596\n",
      "loss: 0.00024387544263988759\n",
      "loss: 0.00024355310757288816\n",
      "loss: 0.00024323157029186175\n",
      "loss: 0.00024291082791197803\n",
      "loss: 0.00024259087756196057\n",
      "loss: 0.00024227171638430825\n",
      "loss: 0.00024195334153496266\n",
      "loss: 0.00024163575018341878\n",
      "loss: 0.0002413189395125029\n",
      "loss: 0.00024100290671837275\n",
      "loss: 0.00024068764901029498\n",
      "loss: 0.00024037316361097866\n",
      "loss: 0.00024005944775579762\n",
      "loss: 0.00023974649869345696\n",
      "loss: 0.00023943431368554847\n",
      "loss: 0.00023912289000632876\n",
      "loss: 0.0002388122249429415\n",
      "loss: 0.00023850231579530554\n",
      "loss: 0.00023819315987578274\n",
      "loss: 0.00023788475450951035\n",
      "loss: 0.00023757709703395703\n",
      "loss: 0.00023727018479892295\n",
      "loss: 0.00023696401516676145\n",
      "loss: 0.00023665858551193518\n",
      "loss: 0.00023635389322123818\n",
      "loss: 0.00023604993569335123\n",
      "loss: 0.00023574671033928642\n",
      "loss: 0.00023544421458194292\n",
      "loss: 0.0002351424458558843\n",
      "loss: 0.0002348414016080056\n",
      "loss: 0.00023454107929664434\n",
      "loss: 0.0002342414763919137\n",
      "loss: 0.00023394259037548039\n",
      "loss: 0.00023364441874089824\n",
      "loss: 0.00023334695899305212\n",
      "loss: 0.00023305020864804743\n",
      "loss: 0.0002327541652338761\n",
      "loss: 0.0002324588262893062\n",
      "loss: 0.0002321641893647704\n",
      "loss: 0.00023187025202181034\n",
      "loss: 0.00023157701183285466\n",
      "loss: 0.00023128446638177443\n",
      "loss: 0.00023099261326299446\n",
      "loss: 0.0002307014500823818\n",
      "loss: 0.0002304109744563572\n",
      "loss: 0.0002301211840122284\n",
      "loss: 0.00022983207638807874\n",
      "loss: 0.00022954364923265645\n",
      "loss: 0.00022925590020537448\n",
      "loss: 0.0002289688269761992\n",
      "loss: 0.0002286824272256507\n",
      "loss: 0.00022839669864469156\n",
      "loss: 0.00022811163893483787\n",
      "loss: 0.00022782724580760403\n",
      "loss: 0.0002275435169850577\n",
      "loss: 0.00022726045019937592\n",
      "loss: 0.0002269780431930671\n",
      "loss: 0.00022669629371863763\n",
      "loss: 0.0002264151995385921\n",
      "loss: 0.00022613475842543326\n",
      "loss: 0.0002258549681618837\n",
      "loss: 0.00022557582654022005\n",
      "loss: 0.00022529733136271703\n",
      "loss: 0.00022501948044153613\n",
      "loss: 0.00022474227159828146\n",
      "loss: 0.00022446570266444407\n",
      "loss: 0.0002241897714810688\n",
      "loss: 0.0002239144758989761\n",
      "loss: 0.00022363981377809597\n",
      "loss: 0.00022336578298824507\n",
      "loss: 0.0002230923814083495\n",
      "loss: 0.0002228196069267778\n",
      "loss: 0.0002225474574414522\n",
      "loss: 0.00022227593085907092\n",
      "loss: 0.00022200502509599687\n",
      "loss: 0.0002217347380775911\n",
      "loss: 0.00022146506773810173\n",
      "loss: 0.0002211960120213304\n",
      "loss: 0.0002209275688796327\n",
      "loss: 0.0002206597362744732\n",
      "loss: 0.00022039251217642597\n",
      "loss: 0.00022012589456450746\n",
      "loss: 0.00021985988142706568\n",
      "loss: 0.00021959447076078025\n",
      "loss: 0.00021932966057132877\n",
      "loss: 0.00021906544887294262\n",
      "loss: 0.00021880183368851793\n",
      "loss: 0.00021853881304939376\n",
      "loss: 0.0002182763849957957\n",
      "loss: 0.00021801454757605914\n",
      "loss: 0.00021775329884718411\n",
      "loss: 0.000217492636874502\n",
      "loss: 0.0002172325597316759\n",
      "loss: 0.0002169730655007005\n",
      "loss: 0.00021671415227190183\n",
      "loss: 0.00021645581814382634\n",
      "loss: 0.00021619806122301883\n",
      "loss: 0.00021594087962435555\n",
      "loss: 0.00021568427147071112\n",
      "loss: 0.0002154282348930691\n",
      "loss: 0.00021517276803030056\n",
      "loss: 0.0002149178690293857\n",
      "loss: 0.00021466353604508083\n",
      "loss: 0.00021440976724025143\n",
      "loss: 0.00021415656078531696\n",
      "loss: 0.00021390391485858392\n",
      "loss: 0.00021365182764635694\n",
      "loss: 0.00021340029734216146\n",
      "loss: 0.00021314932214774299\n",
      "loss: 0.00021289890027217877\n",
      "loss: 0.0002126490299319889\n",
      "loss: 0.00021239970935169153\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "input = np.linspace(0,21,22).reshape(-1,2)\n",
    "output = (input[:,0]*5 + input[:,1]*-3 + 10 > 50).astype(int).reshape(-1, 1)\n",
    "nn.sequence(\n",
    "    input.shape[1],\n",
    "    Dense(7, Relu),\n",
    "    Dense(1, Sigmoid),\n",
    ")\n",
    "for i in range(1000):\n",
    "    predict = nn.compile(input, output, Cross_entropy, learning_rate=0.3)\n",
    "    print('loss:', predict['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
