{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Idea\n",
    "1. add scale to location net\n",
    "2. initial h_t should come from images\n",
    "### Source\n",
    "[paper](https://arxiv.org/pdf/1406.6247.pdf)\n",
    "[ref](https://github.com/kevinzakka/recurrent-visual-attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "pilImage = transforms.ToPILImage()\n",
    "\n",
    "from models import GlimpseSensor, GlimpseNetwork, CoreNetwork, ActionNetwork, LocationNetwork, BaselineNetwork, RecurrentAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST('../../data', train=False, download=True,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "#                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                   ]))\n",
    "data_loader_train = DataLoader(mnist_trainset, 64, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3ElEQVR4nNXOu2oCARQE0MEHPgKCC2IgaSy00NqvsLEJi2ATSJpABPMFFoKNvaS1FrEVLPYTtnBRfGCZYkFsxAfMTaqFuO4tLJ1uOMzlAvec6kTcXiqQXhZCkqUAyo+PlFlt+B6+tsKadM1k4MnCiudmFgC+rKLP4jZ3dQDI9A9s+bDOUxPAU+eHHD34sMuV8fhpCUnHs4iHRM4FcI5C3vb+f9LfW3LZaZCNwH8BPP+Kk9BwICxrljjKNKbhB8XULLnkTh0aZFszvJKGihbnFz30v2xgq0NUSB1vyh8Bn1X5wbe+BQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x11E813908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, target = next(iter(data_loader_train))\n",
    "pilImage(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test GlimpseSensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVR4nGNggILOv3///v3798ffv78tGdCB4Mx3f//ebs/7+zcPQw4KZP7/u8qJS3LNv7+muOQ4f/y7wo5LMuvvv3Bccly3/37AqVHo798WXHIMiX//CuGUPPD3BgqfCZlzn+ECTo0M3n//4pYcBUMeAAC9zCwytCIg4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x11F0CAA58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_location = torch.Tensor((1, 0)).repeat(1,64).view(64, 2)\n",
    "g = GlimpseSensor(retina_size=28)\n",
    "a = g.foveate(data, locations=mock_location)\n",
    "a = a.view(-1, 3, 1, 28, 28) # (batch, num_zoom_image, channel, H, W)\n",
    "pilImage(a[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GlimpseNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0599, 0.1613, 0.0606,  ..., 0.0773, 0.0487, 0.0461],\n",
       "        [0.0779, 0.1181, 0.0475,  ..., 0.0318, 0.0224, 0.0384],\n",
       "        [0.0413, 0.1010, 0.0489,  ..., 0.0229, 0.0121, 0.0384],\n",
       "        ...,\n",
       "        [0.0768, 0.1010, 0.0807,  ..., 0.0383, 0.0114, 0.0384],\n",
       "        [0.0472, 0.1010, 0.0793,  ..., 0.0415, 0.0000, 0.0384],\n",
       "        [0.0270, 0.1114, 0.0366,  ..., 0.0173, 0.0081, 0.0384]],\n",
       "       grad_fn=<ReluBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glimseNetwork = GlimpseNetwork(\n",
    "                     num_hidden_glimpse = 128,\n",
    "                     num_hidden_location = 128,\n",
    "                     retina_size = 7,\n",
    "                     num_zoom_image = 3,\n",
    "                     scale = 2,\n",
    "                     channel = 1)\n",
    "g_t = glimseNetwork(images=data, location_prev=mock_location)\n",
    "g_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_prev = torch.zeros((256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreNetwork = CoreNetwork(num_hidden_glimpse_n_location = 256, num_hidden_core=256)\n",
    "h = coreNetwork(g_t = g_t, h_prev = h_prev)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ActionNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actionNetwork = ActionNetwork(num_hidden_core=h.shape[1], num_action=10)\n",
    "actionNetwork(h).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocationNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2]), torch.Size([64, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locationNetwork = LocationNetwork(num_hidden_core=h.shape[1], num_location=2, std=0.17)\n",
    "mu, location = locationNetwork(h)\n",
    "mu.shape, location.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaselineNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineNetwork = BaselineNetwork(num_hidden_core=h.shape[1], num_output=1)\n",
    "b = baselineNetwork(h)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecurrentAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.2331, -2.3480, -2.2708, -2.1502, -2.3336, -2.3978, -2.4014, -2.3374,\n",
       "          -2.3208, -2.2603],\n",
       "         [-2.2457, -2.3243, -2.2771, -2.1306, -2.3264, -2.3959, -2.4125, -2.3338,\n",
       "          -2.3250, -2.2837],\n",
       "         [-2.2297, -2.3303, -2.2958, -2.1609, -2.3337, -2.3894, -2.3808, -2.3384,\n",
       "          -2.2964, -2.2918],\n",
       "         [-2.2351, -2.3136, -2.2851, -2.1460, -2.3422, -2.4032, -2.4107, -2.3308,\n",
       "          -2.3193, -2.2679],\n",
       "         [-2.2395, -2.3388, -2.2813, -2.1696, -2.3305, -2.3894, -2.3934, -2.3429,\n",
       "          -2.2919, -2.2700],\n",
       "         [-2.2478, -2.3211, -2.2834, -2.1419, -2.3465, -2.4044, -2.3954, -2.3317,\n",
       "          -2.3121, -2.2681],\n",
       "         [-2.2252, -2.3400, -2.2815, -2.1786, -2.3178, -2.3966, -2.4104, -2.3335,\n",
       "          -2.3009, -2.2645],\n",
       "         [-2.2337, -2.3248, -2.2859, -2.1557, -2.3318, -2.4358, -2.4200, -2.3041,\n",
       "          -2.3040, -2.2608],\n",
       "         [-2.2318, -2.3526, -2.2671, -2.1456, -2.3408, -2.4043, -2.4045, -2.3305,\n",
       "          -2.3033, -2.2743],\n",
       "         [-2.2297, -2.3265, -2.2897, -2.1557, -2.3179, -2.4159, -2.3875, -2.3207,\n",
       "          -2.3094, -2.2971],\n",
       "         [-2.2416, -2.3238, -2.2796, -2.1711, -2.3286, -2.4098, -2.3986, -2.3257,\n",
       "          -2.2978, -2.2718],\n",
       "         [-2.2225, -2.3179, -2.2785, -2.1623, -2.3286, -2.4174, -2.4215, -2.3155,\n",
       "          -2.3093, -2.2802],\n",
       "         [-2.2258, -2.3270, -2.2941, -2.1794, -2.3434, -2.4111, -2.3796, -2.3281,\n",
       "          -2.2931, -2.2659],\n",
       "         [-2.2322, -2.3406, -2.2804, -2.1738, -2.3351, -2.4043, -2.4013, -2.3244,\n",
       "          -2.2988, -2.2587],\n",
       "         [-2.2397, -2.3548, -2.2607, -2.1785, -2.3484, -2.4065, -2.4092, -2.3193,\n",
       "          -2.2766, -2.2576],\n",
       "         [-2.2505, -2.3184, -2.2847, -2.1502, -2.3328, -2.4070, -2.4014, -2.3246,\n",
       "          -2.3148, -2.2668],\n",
       "         [-2.2235, -2.3536, -2.2781, -2.1608, -2.3550, -2.4191, -2.3975, -2.3028,\n",
       "          -2.2985, -2.2653],\n",
       "         [-2.2178, -2.3220, -2.2823, -2.1786, -2.3467, -2.4275, -2.3866, -2.3356,\n",
       "          -2.2870, -2.2672],\n",
       "         [-2.2442, -2.3215, -2.2864, -2.1544, -2.3433, -2.4235, -2.3678, -2.3428,\n",
       "          -2.2930, -2.2738],\n",
       "         [-2.2372, -2.3421, -2.2703, -2.1305, -2.3369, -2.4053, -2.3983, -2.3426,\n",
       "          -2.3336, -2.2604],\n",
       "         [-2.2200, -2.3190, -2.2581, -2.1712, -2.3418, -2.4049, -2.4265, -2.3103,\n",
       "          -2.3301, -2.2716],\n",
       "         [-2.2282, -2.3249, -2.2998, -2.1759, -2.3289, -2.4006, -2.3977, -2.3195,\n",
       "          -2.3036, -2.2685],\n",
       "         [-2.2352, -2.3396, -2.2729, -2.1652, -2.3364, -2.4026, -2.3929, -2.3445,\n",
       "          -2.3010, -2.2602],\n",
       "         [-2.2229, -2.3385, -2.2714, -2.1330, -2.3560, -2.4158, -2.4055, -2.3285,\n",
       "          -2.3199, -2.2677],\n",
       "         [-2.2305, -2.3212, -2.2659, -2.1661, -2.3292, -2.4205, -2.4218, -2.3083,\n",
       "          -2.3157, -2.2743],\n",
       "         [-2.2223, -2.3150, -2.2938, -2.1494, -2.3437, -2.4348, -2.3890, -2.3348,\n",
       "          -2.2961, -2.2766],\n",
       "         [-2.2419, -2.3020, -2.2905, -2.1519, -2.3460, -2.4118, -2.3886, -2.3208,\n",
       "          -2.3234, -2.2740],\n",
       "         [-2.2300, -2.3295, -2.2961, -2.1568, -2.3225, -2.3975, -2.3959, -2.3343,\n",
       "          -2.3139, -2.2734],\n",
       "         [-2.2260, -2.3426, -2.2850, -2.1880, -2.3362, -2.4109, -2.3901, -2.3230,\n",
       "          -2.2850, -2.2609],\n",
       "         [-2.2156, -2.3357, -2.2854, -2.1659, -2.3243, -2.4421, -2.4027, -2.3238,\n",
       "          -2.2938, -2.2661],\n",
       "         [-2.2338, -2.3163, -2.2982, -2.1366, -2.3345, -2.4258, -2.3943, -2.3322,\n",
       "          -2.3027, -2.2811],\n",
       "         [-2.2352, -2.3407, -2.2901, -2.1466, -2.3385, -2.4056, -2.3905, -2.3303,\n",
       "          -2.3100, -2.2649],\n",
       "         [-2.2180, -2.3545, -2.2832, -2.1667, -2.3522, -2.4021, -2.3860, -2.3258,\n",
       "          -2.3023, -2.2604],\n",
       "         [-2.2228, -2.3170, -2.3112, -2.1452, -2.3423, -2.4101, -2.3757, -2.3313,\n",
       "          -2.3111, -2.2853],\n",
       "         [-2.2274, -2.3276, -2.2853, -2.1442, -2.3396, -2.4219, -2.3700, -2.3251,\n",
       "          -2.3130, -2.2984],\n",
       "         [-2.2322, -2.3416, -2.2819, -2.1632, -2.3334, -2.4018, -2.3929, -2.3452,\n",
       "          -2.2906, -2.2673],\n",
       "         [-2.2374, -2.3485, -2.2601, -2.1609, -2.3332, -2.4232, -2.3957, -2.3210,\n",
       "          -2.3070, -2.2661],\n",
       "         [-2.2267, -2.3417, -2.2851, -2.1609, -2.3582, -2.4102, -2.3871, -2.3240,\n",
       "          -2.2838, -2.2740],\n",
       "         [-2.2170, -2.3510, -2.2786, -2.1577, -2.3620, -2.4103, -2.4054, -2.3091,\n",
       "          -2.3016, -2.2626],\n",
       "         [-2.2170, -2.3293, -2.2719, -2.1744, -2.3450, -2.4345, -2.4014, -2.3298,\n",
       "          -2.2941, -2.2569],\n",
       "         [-2.2211, -2.3264, -2.2721, -2.1704, -2.3359, -2.4132, -2.4225, -2.3099,\n",
       "          -2.3210, -2.2612],\n",
       "         [-2.2282, -2.3227, -2.2813, -2.1641, -2.3296, -2.4077, -2.3864, -2.3274,\n",
       "          -2.3123, -2.2890],\n",
       "         [-2.2446, -2.3094, -2.3025, -2.1492, -2.3466, -2.4168, -2.3885, -2.3285,\n",
       "          -2.3025, -2.2634],\n",
       "         [-2.2386, -2.3491, -2.2569, -2.1492, -2.3407, -2.3969, -2.4241, -2.3316,\n",
       "          -2.3086, -2.2601],\n",
       "         [-2.2288, -2.3448, -2.2807, -2.1547, -2.3551, -2.4115, -2.3869, -2.3263,\n",
       "          -2.2943, -2.2695],\n",
       "         [-2.2336, -2.3415, -2.2816, -2.1367, -2.3541, -2.4025, -2.4082, -2.3085,\n",
       "          -2.3282, -2.2617],\n",
       "         [-2.2159, -2.3436, -2.2747, -2.1850, -2.3510, -2.3993, -2.4018, -2.3233,\n",
       "          -2.2845, -2.2704],\n",
       "         [-2.2411, -2.3325, -2.2663, -2.1453, -2.3315, -2.4141, -2.4028, -2.3333,\n",
       "          -2.3198, -2.2678],\n",
       "         [-2.2301, -2.3324, -2.2674, -2.1704, -2.3516, -2.4198, -2.4029, -2.3194,\n",
       "          -2.2752, -2.2828],\n",
       "         [-2.2312, -2.3430, -2.2618, -2.1731, -2.3407, -2.4059, -2.3896, -2.3502,\n",
       "          -2.2794, -2.2753],\n",
       "         [-2.2422, -2.3390, -2.2769, -2.1530, -2.3361, -2.4050, -2.3943, -2.3311,\n",
       "          -2.2976, -2.2759],\n",
       "         [-2.2381, -2.3410, -2.2694, -2.1391, -2.3557, -2.4042, -2.3970, -2.3389,\n",
       "          -2.3150, -2.2574],\n",
       "         [-2.2269, -2.3241, -2.2993, -2.1508, -2.3283, -2.4317, -2.3768, -2.3265,\n",
       "          -2.3131, -2.2754],\n",
       "         [-2.2446, -2.3363, -2.2552, -2.1543, -2.3459, -2.4157, -2.4183, -2.3095,\n",
       "          -2.3146, -2.2609],\n",
       "         [-2.2417, -2.3418, -2.2472, -2.1713, -2.3435, -2.4016, -2.3909, -2.3556,\n",
       "          -2.2988, -2.2585],\n",
       "         [-2.2446, -2.3381, -2.2807, -2.1522, -2.3263, -2.4193, -2.3971, -2.3258,\n",
       "          -2.2883, -2.2798],\n",
       "         [-2.2360, -2.3426, -2.2766, -2.1489, -2.3400, -2.4100, -2.4101, -2.3163,\n",
       "          -2.3176, -2.2567],\n",
       "         [-2.2136, -2.3519, -2.2702, -2.1372, -2.3442, -2.3865, -2.4222, -2.3174,\n",
       "          -2.3475, -2.2682],\n",
       "         [-2.2266, -2.3424, -2.2719, -2.1813, -2.3522, -2.4016, -2.3928, -2.3344,\n",
       "          -2.2755, -2.2704],\n",
       "         [-2.2341, -2.3338, -2.2761, -2.1581, -2.3319, -2.4084, -2.4006, -2.3083,\n",
       "          -2.3195, -2.2801],\n",
       "         [-2.2403, -2.3094, -2.2848, -2.1539, -2.3392, -2.4067, -2.3929, -2.3381,\n",
       "          -2.3127, -2.2726],\n",
       "         [-2.2296, -2.3444, -2.2546, -2.1732, -2.3216, -2.4061, -2.4311, -2.3403,\n",
       "          -2.2960, -2.2575],\n",
       "         [-2.2285, -2.3332, -2.2905, -2.1586, -2.3396, -2.3861, -2.3968, -2.3298,\n",
       "          -2.3077, -2.2782],\n",
       "         [-2.2426, -2.3462, -2.2728, -2.1479, -2.3347, -2.4096, -2.3869, -2.3405,\n",
       "          -2.2993, -2.2720]], grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[ 1.5397, -0.6204,  0.8882,  0.7037,  0.5755,  1.5399],\n",
       "         [ 0.2887,  0.2038,  0.3812,  1.2005,  1.2925,  1.3034],\n",
       "         [ 1.0763,  1.3952,  1.0441,  0.7415,  1.6901,  1.3540],\n",
       "         [ 0.9797,  0.5494,  1.6232,  1.4186,  1.7045,  0.9507],\n",
       "         [-0.0927,  1.2876, -2.8853,  1.6062,  1.3105,  1.4227],\n",
       "         [-0.0848,  0.8473,  0.6876, -0.5484,  1.6714,  1.1871],\n",
       "         [ 1.1568,  1.6177,  1.0806, -0.1126,  0.4875,  1.6527],\n",
       "         [ 0.7384,  1.2045,  0.1542,  1.6572,  0.8668,  0.2778],\n",
       "         [ 1.1713,  0.9723,  1.5776,  1.6230,  0.9855,  1.5759],\n",
       "         [ 0.7568,  0.8065,  1.6995,  0.9775,  0.0066,  1.5576],\n",
       "         [ 1.2402,  1.2838,  1.3694,  1.4820,  1.6540,  1.1588],\n",
       "         [ 1.2936,  0.8165,  0.8995, -1.8818,  0.9569,  0.0715],\n",
       "         [ 0.2082,  0.4154, -0.1192,  1.3770, -1.0381,  0.5277],\n",
       "         [ 1.0936,  1.4447,  0.3939,  0.3686,  1.6265,  1.4492],\n",
       "         [-0.2599,  0.6960, -0.6130,  1.0817, -0.8588, -0.2679],\n",
       "         [ 0.7192,  0.2633, -0.6603,  1.1656,  1.5205,  1.2500],\n",
       "         [ 1.3152,  0.1804, -0.5340,  1.5627,  1.3238, -0.6734],\n",
       "         [ 1.6261,  1.5433,  0.9296, -0.5189,  0.0091, -1.3272],\n",
       "         [ 1.6953,  1.2431, -0.6836,  1.3771,  0.1303,  1.2244],\n",
       "         [ 0.8590,  1.1316, -1.1535,  1.6828,  0.5932,  1.5397],\n",
       "         [-0.6803,  1.4646, -0.1163,  1.3973,  1.5512,  1.0505],\n",
       "         [ 1.0578,  0.5395,  1.0008, -0.0362,  0.4548,  0.6869],\n",
       "         [ 0.7424,  0.7907,  0.6992,  1.4784,  1.3652,  0.7930],\n",
       "         [ 1.3733,  0.5795, -0.9953, -0.3729,  1.6909,  1.1418],\n",
       "         [-0.4751,  1.2663,  1.5789,  0.3989,  1.6019,  0.0296],\n",
       "         [ 0.0644,  0.5214,  1.1896,  0.7000, -0.3546, -0.2928],\n",
       "         [-0.3056, -0.4534,  1.0509, -0.1693, -0.1957,  1.2230],\n",
       "         [ 1.2763,  1.7059, -0.2957,  1.3786, -0.0680,  0.1167],\n",
       "         [-3.3197,  1.6796,  1.2708,  1.6685,  0.4106,  0.6659],\n",
       "         [-1.1754,  1.1907,  1.4367, -0.5186,  0.1227,  1.4359],\n",
       "         [ 1.1692,  1.4225,  1.6625,  1.6925, -0.1333,  1.6298],\n",
       "         [ 1.4612,  1.3547, -0.0222, -1.3370,  1.6907,  1.5339],\n",
       "         [ 0.7541,  1.0112,  1.5519,  0.9989,  1.5445,  1.4192],\n",
       "         [ 1.4742,  0.8142,  1.2956, -0.1241, -0.8631,  1.5738],\n",
       "         [ 1.6356,  1.1859,  0.6292,  1.5589,  1.6517,  0.5749],\n",
       "         [ 1.4667,  0.6981,  1.2226,  0.6424,  1.5414,  0.6882],\n",
       "         [ 1.5044,  0.2502,  0.5130,  1.5204,  0.8716,  1.6101],\n",
       "         [ 1.1356,  1.1307,  1.0154, -0.4386, -1.5978, -0.4032],\n",
       "         [ 1.1190,  0.9663, -3.5819,  1.5890,  1.2810,  1.3654],\n",
       "         [ 0.6819,  1.5344,  1.1066,  1.4521,  1.2336,  0.9933],\n",
       "         [ 0.7494,  1.6666, -0.7081, -1.4531,  1.3625,  1.0211],\n",
       "         [ 1.6464,  1.4861,  1.5333,  1.2205,  0.5446,  1.1800],\n",
       "         [ 1.3883, -0.9263,  0.8855,  1.1202, -2.0542, -1.2681],\n",
       "         [ 0.1710,  1.0318, -0.2530,  1.4087, -0.0482,  0.1372],\n",
       "         [-0.5781, -0.6723,  1.3953,  1.7025,  1.6380,  0.9512],\n",
       "         [ 1.5324,  1.2835,  0.0803,  1.3810,  0.4775,  1.4436],\n",
       "         [ 1.7031,  0.8515,  1.0157,  0.7136, -1.1334,  1.4408],\n",
       "         [ 0.6418,  0.4295,  1.4329,  1.5310,  1.0980,  1.2585],\n",
       "         [ 0.9635,  0.5612,  1.6175,  1.1622, -1.0708,  1.0034],\n",
       "         [ 1.0196, -1.1832,  0.1003,  1.2273,  0.8157,  1.2019],\n",
       "         [ 1.4729,  0.2710,  1.1002, -0.8741,  1.0124, -1.6287],\n",
       "         [ 0.9873,  0.7559, -0.8911,  1.6821,  1.4604,  0.5226],\n",
       "         [ 0.2813,  1.5570,  0.9534,  1.5337,  0.3704,  1.4999],\n",
       "         [ 0.4566,  1.6779,  0.7961,  1.1026,  0.0051,  1.0644],\n",
       "         [ 0.2142, -0.4515,  1.2955,  1.6761, -1.2874,  1.5143],\n",
       "         [ 0.4006,  1.4517,  1.6873, -0.1801,  1.3659, -1.6889],\n",
       "         [ 0.6959,  1.3698,  1.0355,  1.0224,  1.2087,  0.6529],\n",
       "         [ 1.1602,  0.6567,  1.2844,  0.9102,  0.7292,  1.1699],\n",
       "         [ 1.3639,  1.0873,  0.0430, -0.0771, -1.5599,  1.6124],\n",
       "         [ 0.7378,  1.5761,  1.2452,  1.3766,  1.5133,  0.0977],\n",
       "         [ 0.8400,  1.7028,  0.9975,  0.0512,  1.6355,  0.9914],\n",
       "         [ 0.1822,  1.0051,  1.4230,  1.6152,  1.0996,  1.6843],\n",
       "         [ 1.4493,  0.6629,  0.0130,  1.0150,  1.3747,  1.0518],\n",
       "         [ 0.6172,  1.2612,  0.4221,  1.1260,  1.5901,  1.5486]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[0.0981, 0.1306, 0.1285, 0.1415, 0.1317, 0.1350],\n",
       "         [0.1333, 0.1387, 0.1162, 0.1186, 0.1284, 0.1578],\n",
       "         [0.1325, 0.1315, 0.1254, 0.1379, 0.1390, 0.1268],\n",
       "         [0.1224, 0.1414, 0.1151, 0.1410, 0.1364, 0.1399],\n",
       "         [0.1158, 0.1214, 0.1371, 0.1475, 0.1325, 0.1383],\n",
       "         [0.1450, 0.1030, 0.1320, 0.1272, 0.1338, 0.1145],\n",
       "         [0.1240, 0.1211, 0.1365, 0.1247, 0.1266, 0.1310],\n",
       "         [0.1615, 0.1172, 0.1341, 0.1280, 0.1506, 0.1324],\n",
       "         [0.1137, 0.1369, 0.1237, 0.1421, 0.1332, 0.1398],\n",
       "         [0.1302, 0.1465, 0.1337, 0.1267, 0.1175, 0.1384],\n",
       "         [0.1573, 0.1359, 0.1329, 0.1394, 0.1279, 0.1287],\n",
       "         [0.1027, 0.1225, 0.1078, 0.1242, 0.1375, 0.1179],\n",
       "         [0.1384, 0.1382, 0.1464, 0.1438, 0.1323, 0.1327],\n",
       "         [0.1362, 0.1258, 0.1257, 0.1316, 0.1322, 0.1235],\n",
       "         [0.1136, 0.1136, 0.1398, 0.1538, 0.1058, 0.1181],\n",
       "         [0.1300, 0.1361, 0.1296, 0.1239, 0.1405, 0.1434],\n",
       "         [0.1470, 0.1249, 0.1251, 0.1326, 0.1318, 0.1296],\n",
       "         [0.1248, 0.1258, 0.1334, 0.1230, 0.1339, 0.1194],\n",
       "         [0.1200, 0.1363, 0.1442, 0.1172, 0.1370, 0.1279],\n",
       "         [0.1379, 0.1368, 0.1348, 0.1387, 0.1372, 0.1406],\n",
       "         [0.1442, 0.1316, 0.1283, 0.1422, 0.1247, 0.1348],\n",
       "         [0.0920, 0.1424, 0.1404, 0.1318, 0.1179, 0.1196],\n",
       "         [0.1491, 0.1162, 0.1541, 0.1172, 0.1276, 0.1282],\n",
       "         [0.1235, 0.1453, 0.1405, 0.1310, 0.1466, 0.1325],\n",
       "         [0.1436, 0.1281, 0.1440, 0.1576, 0.1294, 0.1449],\n",
       "         [0.1274, 0.1048, 0.1337, 0.1327, 0.1381, 0.1380],\n",
       "         [0.1477, 0.1368, 0.1531, 0.1133, 0.1216, 0.1219],\n",
       "         [0.1372, 0.1445, 0.1187, 0.1528, 0.1356, 0.1407],\n",
       "         [0.1072, 0.1337, 0.1278, 0.1201, 0.1340, 0.1287],\n",
       "         [0.0929, 0.1224, 0.1277, 0.1275, 0.1307, 0.1509],\n",
       "         [0.1407, 0.1373, 0.1186, 0.1142, 0.1328, 0.1211],\n",
       "         [0.1190, 0.1255, 0.1163, 0.1266, 0.1154, 0.1243],\n",
       "         [0.1558, 0.1160, 0.1270, 0.1305, 0.1332, 0.1231],\n",
       "         [0.1187, 0.1179, 0.1154, 0.1109, 0.1335, 0.1304],\n",
       "         [0.0971, 0.1442, 0.1344, 0.1192, 0.1419, 0.1311],\n",
       "         [0.1042, 0.1137, 0.1284, 0.1105, 0.1162, 0.1174],\n",
       "         [0.1244, 0.1405, 0.1272, 0.1226, 0.1428, 0.1244],\n",
       "         [0.1374, 0.1308, 0.1443, 0.1242, 0.1438, 0.1155],\n",
       "         [0.1124, 0.1346, 0.1265, 0.1560, 0.1468, 0.1315],\n",
       "         [0.1383, 0.1175, 0.1382, 0.1294, 0.1328, 0.1310],\n",
       "         [0.1142, 0.1404, 0.1310, 0.1260, 0.1565, 0.1236],\n",
       "         [0.1135, 0.1313, 0.1257, 0.1362, 0.1365, 0.1226],\n",
       "         [0.1428, 0.1353, 0.1405, 0.1231, 0.1483, 0.1311],\n",
       "         [0.1120, 0.1376, 0.1242, 0.1402, 0.1150, 0.1361],\n",
       "         [0.1145, 0.1448, 0.1007, 0.1315, 0.1268, 0.1387],\n",
       "         [0.1260, 0.1111, 0.1364, 0.1373, 0.1457, 0.1393],\n",
       "         [0.1373, 0.1168, 0.1191, 0.1324, 0.1241, 0.1169],\n",
       "         [0.1203, 0.1271, 0.1369, 0.1382, 0.1451, 0.1256],\n",
       "         [0.1356, 0.1243, 0.1331, 0.1315, 0.1340, 0.1289],\n",
       "         [0.1096, 0.1229, 0.1036, 0.1347, 0.1177, 0.1148],\n",
       "         [0.1001, 0.1273, 0.1293, 0.1222, 0.1175, 0.1388],\n",
       "         [0.1413, 0.1389, 0.1369, 0.1361, 0.1416, 0.1295],\n",
       "         [0.1221, 0.1087, 0.1158, 0.1103, 0.1241, 0.1294],\n",
       "         [0.1328, 0.1362, 0.1281, 0.1185, 0.1159, 0.1263],\n",
       "         [0.1410, 0.1321, 0.1277, 0.1223, 0.1232, 0.1269],\n",
       "         [0.1314, 0.1207, 0.1320, 0.1368, 0.1279, 0.1286],\n",
       "         [0.1303, 0.1242, 0.1254, 0.1422, 0.1342, 0.1255],\n",
       "         [0.1135, 0.1324, 0.1357, 0.1550, 0.1308, 0.1543],\n",
       "         [0.1355, 0.1392, 0.1425, 0.1295, 0.1405, 0.1142],\n",
       "         [0.1339, 0.1410, 0.1400, 0.1450, 0.1234, 0.1432],\n",
       "         [0.1374, 0.1176, 0.1228, 0.1243, 0.1376, 0.1141],\n",
       "         [0.1144, 0.1386, 0.1293, 0.1341, 0.1491, 0.1460],\n",
       "         [0.1389, 0.1298, 0.1360, 0.1437, 0.1174, 0.1307],\n",
       "         [0.0940, 0.1316, 0.1192, 0.1197, 0.1282, 0.1297]],\n",
       "        grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_glimpse = 6\n",
    "ram = RecurrentAttention(\n",
    "     num_hidden_glimpse = 128,\n",
    "     num_hidden_location = 128,\n",
    "     num_hidden_core = 256,\n",
    "     num_zoom_image = 3,\n",
    "     num_glimpse=num_glimpse,\n",
    "     num_action=10,\n",
    "     retina_size = 7,\n",
    "     scale = 2,\n",
    "     channel = 1,\n",
    "     std=0.17)\n",
    "ram(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 40.625 loss: -0.5688647\n",
      "acc: 34.375 loss: -0.49798656\n",
      "acc: 37.5 loss: -0.14341629\n",
      "acc: 39.0625 loss: 0.17888749\n",
      "acc: 42.1875 loss: -0.23501134\n",
      "acc: 48.4375 loss: -0.9720911\n",
      "acc: 45.3125 loss: -0.78758967\n",
      "acc: 53.125 loss: -1.467391\n",
      "acc: 48.4375 loss: -1.2042782\n",
      "acc: 48.4375 loss: -1.0110687\n",
      "acc: 45.3125 loss: -0.50475967\n",
      "acc: 59.375 loss: -1.2751955\n",
      "acc: 45.3125 loss: -0.73973155\n",
      "acc: 43.75 loss: -0.11872089\n",
      "acc: 39.0625 loss: -0.27893305\n",
      "acc: 40.625 loss: -0.39890087\n",
      "acc: 48.4375 loss: -0.73813975\n",
      "acc: 39.0625 loss: -0.47749007\n",
      "acc: 40.625 loss: -0.5876181\n",
      "acc: 42.1875 loss: -0.55774856\n",
      "acc: 26.5625 loss: 0.48112142\n",
      "acc: 48.4375 loss: -1.0298237\n",
      "acc: 59.375 loss: -1.3511432\n",
      "acc: 59.375 loss: -1.1670583\n",
      "acc: 53.125 loss: -0.75354505\n",
      "acc: 43.75 loss: -0.707415\n",
      "acc: 35.9375 loss: -0.20566821\n",
      "acc: 48.4375 loss: -0.9625201\n",
      "acc: 57.8125 loss: -1.5450945\n",
      "acc: 50.0 loss: -0.87034965\n",
      "acc: 46.875 loss: -0.79112124\n",
      "acc: 51.5625 loss: -1.0812579\n",
      "acc: 40.625 loss: -0.30816364\n",
      "acc: 42.1875 loss: -0.3683207\n",
      "acc: 56.25 loss: -1.0850332\n",
      "acc: 45.3125 loss: -0.72199667\n",
      "acc: 59.375 loss: -1.7132741\n",
      "acc: 46.875 loss: -0.7898315\n",
      "acc: 50.0 loss: -1.5207161\n",
      "acc: 54.6875 loss: -1.7963738\n",
      "acc: 56.25 loss: -1.50647\n",
      "acc: 39.0625 loss: -0.30904484\n",
      "acc: 53.125 loss: -1.0296091\n",
      "acc: 45.3125 loss: -0.62612224\n",
      "acc: 43.75 loss: 0.04123187\n",
      "acc: 53.125 loss: -1.1950996\n",
      "acc: 48.4375 loss: -0.5543783\n",
      "acc: 51.5625 loss: -1.0479459\n",
      "acc: 43.75 loss: -0.98948514\n",
      "acc: 51.5625 loss: -1.3413054\n",
      "acc: 54.6875 loss: -1.6005821\n",
      "acc: 50.0 loss: -1.3229644\n",
      "acc: 50.0 loss: -1.5064032\n",
      "acc: 48.4375 loss: -0.7635243\n",
      "acc: 67.1875 loss: -1.8906451\n",
      "acc: 53.125 loss: -1.2938042\n",
      "acc: 57.8125 loss: -1.2496984\n",
      "acc: 59.375 loss: -1.8111885\n",
      "acc: 45.3125 loss: -0.62533057\n",
      "acc: 65.625 loss: -2.3696508\n",
      "acc: 53.125 loss: -1.1648966\n",
      "acc: 56.25 loss: -1.5530291\n",
      "acc: 59.375 loss: -1.664326\n",
      "acc: 46.875 loss: -1.0164278\n",
      "acc: 60.9375 loss: -1.9128548\n",
      "acc: 53.125 loss: -1.319564\n",
      "acc: 56.25 loss: -1.3944626\n",
      "acc: 46.875 loss: -1.013582\n",
      "acc: 50.0 loss: -0.7142507\n",
      "acc: 59.375 loss: -1.5363464\n",
      "acc: 50.0 loss: -0.8244542\n",
      "acc: 67.1875 loss: -2.010409\n",
      "acc: 54.6875 loss: -1.4834278\n",
      "acc: 35.9375 loss: -0.042162538\n",
      "acc: 51.5625 loss: -1.4401109\n",
      "acc: 57.8125 loss: -1.7465218\n",
      "acc: 68.75 loss: -2.3690417\n",
      "acc: 53.125 loss: -1.3697708\n",
      "acc: 51.5625 loss: -0.9292122\n",
      "acc: 62.5 loss: -2.5755734\n",
      "acc: 50.0 loss: -0.8973751\n",
      "acc: 51.5625 loss: -1.0407189\n",
      "acc: 50.0 loss: -1.0272679\n",
      "acc: 48.4375 loss: -0.9554423\n",
      "acc: 59.375 loss: -1.6765641\n",
      "acc: 54.6875 loss: -1.3947295\n",
      "acc: 50.0 loss: -1.183077\n",
      "acc: 57.8125 loss: -1.3775197\n",
      "acc: 62.5 loss: -2.2279434\n",
      "acc: 53.125 loss: -1.516491\n",
      "acc: 51.5625 loss: -0.9859623\n",
      "acc: 60.9375 loss: -2.0627267\n",
      "acc: 59.375 loss: -2.0094175\n",
      "acc: 48.4375 loss: -0.7244171\n",
      "acc: 64.0625 loss: -1.7615021\n",
      "acc: 56.25 loss: -1.6800575\n",
      "acc: 59.375 loss: -2.031508\n",
      "acc: 56.25 loss: -1.7438122\n",
      "acc: 57.8125 loss: -1.8631263\n",
      "acc: 57.8125 loss: -2.0953088\n",
      "acc: 54.6875 loss: -1.5282552\n",
      "acc: 60.9375 loss: -1.9148638\n",
      "acc: 45.3125 loss: -1.2913033\n",
      "acc: 53.125 loss: -1.1726278\n",
      "acc: 53.125 loss: -0.97332835\n",
      "acc: 51.5625 loss: -0.9938842\n",
      "acc: 57.8125 loss: -1.4161133\n",
      "acc: 71.875 loss: -2.0892992\n",
      "acc: 71.875 loss: -2.420665\n",
      "acc: 67.1875 loss: -2.5811143\n",
      "acc: 56.25 loss: -2.1353517\n",
      "acc: 54.6875 loss: -1.5813818\n",
      "acc: 51.5625 loss: -1.5807734\n",
      "acc: 57.8125 loss: -1.7908915\n",
      "acc: 53.125 loss: -1.7314104\n",
      "acc: 53.125 loss: -1.1725644\n",
      "acc: 54.6875 loss: -1.201701\n",
      "acc: 59.375 loss: -1.3271707\n",
      "acc: 59.375 loss: -1.793567\n",
      "acc: 54.6875 loss: -1.5165344\n",
      "acc: 59.375 loss: -1.9137113\n",
      "acc: 60.9375 loss: -1.8153126\n",
      "acc: 64.0625 loss: -2.3954208\n",
      "acc: 51.5625 loss: -1.5840427\n",
      "acc: 53.125 loss: -1.5151962\n",
      "acc: 57.8125 loss: -1.6676877\n",
      "acc: 56.25 loss: -1.3123777\n",
      "acc: 64.0625 loss: -1.9177525\n",
      "acc: 45.3125 loss: -0.62879086\n",
      "acc: 56.25 loss: -0.9731139\n",
      "acc: 60.9375 loss: -1.9221663\n",
      "acc: 65.625 loss: -2.5309896\n",
      "acc: 67.1875 loss: -2.6343026\n",
      "acc: 57.8125 loss: -1.9069536\n",
      "acc: 57.8125 loss: -2.2761712\n",
      "acc: 68.75 loss: -2.6021895\n",
      "acc: 53.125 loss: -1.1684116\n",
      "acc: 62.5 loss: -1.9380999\n",
      "acc: 60.9375 loss: -1.9956133\n",
      "acc: 62.5 loss: -1.333211\n",
      "acc: 57.8125 loss: -1.1756313\n",
      "acc: 65.625 loss: -2.0640204\n",
      "acc: 62.5 loss: -1.5247753\n",
      "acc: 65.625 loss: -2.1583438\n",
      "acc: 54.6875 loss: -2.1957483\n",
      "acc: 57.8125 loss: -1.9374928\n",
      "acc: 70.3125 loss: -2.75699\n",
      "acc: 68.75 loss: -2.7136073\n",
      "acc: 62.5 loss: -1.6767604\n",
      "acc: 59.375 loss: -1.478581\n",
      "acc: 64.0625 loss: -2.8716211\n",
      "acc: 56.25 loss: -1.6236836\n",
      "acc: 56.25 loss: -1.8856076\n",
      "acc: 51.5625 loss: -1.530201\n",
      "acc: 59.375 loss: -2.0379477\n",
      "acc: 56.25 loss: -1.4455217\n",
      "acc: 64.0625 loss: -2.361091\n",
      "acc: 60.9375 loss: -2.2973638\n",
      "acc: 64.0625 loss: -2.231723\n",
      "acc: 57.8125 loss: -1.5101074\n",
      "acc: 57.8125 loss: -1.3201156\n",
      "acc: 64.0625 loss: -2.167633\n",
      "acc: 62.5 loss: -1.9367422\n",
      "acc: 60.9375 loss: -1.3566594\n",
      "acc: 71.875 loss: -2.8086362\n",
      "acc: 59.375 loss: -2.0190187\n",
      "acc: 71.875 loss: -2.3658044\n",
      "acc: 64.0625 loss: -2.7341616\n",
      "acc: 76.5625 loss: -2.8567524\n",
      "acc: 57.8125 loss: -1.8410995\n",
      "acc: 64.0625 loss: -2.2947803\n",
      "acc: 60.9375 loss: -1.6885481\n",
      "acc: 60.9375 loss: -1.6300945\n",
      "acc: 65.625 loss: -1.9452467\n",
      "acc: 68.75 loss: -2.1620364\n",
      "acc: 57.8125 loss: -1.7399194\n",
      "acc: 62.5 loss: -1.9295028\n",
      "acc: 73.4375 loss: -2.8088465\n",
      "acc: 62.5 loss: -1.7374752\n",
      "acc: 60.9375 loss: -2.2547717\n",
      "acc: 73.4375 loss: -2.6294277\n",
      "acc: 70.3125 loss: -2.5350494\n",
      "acc: 60.9375 loss: -1.8013914\n",
      "acc: 68.75 loss: -2.5531566\n",
      "acc: 70.3125 loss: -2.1518848\n",
      "acc: 64.0625 loss: -1.605718\n",
      "acc: 70.3125 loss: -2.2454119\n",
      "acc: 64.0625 loss: -2.0076306\n",
      "acc: 59.375 loss: -1.9070238\n",
      "acc: 68.75 loss: -2.138009\n",
      "acc: 75.0 loss: -2.950524\n",
      "acc: 53.125 loss: -1.6123642\n",
      "acc: 73.4375 loss: -3.391974\n",
      "acc: 59.375 loss: -1.972419\n",
      "acc: 64.0625 loss: -2.1428466\n",
      "acc: 68.75 loss: -2.3672621\n",
      "acc: 64.0625 loss: -1.8964834\n",
      "acc: 64.0625 loss: -2.1312747\n",
      "acc: 68.75 loss: -2.9877534\n",
      "acc: 60.9375 loss: -1.9894202\n",
      "acc: 59.375 loss: -2.1352673\n",
      "acc: 64.0625 loss: -2.4868393\n",
      "acc: 65.625 loss: -2.5894263\n",
      "acc: 62.5 loss: -1.9200249\n",
      "acc: 75.0 loss: -3.149024\n",
      "acc: 68.75 loss: -1.7792665\n",
      "acc: 51.5625 loss: -1.3033543\n",
      "acc: 71.875 loss: -2.3486192\n",
      "acc: 70.3125 loss: -2.35024\n",
      "acc: 57.8125 loss: -2.076992\n",
      "acc: 73.4375 loss: -3.1116643\n",
      "acc: 57.8125 loss: -1.6402551\n",
      "acc: 67.1875 loss: -1.8526392\n",
      "acc: 67.1875 loss: -1.8105149\n",
      "acc: 64.0625 loss: -2.021801\n",
      "acc: 78.125 loss: -2.925609\n",
      "acc: 68.75 loss: -2.7463334\n",
      "acc: 71.875 loss: -2.7225266\n",
      "acc: 73.4375 loss: -2.9991586\n",
      "acc: 73.4375 loss: -2.8673167\n",
      "acc: 67.1875 loss: -2.1034145\n",
      "acc: 68.75 loss: -2.268517\n",
      "acc: 76.5625 loss: -2.1882396\n",
      "acc: 73.4375 loss: -2.5477264\n",
      "acc: 75.0 loss: -2.52257\n",
      "acc: 67.1875 loss: -2.1249855\n",
      "acc: 78.125 loss: -2.6961617\n",
      "acc: 70.3125 loss: -2.3685493\n",
      "acc: 67.1875 loss: -2.3907313\n",
      "acc: 71.875 loss: -3.0273728\n",
      "acc: 62.5 loss: -2.3612037\n",
      "acc: 73.4375 loss: -2.9104497\n",
      "acc: 62.5 loss: -2.0303216\n",
      "acc: 85.9375 loss: -3.6817985\n",
      "acc: 68.75 loss: -2.233489\n",
      "acc: 73.4375 loss: -2.471555\n",
      "acc: 73.4375 loss: -3.2040288\n",
      "acc: 73.4375 loss: -3.0988808\n",
      "acc: 73.4375 loss: -2.9036984\n",
      "acc: 67.1875 loss: -2.8084176\n",
      "acc: 76.5625 loss: -2.687426\n",
      "acc: 59.375 loss: -1.8968316\n",
      "acc: 76.5625 loss: -2.945211\n",
      "acc: 73.4375 loss: -2.5616264\n",
      "acc: 65.625 loss: -2.4518278\n",
      "acc: 68.75 loss: -2.3900547\n",
      "acc: 75.0 loss: -2.971611\n",
      "acc: 76.5625 loss: -3.2498193\n",
      "acc: 70.3125 loss: -2.9114504\n",
      "acc: 68.75 loss: -2.5118432\n",
      "acc: 75.0 loss: -3.2619748\n",
      "acc: 76.5625 loss: -2.9507132\n",
      "acc: 64.0625 loss: -1.9379497\n",
      "acc: 79.6875 loss: -3.4845967\n",
      "acc: 60.9375 loss: -1.8215257\n",
      "acc: 67.1875 loss: -2.7070498\n",
      "acc: 73.4375 loss: -3.2329824\n",
      "acc: 76.5625 loss: -3.1077518\n",
      "acc: 68.75 loss: -2.4315212\n",
      "acc: 68.75 loss: -2.4745228\n",
      "acc: 71.875 loss: -2.8683014\n",
      "acc: 75.0 loss: -3.3070712\n",
      "acc: 64.0625 loss: -2.339178\n",
      "acc: 59.375 loss: -2.326386\n",
      "acc: 67.1875 loss: -2.5905404\n",
      "acc: 81.25 loss: -3.3479018\n",
      "acc: 75.0 loss: -2.8201838\n",
      "acc: 67.1875 loss: -2.3012304\n",
      "acc: 68.75 loss: -2.2952728\n",
      "acc: 73.4375 loss: -3.1022434\n",
      "acc: 73.4375 loss: -2.9120743\n",
      "acc: 68.75 loss: -2.508383\n",
      "acc: 68.75 loss: -2.426124\n",
      "acc: 68.75 loss: -2.6999655\n",
      "acc: 62.5 loss: -2.0312026\n",
      "acc: 68.75 loss: -2.3153389\n",
      "acc: 82.8125 loss: -3.3289022\n",
      "acc: 78.125 loss: -3.1243382\n",
      "acc: 75.0 loss: -2.566575\n",
      "acc: 70.3125 loss: -2.0189877\n",
      "acc: 73.4375 loss: -3.046524\n",
      "acc: 64.0625 loss: -2.544892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 85.9375 loss: -3.8197045\n",
      "acc: 75.0 loss: -3.0210552\n",
      "acc: 60.9375 loss: -2.3601437\n",
      "acc: 78.125 loss: -3.071231\n",
      "acc: 76.5625 loss: -2.5714533\n",
      "acc: 62.5 loss: -1.8964741\n",
      "acc: 75.0 loss: -3.2321262\n",
      "acc: 73.4375 loss: -2.577521\n",
      "acc: 81.25 loss: -3.801052\n",
      "acc: 75.0 loss: -3.0145419\n",
      "acc: 76.5625 loss: -3.1034985\n",
      "acc: 84.375 loss: -3.815574\n",
      "acc: 79.6875 loss: -2.8107805\n",
      "acc: 70.3125 loss: -2.8028893\n",
      "acc: 79.6875 loss: -3.2939477\n",
      "acc: 75.0 loss: -2.8197346\n",
      "acc: 67.1875 loss: -2.3180757\n",
      "acc: 70.3125 loss: -2.6152248\n",
      "acc: 71.875 loss: -2.5712793\n",
      "acc: 71.875 loss: -2.731742\n",
      "acc: 70.3125 loss: -2.2538214\n",
      "acc: 75.0 loss: -2.9627929\n",
      "acc: 76.5625 loss: -2.6275678\n",
      "acc: 70.3125 loss: -2.4489522\n",
      "acc: 76.5625 loss: -2.8149827\n",
      "acc: 76.5625 loss: -2.754521\n",
      "acc: 65.625 loss: -2.312756\n",
      "acc: 73.4375 loss: -2.9990396\n",
      "acc: 87.5 loss: -3.531276\n",
      "acc: 70.3125 loss: -2.867074\n",
      "acc: 78.125 loss: -3.300788\n",
      "acc: 70.3125 loss: -2.485016\n",
      "acc: 84.375 loss: -4.06205\n",
      "acc: 79.6875 loss: -3.0915222\n",
      "acc: 76.5625 loss: -2.7362437\n",
      "acc: 62.5 loss: -2.0555384\n",
      "acc: 78.125 loss: -3.3588357\n",
      "acc: 82.8125 loss: -3.454049\n",
      "acc: 75.0 loss: -2.4821393\n",
      "acc: 84.375 loss: -3.032835\n",
      "acc: 76.5625 loss: -2.8789032\n",
      "acc: 73.4375 loss: -2.6095936\n",
      "acc: 76.5625 loss: -2.8205812\n",
      "acc: 79.6875 loss: -2.9288545\n",
      "acc: 75.0 loss: -2.6477766\n",
      "acc: 79.6875 loss: -3.4377964\n",
      "acc: 76.5625 loss: -2.8638802\n",
      "acc: 71.875 loss: -2.8901577\n",
      "acc: 78.125 loss: -3.5396852\n",
      "acc: 79.6875 loss: -2.9996529\n",
      "acc: 76.5625 loss: -3.5175202\n",
      "acc: 75.0 loss: -2.8814635\n",
      "acc: 73.4375 loss: -2.56984\n",
      "acc: 79.6875 loss: -3.1910641\n",
      "acc: 82.8125 loss: -3.6391385\n",
      "acc: 79.6875 loss: -2.8237324\n",
      "acc: 71.875 loss: -2.9738574\n",
      "acc: 75.0 loss: -3.0766459\n",
      "acc: 79.6875 loss: -3.2130837\n",
      "acc: 71.875 loss: -3.0250437\n",
      "acc: 71.875 loss: -2.8162656\n",
      "acc: 82.8125 loss: -3.2498538\n",
      "acc: 71.875 loss: -2.6144621\n",
      "acc: 78.125 loss: -3.530725\n",
      "acc: 82.8125 loss: -3.3635728\n",
      "acc: 75.0 loss: -2.501028\n",
      "acc: 81.25 loss: -3.3344498\n",
      "acc: 78.125 loss: -3.2307658\n",
      "acc: 79.6875 loss: -3.361538\n",
      "acc: 78.125 loss: -2.863265\n",
      "acc: 73.4375 loss: -2.4057689\n",
      "acc: 82.8125 loss: -3.563383\n",
      "acc: 75.0 loss: -2.7102818\n",
      "acc: 79.6875 loss: -3.421726\n",
      "acc: 81.25 loss: -3.59141\n",
      "acc: 68.75 loss: -2.4033663\n",
      "acc: 82.8125 loss: -3.4316792\n",
      "acc: 84.375 loss: -3.2948775\n",
      "acc: 84.375 loss: -3.5598571\n",
      "acc: 78.125 loss: -2.612319\n",
      "acc: 76.5625 loss: -2.620423\n",
      "acc: 76.5625 loss: -3.2721825\n",
      "acc: 76.5625 loss: -3.142911\n",
      "acc: 79.6875 loss: -3.0539415\n",
      "acc: 84.375 loss: -3.5411725\n",
      "acc: 71.875 loss: -2.8305595\n",
      "acc: 75.0 loss: -3.260189\n",
      "acc: 73.4375 loss: -3.0496433\n",
      "acc: 81.25 loss: -2.8654747\n",
      "acc: 71.875 loss: -2.4382048\n",
      "acc: 68.75 loss: -2.2835932\n",
      "acc: 76.5625 loss: -2.917187\n",
      "acc: 82.8125 loss: -3.6189065\n",
      "acc: 82.8125 loss: -3.5949266\n",
      "acc: 79.6875 loss: -2.681845\n",
      "acc: 71.875 loss: -2.8923073\n",
      "acc: 70.3125 loss: -2.449354\n",
      "acc: 89.0625 loss: -4.342238\n",
      "acc: 82.8125 loss: -3.8333628\n",
      "acc: 71.875 loss: -2.7427533\n",
      "acc: 70.3125 loss: -2.1835356\n",
      "acc: 81.25 loss: -3.197343\n",
      "acc: 76.5625 loss: -2.8165338\n",
      "acc: 68.75 loss: -2.2031507\n",
      "acc: 79.6875 loss: -3.348903\n",
      "acc: 73.4375 loss: -2.7291613\n",
      "acc: 81.25 loss: -3.6710248\n",
      "acc: 68.75 loss: -2.765768\n",
      "acc: 81.25 loss: -3.334539\n",
      "acc: 82.8125 loss: -3.5976958\n",
      "acc: 78.125 loss: -3.252009\n",
      "acc: 73.4375 loss: -2.5512967\n",
      "acc: 84.375 loss: -3.2788298\n",
      "acc: 84.375 loss: -3.280644\n",
      "acc: 84.375 loss: -3.538656\n",
      "acc: 78.125 loss: -3.268363\n",
      "acc: 75.0 loss: -2.7890418\n",
      "acc: 78.125 loss: -3.1766558\n",
      "acc: 76.5625 loss: -2.9186654\n",
      "acc: 78.125 loss: -3.1167974\n",
      "acc: 81.25 loss: -2.8947904\n",
      "acc: 87.5 loss: -3.7172475\n",
      "acc: 73.4375 loss: -3.0221725\n",
      "acc: 73.4375 loss: -2.859636\n",
      "acc: 81.25 loss: -3.496247\n",
      "acc: 78.125 loss: -3.1156814\n",
      "acc: 81.25 loss: -3.423795\n",
      "acc: 82.8125 loss: -3.50421\n",
      "acc: 79.6875 loss: -3.139998\n",
      "acc: 90.625 loss: -4.1592455\n",
      "acc: 79.6875 loss: -3.2942884\n",
      "acc: 84.375 loss: -3.5492833\n",
      "acc: 89.0625 loss: -4.1928186\n",
      "acc: 84.375 loss: -3.4978654\n",
      "acc: 81.25 loss: -2.9806228\n",
      "acc: 79.6875 loss: -3.5794656\n",
      "acc: 78.125 loss: -3.1218336\n",
      "acc: 79.6875 loss: -3.510437\n",
      "acc: 76.5625 loss: -2.9126122\n",
      "acc: 78.125 loss: -2.7155309\n",
      "acc: 78.125 loss: -3.0230775\n",
      "acc: 79.6875 loss: -3.1499841\n",
      "acc: 84.375 loss: -3.8247\n",
      "acc: 79.6875 loss: -3.231852\n",
      "acc: 76.5625 loss: -3.3148232\n",
      "acc: 87.5 loss: -3.940949\n",
      "acc: 87.5 loss: -3.3161092\n",
      "acc: 76.5625 loss: -3.3249528\n",
      "acc: 76.5625 loss: -2.4211144\n",
      "acc: 84.375 loss: -3.0339594\n",
      "acc: 84.375 loss: -3.2858188\n",
      "acc: 79.6875 loss: -2.8503807\n",
      "acc: 79.6875 loss: -3.8832457\n",
      "acc: 75.0 loss: -2.8771713\n",
      "acc: 73.4375 loss: -2.8130739\n",
      "acc: 84.375 loss: -3.8206315\n",
      "acc: 75.0 loss: -3.0914242\n",
      "acc: 82.8125 loss: -3.746102\n",
      "acc: 84.375 loss: -3.704207\n",
      "acc: 89.0625 loss: -4.060486\n",
      "acc: 82.8125 loss: -3.4886322\n",
      "acc: 76.5625 loss: -2.9000056\n",
      "acc: 82.8125 loss: -2.8152785\n",
      "acc: 81.25 loss: -3.375578\n",
      "acc: 81.25 loss: -3.081177\n",
      "acc: 82.8125 loss: -3.4542646\n",
      "acc: 81.25 loss: -3.3425891\n",
      "acc: 93.75 loss: -3.7176034\n",
      "acc: 78.125 loss: -2.9709885\n",
      "acc: 82.8125 loss: -3.0081728\n",
      "acc: 89.0625 loss: -3.6087708\n",
      "acc: 73.4375 loss: -3.349073\n",
      "acc: 76.5625 loss: -2.9049282\n",
      "acc: 85.9375 loss: -3.624157\n",
      "acc: 85.9375 loss: -3.530391\n",
      "acc: 75.0 loss: -2.896665\n",
      "acc: 79.6875 loss: -3.2042372\n",
      "acc: 79.6875 loss: -3.9661465\n",
      "acc: 85.9375 loss: -3.4141178\n",
      "acc: 76.5625 loss: -2.5575523\n",
      "acc: 68.75 loss: -2.6495218\n",
      "acc: 84.375 loss: -3.8798723\n",
      "acc: 76.5625 loss: -2.8068867\n",
      "acc: 79.6875 loss: -3.3174853\n",
      "acc: 78.125 loss: -3.0602496\n",
      "acc: 82.8125 loss: -3.3589232\n",
      "acc: 79.6875 loss: -3.7243993\n",
      "acc: 85.9375 loss: -4.2027903\n",
      "acc: 90.625 loss: -4.088617\n",
      "acc: 90.625 loss: -4.0826087\n",
      "acc: 78.125 loss: -3.305956\n",
      "acc: 82.8125 loss: -3.8794682\n",
      "acc: 89.0625 loss: -4.608118\n",
      "acc: 84.375 loss: -3.8121731\n",
      "acc: 73.4375 loss: -2.743013\n",
      "acc: 85.9375 loss: -3.3084838\n",
      "acc: 90.625 loss: -4.3570375\n",
      "acc: 85.9375 loss: -3.1021318\n",
      "acc: 82.8125 loss: -3.5207562\n",
      "acc: 84.375 loss: -2.655286\n",
      "acc: 78.125 loss: -2.502135\n",
      "acc: 78.125 loss: -2.901422\n",
      "acc: 79.6875 loss: -3.5995338\n",
      "acc: 85.9375 loss: -4.05486\n",
      "acc: 79.6875 loss: -3.2513485\n",
      "acc: 82.8125 loss: -3.6819315\n",
      "acc: 84.375 loss: -3.7088966\n",
      "acc: 85.9375 loss: -3.9740372\n",
      "acc: 85.9375 loss: -3.8343532\n",
      "acc: 78.125 loss: -3.004577\n",
      "acc: 73.4375 loss: -2.0427878\n",
      "acc: 78.125 loss: -2.735864\n",
      "acc: 87.5 loss: -3.464166\n",
      "acc: 84.375 loss: -3.4558146\n",
      "acc: 82.8125 loss: -3.3199573\n",
      "acc: 75.0 loss: -2.6255817\n",
      "acc: 75.0 loss: -2.348636\n",
      "acc: 73.4375 loss: -2.9375577\n",
      "acc: 81.25 loss: -2.9198928\n",
      "acc: 87.5 loss: -3.5947368\n",
      "acc: 85.9375 loss: -3.1076713\n",
      "acc: 82.8125 loss: -3.0815444\n",
      "acc: 81.25 loss: -3.1862237\n",
      "acc: 78.125 loss: -3.1212733\n",
      "acc: 82.8125 loss: -3.440466\n",
      "acc: 93.75 loss: -4.0371094\n",
      "acc: 87.5 loss: -3.7216873\n",
      "acc: 82.8125 loss: -3.5595448\n",
      "acc: 90.625 loss: -3.521089\n",
      "acc: 84.375 loss: -3.4896045\n",
      "acc: 84.375 loss: -3.5333776\n",
      "acc: 82.8125 loss: -2.84253\n",
      "acc: 85.9375 loss: -3.981561\n",
      "acc: 70.3125 loss: -2.356519\n",
      "acc: 81.25 loss: -3.7962282\n",
      "acc: 79.6875 loss: -3.6054626\n",
      "acc: 89.0625 loss: -4.044295\n",
      "acc: 71.875 loss: -2.5479906\n",
      "acc: 85.9375 loss: -3.4324796\n",
      "acc: 82.8125 loss: -2.738828\n",
      "acc: 67.1875 loss: -2.2679641\n",
      "acc: 79.6875 loss: -3.3032463\n",
      "acc: 82.8125 loss: -3.217503\n",
      "acc: 81.25 loss: -3.4008024\n",
      "acc: 84.375 loss: -3.449555\n",
      "acc: 89.0625 loss: -3.9858093\n",
      "acc: 84.375 loss: -3.79828\n",
      "acc: 82.8125 loss: -3.2948208\n",
      "acc: 87.5 loss: -3.4800565\n",
      "acc: 81.25 loss: -3.1703339\n",
      "acc: 82.8125 loss: -3.3479054\n",
      "acc: 84.375 loss: -3.0599666\n",
      "acc: 75.0 loss: -2.6924665\n",
      "acc: 85.9375 loss: -3.573944\n",
      "acc: 75.0 loss: -2.8163142\n",
      "acc: 89.0625 loss: -3.5967598\n",
      "acc: 87.5 loss: -3.4257758\n",
      "acc: 89.0625 loss: -4.0209985\n",
      "acc: 79.6875 loss: -3.289649\n",
      "acc: 79.6875 loss: -3.011218\n",
      "acc: 82.8125 loss: -3.1637502\n",
      "acc: 85.9375 loss: -3.707708\n",
      "acc: 84.375 loss: -3.9568958\n",
      "acc: 81.25 loss: -3.0840795\n",
      "acc: 78.125 loss: -2.6578374\n",
      "acc: 79.6875 loss: -3.0072877\n",
      "acc: 87.5 loss: -3.9939234\n",
      "acc: 81.25 loss: -2.9664168\n",
      "acc: 84.375 loss: -3.8979354\n",
      "acc: 87.5 loss: -4.2658687\n",
      "acc: 79.6875 loss: -3.478641\n",
      "acc: 90.625 loss: -3.8544075\n",
      "acc: 79.6875 loss: -3.1955388\n",
      "acc: 89.0625 loss: -3.3091545\n",
      "acc: 95.3125 loss: -4.435774\n",
      "acc: 76.5625 loss: -2.5735555\n",
      "acc: 79.6875 loss: -3.0469747\n",
      "acc: 82.8125 loss: -2.9814167\n",
      "acc: 78.125 loss: -3.0757432\n",
      "acc: 82.8125 loss: -3.1711884\n",
      "acc: 84.375 loss: -3.3925414\n",
      "acc: 65.625 loss: -2.122341\n",
      "acc: 84.375 loss: -3.8137562\n",
      "acc: 79.6875 loss: -3.158193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 82.8125 loss: -3.235753\n",
      "acc: 82.8125 loss: -3.1869667\n",
      "acc: 81.25 loss: -2.8483298\n",
      "acc: 76.5625 loss: -2.4414973\n",
      "acc: 71.875 loss: -2.3785276\n",
      "acc: 75.0 loss: -2.6879172\n",
      "acc: 85.9375 loss: -3.0642278\n",
      "acc: 84.375 loss: -3.7201211\n",
      "acc: 87.5 loss: -3.4902802\n",
      "acc: 84.375 loss: -3.8912992\n",
      "acc: 82.8125 loss: -4.0397916\n",
      "acc: 87.5 loss: -4.303521\n",
      "acc: 76.5625 loss: -3.0523815\n",
      "acc: 81.25 loss: -4.435495\n",
      "acc: 89.0625 loss: -4.3479257\n",
      "acc: 84.375 loss: -3.9780164\n",
      "acc: 89.0625 loss: -3.2950783\n",
      "acc: 90.625 loss: -3.247013\n",
      "acc: 81.25 loss: -2.9412956\n",
      "acc: 81.25 loss: -3.1159625\n",
      "acc: 82.8125 loss: -3.00007\n",
      "acc: 78.125 loss: -2.895609\n",
      "acc: 87.5 loss: -2.777152\n",
      "acc: 84.375 loss: -3.7405748\n",
      "acc: 84.375 loss: -3.96528\n",
      "acc: 89.0625 loss: -3.7071743\n",
      "acc: 89.0625 loss: -4.332907\n",
      "acc: 82.8125 loss: -4.1254306\n",
      "acc: 81.25 loss: -3.0721207\n",
      "acc: 79.6875 loss: -3.3461199\n",
      "acc: 79.6875 loss: -3.484336\n",
      "acc: 82.8125 loss: -3.1375518\n",
      "acc: 87.5 loss: -3.7670348\n",
      "acc: 85.9375 loss: -3.650989\n",
      "acc: 76.5625 loss: -2.8293738\n",
      "acc: 82.8125 loss: -3.8121965\n",
      "acc: 82.8125 loss: -3.2947788\n",
      "acc: 78.125 loss: -3.007716\n",
      "acc: 79.6875 loss: -3.433576\n",
      "acc: 81.25 loss: -3.1649117\n",
      "acc: 84.375 loss: -3.3199089\n",
      "acc: 82.8125 loss: -3.2190056\n",
      "acc: 79.6875 loss: -3.0696025\n",
      "acc: 76.5625 loss: -3.1845398\n",
      "acc: 78.125 loss: -3.3051322\n",
      "acc: 76.5625 loss: -3.12398\n",
      "acc: 78.125 loss: -2.929401\n",
      "acc: 79.6875 loss: -2.7169034\n",
      "acc: 93.75 loss: -4.334234\n",
      "acc: 87.5 loss: -2.8748317\n",
      "acc: 82.8125 loss: -3.7214808\n",
      "acc: 87.5 loss: -3.7553458\n",
      "acc: 78.125 loss: -2.9588687\n",
      "acc: 70.3125 loss: -2.651169\n",
      "acc: 78.125 loss: -2.8307562\n",
      "acc: 84.375 loss: -4.087457\n",
      "acc: 90.625 loss: -3.6172812\n",
      "acc: 84.375 loss: -3.7800963\n",
      "acc: 84.375 loss: -3.6731563\n",
      "acc: 76.5625 loss: -2.8540902\n",
      "acc: 89.0625 loss: -3.8225\n",
      "acc: 82.8125 loss: -3.2851102\n",
      "acc: 79.6875 loss: -3.2393267\n",
      "acc: 95.3125 loss: -4.1745896\n",
      "acc: 82.8125 loss: -3.20143\n",
      "acc: 85.9375 loss: -3.4564898\n",
      "acc: 79.6875 loss: -3.2389731\n",
      "acc: 82.8125 loss: -3.517136\n",
      "acc: 85.9375 loss: -3.8444014\n",
      "acc: 85.9375 loss: -3.319952\n",
      "acc: 79.6875 loss: -3.1815026\n",
      "acc: 84.375 loss: -3.6828942\n",
      "acc: 89.0625 loss: -3.8312194\n",
      "acc: 84.375 loss: -3.6964827\n",
      "acc: 89.0625 loss: -3.9952042\n",
      "acc: 82.8125 loss: -3.2497203\n",
      "acc: 79.6875 loss: -3.5032423\n",
      "acc: 81.25 loss: -3.254736\n",
      "acc: 87.5 loss: -3.7861812\n",
      "acc: 87.5 loss: -3.895445\n",
      "acc: 71.875 loss: -2.4892313\n",
      "acc: 84.375 loss: -4.101566\n",
      "acc: 87.5 loss: -3.624878\n",
      "acc: 89.0625 loss: -3.5769866\n",
      "acc: 82.8125 loss: -3.4757488\n",
      "acc: 76.5625 loss: -3.0202918\n",
      "acc: 79.6875 loss: -3.4643106\n",
      "acc: 87.5 loss: -4.053725\n",
      "acc: 85.9375 loss: -3.6128235\n",
      "acc: 87.5 loss: -3.6222372\n",
      "acc: 82.8125 loss: -2.9973705\n",
      "acc: 79.6875 loss: -2.9667478\n",
      "acc: 79.6875 loss: -2.8948963\n",
      "acc: 78.125 loss: -2.6422348\n",
      "acc: 84.375 loss: -3.4344883\n",
      "acc: 87.5 loss: -4.60701\n",
      "acc: 75.0 loss: -3.1328511\n",
      "acc: 81.25 loss: -3.5850315\n",
      "acc: 81.25 loss: -3.4039674\n",
      "acc: 87.5 loss: -3.5623693\n",
      "acc: 90.625 loss: -3.4798872\n",
      "acc: 89.0625 loss: -3.697643\n",
      "acc: 79.6875 loss: -2.9873877\n",
      "acc: 82.8125 loss: -3.216546\n",
      "acc: 92.1875 loss: -3.5595741\n",
      "acc: 82.8125 loss: -3.8044865\n",
      "acc: 87.5 loss: -3.7902517\n",
      "acc: 89.0625 loss: -3.9308972\n",
      "acc: 90.625 loss: -4.5188465\n",
      "acc: 81.25 loss: -3.3361783\n",
      "acc: 87.5 loss: -4.0706396\n",
      "acc: 84.375 loss: -3.3286362\n",
      "acc: 93.75 loss: -4.0744805\n",
      "acc: 82.8125 loss: -4.086411\n",
      "acc: 84.375 loss: -3.2322145\n",
      "acc: 84.375 loss: -3.441444\n",
      "acc: 85.9375 loss: -3.8058467\n",
      "acc: 89.0625 loss: -3.7041957\n",
      "acc: 89.0625 loss: -3.0684545\n",
      "acc: 76.5625 loss: -2.5461037\n",
      "acc: 85.9375 loss: -3.7677486\n",
      "acc: 90.625 loss: -4.179775\n",
      "acc: 81.25 loss: -2.8136485\n",
      "acc: 87.5 loss: -3.917314\n",
      "acc: 92.1875 loss: -4.182538\n",
      "acc: 84.375 loss: -3.315021\n",
      "acc: 82.8125 loss: -3.7579947\n",
      "acc: 89.0625 loss: -3.6444552\n",
      "acc: 85.9375 loss: -3.514317\n",
      "acc: 85.9375 loss: -3.8430498\n",
      "acc: 79.6875 loss: -3.075326\n",
      "acc: 81.25 loss: -2.9918637\n",
      "acc: 87.5 loss: -4.0066943\n",
      "acc: 90.625 loss: -4.00424\n",
      "acc: 82.8125 loss: -3.248649\n",
      "acc: 93.75 loss: -4.3125944\n",
      "acc: 89.0625 loss: -3.4089007\n",
      "acc: 89.0625 loss: -3.9924111\n",
      "acc: 90.625 loss: -4.3698773\n",
      "acc: 90.625 loss: -4.120129\n",
      "acc: 84.375 loss: -3.8928938\n",
      "acc: 75.0 loss: -2.7219515\n",
      "acc: 85.9375 loss: -3.678506\n",
      "acc: 89.0625 loss: -3.122107\n",
      "acc: 87.5 loss: -3.3950286\n",
      "acc: 85.9375 loss: -3.5176826\n",
      "acc: 76.5625 loss: -2.9848807\n",
      "acc: 93.75 loss: -4.3098874\n",
      "acc: 90.625 loss: -4.101682\n",
      "acc: 85.9375 loss: -3.765083\n",
      "acc: 89.0625 loss: -4.138323\n",
      "acc: 82.8125 loss: -3.4832137\n",
      "acc: 89.0625 loss: -3.8889437\n",
      "acc: 92.1875 loss: -3.8015156\n",
      "acc: 84.375 loss: -3.621745\n",
      "acc: 79.6875 loss: -2.5408733\n",
      "acc: 90.625 loss: -4.112693\n",
      "acc: 84.375 loss: -3.0653508\n",
      "acc: 85.9375 loss: -3.54682\n",
      "acc: 85.9375 loss: -3.9591746\n",
      "acc: 82.8125 loss: -3.5128648\n",
      "acc: 87.5 loss: -3.5678751\n",
      "acc: 87.5 loss: -3.2403002\n",
      "acc: 84.375 loss: -3.4728026\n",
      "acc: 75.0 loss: -2.6475835\n",
      "acc: 90.625 loss: -4.0931187\n",
      "acc: 90.625 loss: -3.3400607\n",
      "acc: 92.1875 loss: -3.9498038\n",
      "acc: 87.5 loss: -3.5572867\n",
      "acc: 85.9375 loss: -3.758768\n",
      "acc: 90.625 loss: -3.3926725\n",
      "acc: 89.0625 loss: -3.5632627\n",
      "acc: 87.5 loss: -4.041882\n",
      "acc: 87.5 loss: -3.9643636\n",
      "acc: 84.375 loss: -3.7889307\n",
      "acc: 84.375 loss: -3.3451073\n",
      "acc: 87.5 loss: -4.038074\n",
      "acc: 87.5 loss: -4.376199\n",
      "acc: 85.9375 loss: -3.7706027\n",
      "acc: 93.75 loss: -4.0836806\n",
      "acc: 85.9375 loss: -4.1006403\n",
      "acc: 87.5 loss: -3.8744771\n",
      "acc: 89.0625 loss: -3.9327888\n",
      "acc: 78.125 loss: -2.553375\n",
      "acc: 81.25 loss: -2.8204944\n",
      "acc: 82.8125 loss: -3.287371\n",
      "acc: 85.9375 loss: -3.3869412\n",
      "acc: 93.75 loss: -4.0233192\n",
      "acc: 89.0625 loss: -3.5357733\n",
      "acc: 85.9375 loss: -3.952715\n",
      "acc: 78.125 loss: -2.734078\n",
      "acc: 82.8125 loss: -3.7016213\n",
      "acc: 79.6875 loss: -3.494563\n",
      "acc: 90.625 loss: -3.6958935\n",
      "acc: 90.625 loss: -3.9628463\n",
      "acc: 84.375 loss: -3.393167\n",
      "acc: 85.9375 loss: -3.904002\n",
      "acc: 87.5 loss: -4.1020584\n",
      "acc: 84.375 loss: -3.750414\n",
      "acc: 82.8125 loss: -3.3649516\n",
      "acc: 87.5 loss: -3.3986266\n",
      "acc: 84.375 loss: -3.4756842\n",
      "acc: 85.9375 loss: -3.3243253\n",
      "acc: 89.0625 loss: -4.2626557\n",
      "acc: 84.375 loss: -3.727354\n",
      "acc: 90.625 loss: -4.3914123\n",
      "acc: 87.5 loss: -4.5224447\n",
      "acc: 87.5 loss: -3.985183\n",
      "acc: 87.5 loss: -3.9666963\n",
      "acc: 87.5 loss: -3.9088159\n",
      "acc: 82.8125 loss: -3.1266646\n",
      "acc: 89.0625 loss: -3.9852417\n",
      "acc: 82.8125 loss: -3.5212746\n",
      "acc: 89.0625 loss: -3.548561\n",
      "acc: 82.8125 loss: -3.124261\n",
      "acc: 78.125 loss: -2.830832\n",
      "acc: 82.8125 loss: -3.523067\n",
      "acc: 81.25 loss: -2.7504745\n",
      "acc: 85.9375 loss: -3.2465272\n",
      "acc: 90.625 loss: -4.1787653\n",
      "acc: 79.6875 loss: -3.303904\n",
      "acc: 81.25 loss: -3.682547\n",
      "acc: 87.5 loss: -3.3530226\n",
      "acc: 82.8125 loss: -3.1589878\n",
      "acc: 90.625 loss: -3.8720465\n",
      "acc: 85.9375 loss: -3.1386576\n",
      "acc: 89.0625 loss: -3.2409172\n",
      "acc: 92.1875 loss: -3.8583565\n",
      "acc: 87.5 loss: -3.9089293\n",
      "acc: 90.625 loss: -3.9717522\n",
      "acc: 85.9375 loss: -4.03714\n",
      "acc: 95.3125 loss: -4.7643356\n",
      "acc: 81.25 loss: -3.1108015\n",
      "acc: 82.8125 loss: -3.2909055\n",
      "acc: 81.25 loss: -3.3561385\n",
      "acc: 87.5 loss: -4.281766\n",
      "acc: 87.5 loss: -3.5945292\n",
      "acc: 82.8125 loss: -3.1666946\n",
      "acc: 90.625 loss: -4.0326104\n",
      "acc: 79.6875 loss: -2.5766315\n",
      "acc: 90.625 loss: -4.089251\n",
      "acc: 81.25 loss: -3.2453716\n",
      "acc: 79.6875 loss: -3.078361\n",
      "acc: 89.0625 loss: -4.1555324\n",
      "acc: 85.9375 loss: -3.7245672\n",
      "acc: 84.375 loss: -3.2276926\n",
      "acc: 84.375 loss: -3.305653\n",
      "acc: 82.8125 loss: -3.1794727\n",
      "acc: 81.25 loss: -3.2815251\n",
      "acc: 89.0625 loss: -4.010278\n",
      "acc: 85.9375 loss: -3.77394\n",
      "acc: 82.8125 loss: -3.477012\n",
      "acc: 90.625 loss: -3.7184188\n",
      "acc: 90.625 loss: -3.8178995\n",
      "acc: 84.375 loss: -3.6265357\n",
      "acc: 89.0625 loss: -3.8315895\n",
      "acc: 84.375 loss: -3.4438345\n",
      "acc: 92.1875 loss: -4.1294937\n",
      "acc: 71.875 loss: -2.5371993\n",
      "acc: 84.375 loss: -3.4013124\n",
      "acc: 89.0625 loss: -3.739257\n",
      "acc: 92.1875 loss: -4.2229085\n",
      "acc: 85.9375 loss: -3.477822\n",
      "acc: 89.0625 loss: -4.225688\n",
      "acc: 84.375 loss: -4.074718\n",
      "acc: 89.0625 loss: -3.5016334\n",
      "acc: 89.0625 loss: -3.9510295\n",
      "acc: 87.5 loss: -4.212562\n",
      "acc: 84.375 loss: -3.7831116\n",
      "acc: 89.0625 loss: -4.1117744\n",
      "acc: 90.625 loss: -3.8245735\n",
      "acc: 73.4375 loss: -2.4190202\n",
      "acc: 87.5 loss: -3.925026\n",
      "acc: 87.5 loss: -3.4151316\n",
      "acc: 84.375 loss: -2.8816686\n",
      "acc: 95.3125 loss: -4.642841\n",
      "acc: 85.9375 loss: -3.233096\n",
      "acc: 89.0625 loss: -3.4987614\n",
      "acc: 87.5 loss: -3.3617463\n",
      "acc: 89.0625 loss: -3.84838\n",
      "acc: 87.5 loss: -4.3498306\n",
      "acc: 92.1875 loss: -4.2257113\n",
      "acc: 87.5 loss: -4.069091\n",
      "acc: 87.5 loss: -4.3346667\n",
      "acc: 92.1875 loss: -3.8136494\n",
      "acc: 84.375 loss: -2.996439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 87.5 loss: -3.601067\n",
      "acc: 93.75 loss: -4.1231465\n",
      "acc: 85.9375 loss: -3.1557076\n",
      "acc: 90.625 loss: -3.9553368\n",
      "acc: 87.5 loss: -2.9513798\n",
      "acc: 89.0625 loss: -4.098056\n",
      "acc: 81.25 loss: -3.1338832\n",
      "acc: 87.5 loss: -3.5698006\n",
      "acc: 87.5 loss: -4.3907623\n",
      "acc: 87.5 loss: -4.314297\n",
      "acc: 89.0625 loss: -3.8715365\n",
      "acc: 84.375 loss: -3.326603\n",
      "acc: 84.375 loss: -3.1291974\n",
      "acc: 87.5 loss: -3.455706\n",
      "acc: 85.9375 loss: -3.8601267\n",
      "acc: 98.4375 loss: -4.203083\n",
      "acc: 95.3125 loss: -4.485583\n",
      "acc: 87.5 loss: -4.3818836\n",
      "acc: 89.0625 loss: -4.0287056\n",
      "acc: 82.8125 loss: -3.5727122\n",
      "acc: 92.1875 loss: -4.4934893\n",
      "acc: 84.375 loss: -3.636011\n",
      "acc: 84.375 loss: -3.3933883\n",
      "acc: 79.6875 loss: -3.3341613\n",
      "acc: 85.9375 loss: -3.8672633\n",
      "acc: 95.3125 loss: -3.833325\n",
      "acc: 92.1875 loss: -3.6657445\n",
      "acc: 90.625 loss: -3.6764133\n",
      "acc: 95.3125 loss: -4.020876\n",
      "acc: 85.9375 loss: -3.436744\n",
      "acc: 84.375 loss: -3.2405477\n",
      "acc: 89.0625 loss: -3.8061929\n",
      "acc: 90.625 loss: -3.9030101\n",
      "acc: 90.625 loss: -3.568936\n",
      "acc: 87.5 loss: -3.8073676\n",
      "acc: 92.1875 loss: -3.8017488\n",
      "acc: 90.625 loss: -3.5525327\n",
      "acc: 89.0625 loss: -2.9221468\n",
      "acc: 89.0625 loss: -3.6640842\n",
      "acc: 93.75 loss: -4.3338737\n",
      "acc: 82.8125 loss: -3.3286295\n",
      "acc: 87.5 loss: -3.5165157\n",
      "acc: 92.1875 loss: -4.0504427\n",
      "acc: 75.0 loss: -2.487575\n",
      "acc: 82.8125 loss: -3.6098526\n",
      "acc: 85.9375 loss: -3.4028592\n",
      "acc: 82.8125 loss: -3.849684\n",
      "acc: 85.9375 loss: -3.947515\n",
      "acc: 85.9375 loss: -3.6145988\n",
      "acc: 82.8125 loss: -3.8091989\n",
      "acc: 82.8125 loss: -3.2812607\n",
      "acc: 93.75 loss: -4.892265\n",
      "acc: 93.75 loss: -4.396615\n",
      "acc: 87.5 loss: -3.8324897\n",
      "acc: 85.9375 loss: -3.9371786\n",
      "acc: 92.1875 loss: -3.885306\n",
      "acc: 84.375 loss: -3.8111792\n",
      "acc: 90.625 loss: -3.9093015\n",
      "acc: 82.8125 loss: -3.567968\n",
      "acc: 87.5 loss: -4.0082874\n",
      "acc: 85.9375 loss: -3.4664245\n",
      "acc: 93.75 loss: -4.2884536\n",
      "acc: 90.625 loss: -4.472109\n",
      "acc: 84.375 loss: -3.814922\n",
      "acc: 82.8125 loss: -3.6067035\n",
      "acc: 93.75 loss: -4.162508\n",
      "acc: 92.1875 loss: -4.6975327\n",
      "acc: 85.9375 loss: -4.129757\n",
      "acc: 85.9375 loss: -3.821065\n",
      "acc: 87.5 loss: -3.9560666\n",
      "acc: 84.375 loss: -3.3591204\n",
      "acc: 89.0625 loss: -3.7045703\n",
      "acc: 89.0625 loss: -3.8337965\n",
      "acc: 82.8125 loss: -3.017855\n",
      "acc: 84.375 loss: -3.26268\n",
      "acc: 79.6875 loss: -3.2810106\n",
      "acc: 84.375 loss: -3.8235574\n",
      "acc: 90.625 loss: -4.166355\n",
      "acc: 93.75 loss: -4.578466\n",
      "acc: 95.3125 loss: -4.111158\n",
      "acc: 75.0 loss: -3.0720758\n",
      "acc: 82.8125 loss: -3.7572377\n",
      "acc: 84.375 loss: -3.6627834\n",
      "acc: 79.6875 loss: -3.528779\n",
      "acc: 85.9375 loss: -3.2929933\n",
      "acc: 85.9375 loss: -3.2732458\n",
      "acc: 87.5 loss: -3.7468572\n",
      "acc: 93.75 loss: -4.116295\n",
      "acc: 92.1875 loss: -3.8508778\n",
      "acc: 93.75 loss: -4.500561\n",
      "acc: 92.1875 loss: -4.305682\n",
      "acc: 95.3125 loss: -4.6196675\n",
      "acc: 89.0625 loss: -3.9470518\n",
      "acc: 93.75 loss: -5.1897645\n",
      "acc: 89.0625 loss: -3.4383097\n",
      "acc: 85.9375 loss: -3.7082074\n",
      "acc: 87.5 loss: -4.0914044\n",
      "acc: 81.25 loss: -2.718755\n",
      "acc: 87.5 loss: -4.3258877\n",
      "acc: 95.3125 loss: -4.1420674\n",
      "acc: 84.375 loss: -3.3981388\n",
      "acc: 90.625 loss: -3.7307544\n",
      "acc: 92.1875 loss: -4.066698\n",
      "acc: 90.625 loss: -3.7283225\n",
      "acc: 95.3125 loss: -4.1713142\n",
      "acc: 92.1875 loss: -3.4295747\n",
      "acc: 89.0625 loss: -4.3358083\n",
      "acc: 87.5 loss: -3.8935354\n",
      "acc: 90.625 loss: -4.40927\n",
      "acc: 90.625 loss: -4.156531\n",
      "acc: 89.0625 loss: -3.682423\n",
      "acc: 90.625 loss: -3.9107804\n",
      "acc: 82.8125 loss: -3.76202\n",
      "acc: 90.625 loss: -4.000572\n",
      "acc: 93.75 loss: -4.5711775\n",
      "acc: 85.9375 loss: -4.0418086\n",
      "acc: 85.9375 loss: -3.6417553\n",
      "acc: 96.875 loss: -4.4569163\n",
      "acc: 84.375 loss: -2.95746\n",
      "acc: 87.5 loss: -3.364213\n",
      "acc: 87.5 loss: -3.8645673\n",
      "acc: 87.5 loss: -3.732174\n",
      "acc: 87.5 loss: -4.0730553\n",
      "acc: 92.1875 loss: -3.897901\n",
      "acc: 87.5 loss: -3.7148929\n",
      "acc: 87.5 loss: -4.0149674\n",
      "acc: 84.375 loss: -3.617241\n",
      "acc: 82.8125 loss: -3.512247\n",
      "acc: 82.8125 loss: -3.7136354\n",
      "acc: 90.625 loss: -3.8939247\n",
      "acc: 89.0625 loss: -3.3219733\n",
      "acc: 89.0625 loss: -3.8913245\n",
      "acc: 93.75 loss: -4.049497\n",
      "acc: 85.9375 loss: -3.5991862\n",
      "acc: 89.0625 loss: -3.9335794\n",
      "acc: 87.5 loss: -4.0040617\n",
      "acc: 85.9375 loss: -4.0016274\n",
      "acc: 81.25 loss: -3.8724942\n",
      "acc: 90.625 loss: -4.0516114\n",
      "acc: 89.0625 loss: -3.7486324\n",
      "acc: 92.1875 loss: -3.5969193\n",
      "acc: 90.625 loss: -3.82947\n",
      "acc: 90.625 loss: -3.8512936\n",
      "acc: 90.625 loss: -4.6342444\n",
      "acc: 84.375 loss: -3.9768748\n",
      "acc: 89.0625 loss: -3.4777317\n",
      "acc: 89.0625 loss: -3.9313555\n",
      "acc: 81.25 loss: -2.9160702\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(ram.parameters(), lr=3e-3)\n",
    "for t in range(1000):\n",
    "    data, y = next(iter(data_loader_train))\n",
    "    log_probas, log_pis, baselines = ram(data)\n",
    "    \n",
    "    # reward\n",
    "    predicted = torch.max(log_probas, 1)[1]\n",
    "    correct = (predicted.detach() == y).float() # detach()????\n",
    "    R = correct.unsqueeze(1).repeat(1, num_glimpse)\n",
    "    \n",
    "    adjusted_reward = R - baselines.detach()\n",
    "    loss_reinforce = torch.sum(-log_pis*adjusted_reward, dim=1)\n",
    "    loss_reinforce = torch.mean(loss_reinforce, dim=0)\n",
    "    loss_action = F.nll_loss(log_probas, y)\n",
    "    loss = loss_reinforce + loss_action\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    acc = 100 * (correct.sum() / len(y))\n",
    "    print('acc:', acc.numpy(), 'loss:', loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
