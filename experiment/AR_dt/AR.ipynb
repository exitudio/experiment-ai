{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import shutil\n",
    "import os\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = './data/train'\n",
    "VAL_FOLDER = './data/val'\n",
    "TEST_FOLDER = './data/test'\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. generate object images with perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' EXAMPLE\n",
    "_ = get_distort_image({\n",
    "    'image_path':'source-data/object/dt1.png',\n",
    "    'top_left': {'x':40, 'y':40},\n",
    "    'top_right': {'x':44, 'y':47},\n",
    "    'bottom_left': {'x':40, 'y':33},\n",
    "    'bottom_right': {'x':39, 'y':35},\n",
    "})\n",
    "'''\n",
    "def get_distort_image(image_data):\n",
    "    image = cv2.imread(image_data['image_path'], cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # hue\n",
    "    temp_alpha = image[:, :, 3]\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    rand = np.random.randint(0, 180)\n",
    "    image[:, :, 0] += rand\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "    # convert back with alpha channel\n",
    "    image = cv2.merge((\n",
    "        image[:, :, 0], \n",
    "        image[:, :, 1], \n",
    "        image[:, :, 2], \n",
    "        temp_alpha))\n",
    "    \n",
    "    cols, rows, ch = image.shape\n",
    "\n",
    "    output_rows = output_cols = np.random.randint(50, IMAGE_SIZE)\n",
    "    SMALL_RECT_LEFT = output_rows*2/6\n",
    "    SMALL_RECT_RIGHT = output_rows*4/6\n",
    "    SMALL_RECT_TOP = output_cols*2/6\n",
    "    SMALL_RECT_BOTTOM = output_cols*4/6\n",
    "    \n",
    "    # random all points\n",
    "    left = np.random.randint(0, SMALL_RECT_LEFT, size=2)\n",
    "    right = np.random.randint(SMALL_RECT_RIGHT, output_cols, size=2)\n",
    "    top = np.random.randint(0, SMALL_RECT_TOP, size=2)\n",
    "    bottom = np.random.randint(SMALL_RECT_BOTTOM, output_rows, size=2)\n",
    "    \n",
    "    # declare points\n",
    "    pts1 = np.float32([[image_data['top_left']['x'], image_data['top_left']['y']],\n",
    "                       [cols - image_data['top_right']['x'], image_data['top_right']['y']],\n",
    "                       [image_data['bottom_left']['x'], rows - image_data['bottom_left']['y']],\n",
    "                       [cols - image_data['bottom_right']['x'], rows - image_data['bottom_right']['y']]])\n",
    "\n",
    "    top_left = [left[0], top[0]]\n",
    "    right_top = [right[0], top[1]]\n",
    "    left_bottom = [left[1], bottom[0]]\n",
    "    right_bottom = [right[1], bottom[1]]\n",
    "    pts2 = np.float32([top_left, right_top, left_bottom, right_bottom])\n",
    "\n",
    "\n",
    "    # transform\n",
    "    perspectiveTransform = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    image = cv2.warpPerspective(image, perspectiveTransform, (output_cols, output_rows))\n",
    "    \n",
    "    # draw bounding box\n",
    "#     lines = [np.int32([top_left, right_top, right_bottom, left_bottom])]\n",
    "#     cv2.polylines(image, lines, True, color=(0, 0, 255, 255), thickness=1)\n",
    "    \n",
    "    return image, pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_augmented_background('source-data/background/bg1.jpg')\n",
    "def gen_augmented_background(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    cols, rows, _ = image.shape\n",
    "    x = np.random.randint(0, cols - IMAGE_SIZE)\n",
    "    y = np.random.randint(0, rows - IMAGE_SIZE)\n",
    "    image = image[x:x+IMAGE_SIZE, y:y+IMAGE_SIZE]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_image(top_image, background_image, x_offset, y_offset):\n",
    "    y1, y2 = y_offset, y_offset + top_image.shape[0]\n",
    "    x1, x2 = x_offset, x_offset + top_image.shape[1]\n",
    "\n",
    "    alpha_top = top_image[:, :, 3] / 255.0\n",
    "    alpha_background = 1.0 - alpha_top\n",
    "    \n",
    "    image = background_image[:,:,:]\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        a1 = alpha_top * top_image[:, :, c]\n",
    "        a2 = alpha_background * background_image[y1:y2, x1:x2, c]\n",
    "        image[y1:y2, x1:x2, c] = (a1 + a2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_image_datas = [{\n",
    "        'image_path': 'source-data/object/dt0.png',\n",
    "        'top_left': {'x':0, 'y':0},\n",
    "        'top_right': {'x':0, 'y':0},\n",
    "        'bottom_left': {'x':0, 'y':0},\n",
    "        'bottom_right': {'x':0, 'y':0},\n",
    "    },{\n",
    "        'image_path': 'source-data/object/dt1.png',\n",
    "        'top_left': {'x':40, 'y':40},\n",
    "        'top_right': {'x':44, 'y':47},\n",
    "        'bottom_left': {'x':40, 'y':33},\n",
    "        'bottom_right': {'x':39, 'y':35},\n",
    "    },{\n",
    "        'image_path': 'source-data/object/dt2.png',\n",
    "        'top_left': {'x':14, 'y':22},\n",
    "        'top_right': {'x':12, 'y':17},\n",
    "        'bottom_left': {'x':14, 'y':8},\n",
    "        'bottom_right': {'x':8, 'y':11},\n",
    "    }]\n",
    "background_image_paths = ['source-data/background/bg1.jpg',\n",
    "                            'source-data/background/bg2.jpg',\n",
    "                            'source-data/background/bg3.jpg',\n",
    "                            'source-data/background/bg4.jpg']\n",
    "\n",
    "def gen_images(num_image, path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "    \n",
    "    corners = []\n",
    "    for i in range(num_image):\n",
    "        \n",
    "        # random index\n",
    "        object_image_index = np.random.randint(0, len(object_image_datas))\n",
    "        background_image_index = np.random.randint(0, len(background_image_paths))\n",
    "\n",
    "        # gen images\n",
    "        object_image, one_image_corners = get_distort_image(object_image_datas[object_image_index])\n",
    "        bg_image = gen_augmented_background(background_image_paths[background_image_index])\n",
    "\n",
    "        # merge images\n",
    "        obj_cols, obj_rows, _ = object_image.shape\n",
    "        bg_cols, bg_rows, _ = bg_image.shape\n",
    "        \n",
    "        offset_x = np.random.randint(0, bg_cols - obj_cols)\n",
    "        offset_y = np.random.randint(0, bg_rows - obj_rows)\n",
    "        \n",
    "        one_image_corners[:, 0] += offset_x\n",
    "        one_image_corners[:, 1] += offset_y\n",
    "        \n",
    "        image = overlay_image(object_image, bg_image, offset_x, offset_y)\n",
    "        \n",
    "        # save image\n",
    "        # cv2.polylines(image, [np.int32(one_image_corners)], True, color=(0, 0, 255, 255), thickness=1)\n",
    "        cv2.imwrite(f'{path}/object_image{i}.png',image)\n",
    "        \n",
    "        # save points\n",
    "        one_image_corners = np.concatenate(one_image_corners) # concatenate all points to one array\n",
    "        corners.append(one_image_corners)\n",
    "    \n",
    "    file = open(f'{path}/corners.csv', 'w')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(corners)\n",
    "\n",
    "gen_images(4112, TRAIN_FOLDER)\n",
    "gen_images(512, TEST_FOLDER)\n",
    "gen_images(512, VAL_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "from keras.applications.mobilenet import MobileNet, _depthwise_conv_block\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils import Sequence\n",
    "\n",
    "ALPHA = 0.25\n",
    "# IMAGE_SIZE = 128 move to top\n",
    "\n",
    "EPOCHS = 5000\n",
    "PATIENCE = 100\n",
    "\n",
    "\n",
    "class DataSequence(Sequence):\n",
    "\n",
    "    def __load_images(self, dataset):\n",
    "        out = []\n",
    "        for file_name in dataset:\n",
    "            im = cv2.resize(cv2.imread(file_name), (self.image_size, self.image_size))\n",
    "            out.append(im)\n",
    "\n",
    "        return np.array(out)\n",
    "\n",
    "    def __init__(self, csv_file, image_path, image_size, batch_size=32, feature_scaling=False):\n",
    "        self.csv_file = csv_file\n",
    "        with open(self.csv_file, \"r\") as file:\n",
    "            reader = csv.reader(file, delimiter=\",\")\n",
    "            arr = list(reader)\n",
    "\n",
    "        self.y = np.zeros((len(arr), 8))\n",
    "        self.x = []\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # for index, (path, class_id, width, height, x0, y0, x1, y1) in enumerate(arr):\n",
    "        for index, coner_points in enumerate(arr):\n",
    "            self.y[index] = np.array(coner_points)\n",
    "            self.x.append(f'{image_path}/object_image{index}.png')\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_scaling = feature_scaling\n",
    "        if self.feature_scaling:\n",
    "            dataset = self.__load_images(self.x)\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[2] = dataset.shape[3]\n",
    "\n",
    "            self.mean = np.mean(dataset, axis=(0, 1, 2))\n",
    "            self.mean = np.reshape(self.mean, broadcast_shape)\n",
    "            self.std = np.std(dataset, axis=(0, 1, 2))\n",
    "            self.std = np.reshape(self.std, broadcast_shape) + K.epsilon()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        images = self.__load_images(batch_x).astype('float32')\n",
    "        if self.feature_scaling:\n",
    "            images -= self.mean\n",
    "            images /= self.std\n",
    "\n",
    "        return images, batch_y\n",
    "\n",
    "\n",
    "def create_model(size, alpha):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     input_shape=(size, size, 3)))\n",
    "#     model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "    print(model.output_shape)\n",
    "    model.add(MaxPooling2D((27, 27)))\n",
    "    model.add(Conv2D(8, (1, 1), activation='relu'))\n",
    "    print(model.output_shape)\n",
    "    model.add(Reshape((8,)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(8))\n",
    "    return model\n",
    "\n",
    "def create_model2(size, alpha):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(size, size, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#     model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.3))\n",
    "    model.add(Dense(8))\n",
    "    return model\n",
    "\n",
    "def create_mobile_net_model(size, alpha):\n",
    "    model_net = MobileNet(input_shape=(size, size, 3), include_top=False, alpha=alpha)\n",
    "    x = _depthwise_conv_block(model_net.layers[-1].output, 1024, alpha, 1, block_id=14)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4))(x)\n",
    "    x = Conv2D(8, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    x = Reshape((8,))(x)\n",
    "    \n",
    "#     if I use flatten it will cause overfitting, I don't know why\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(8)(x)\n",
    "\n",
    "    return Model(inputs=model_net.input, outputs=x)\n",
    "\n",
    "\n",
    "def train(model, epochs, image_size):\n",
    "    train_datagen = DataSequence(\"./data/train/corners.csv\", \"./data/train\", image_size)\n",
    "    validation_datagen = DataSequence(\"./data/val/corners.csv\", \"./data/val\", image_size)\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    checkpoint = ModelCheckpoint(\"model-{val_acc:.2f}.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=True, mode=\"auto\", period=1)\n",
    "    stop = EarlyStopping(monitor=\"val_acc\", patience=PATIENCE, mode=\"auto\")\n",
    "\n",
    "    model.fit_generator(train_datagen, steps_per_epoch=1028, epochs=epochs, validation_data=validation_datagen,\n",
    "                        validation_steps=22, callbacks=[checkpoint, stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1028/1028 [==============================] - 187s 182ms/step - loss: 305.3089 - acc: 0.7064 - val_loss: 42.2550 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87358, saving model to model-0.87.h5\n",
      "Epoch 2/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 13.7456 - acc: 0.8826 - val_loss: 26.1745 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87358\n",
      "Epoch 3/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 7.4707 - acc: 0.9039 - val_loss: 15.9888 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87358 to 0.89347, saving model to model-0.89.h5\n",
      "Epoch 4/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 6.3785 - acc: 0.9161 - val_loss: 16.0462 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89347 to 0.89631, saving model to model-0.90.h5\n",
      "Epoch 5/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 6.4587 - acc: 0.9232 - val_loss: 18.4666 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89631\n",
      "Epoch 6/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 4.5135 - acc: 0.9340 - val_loss: 15.0852 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89631\n",
      "Epoch 7/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 4.4198 - acc: 0.9382 - val_loss: 12.0400 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.89631 to 0.90199, saving model to model-0.90.h5\n",
      "Epoch 8/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 4.0938 - acc: 0.9460 - val_loss: 16.2223 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.90199 to 0.91477, saving model to model-0.91.h5\n",
      "Epoch 9/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 3.3921 - acc: 0.9473 - val_loss: 10.4127 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91477\n",
      "Epoch 10/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 3.0297 - acc: 0.9538 - val_loss: 13.7555 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91477\n",
      "Epoch 11/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 2.5798 - acc: 0.9534 - val_loss: 9.2833 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91477\n",
      "Epoch 12/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 2.5519 - acc: 0.9562 - val_loss: 10.5244 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.91477 to 0.91761, saving model to model-0.92.h5\n",
      "Epoch 13/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 3.0692 - acc: 0.9541 - val_loss: 8.5869 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91761\n",
      "Epoch 14/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.5953 - acc: 0.9642 - val_loss: 9.3434 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.91761 to 0.92045, saving model to model-0.92.h5\n",
      "Epoch 15/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 2.1113 - acc: 0.9628 - val_loss: 7.3331 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92045\n",
      "Epoch 16/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.7732 - acc: 0.9667 - val_loss: 5.7517 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92045\n",
      "Epoch 17/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.5918 - acc: 0.9663 - val_loss: 7.6667 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92045\n",
      "Epoch 18/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 2.0014 - acc: 0.9643 - val_loss: 6.3246 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92045\n",
      "Epoch 19/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.4804 - acc: 0.9691 - val_loss: 6.2074 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92045\n",
      "Epoch 20/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.1368 - acc: 0.9691 - val_loss: 5.8939 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92045\n",
      "Epoch 21/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.5985 - acc: 0.9665 - val_loss: 5.9308 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92045\n",
      "Epoch 22/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 1.1898 - acc: 0.9714 - val_loss: 11.3270 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92045\n",
      "Epoch 23/5000\n",
      "1028/1028 [==============================] - 179s 174ms/step - loss: 1.4612 - acc: 0.9688 - val_loss: 7.6916 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.92045\n",
      "Epoch 24/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.0994 - acc: 0.9718 - val_loss: 5.0224 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.92045\n",
      "Epoch 25/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.1467 - acc: 0.9723 - val_loss: 5.8809 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.92045\n",
      "Epoch 26/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 1.2437 - acc: 0.9735 - val_loss: 8.9034 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.92045\n",
      "Epoch 27/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.0480 - acc: 0.9730 - val_loss: 6.6466 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.92045\n",
      "Epoch 28/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.8587 - acc: 0.9739 - val_loss: 6.4225 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.92045 to 0.92188, saving model to model-0.92.h5\n",
      "Epoch 29/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.1533 - acc: 0.9708 - val_loss: 4.8907 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.92188\n",
      "Epoch 30/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.0193 - acc: 0.9722 - val_loss: 5.1193 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.92188\n",
      "Epoch 31/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.8696 - acc: 0.9743 - val_loss: 7.5668 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.92188 to 0.93040, saving model to model-0.93.h5\n",
      "Epoch 32/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.7635 - acc: 0.9749 - val_loss: 9.0939 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93040\n",
      "Epoch 33/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.9868 - acc: 0.9716 - val_loss: 7.9063 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.93040\n",
      "Epoch 34/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.7637 - acc: 0.9745 - val_loss: 5.6983 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.93040\n",
      "Epoch 35/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 1.0989 - acc: 0.9733 - val_loss: 5.6891 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.93040\n",
      "Epoch 36/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.6158 - acc: 0.9773 - val_loss: 6.3260 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.93040\n",
      "Epoch 37/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.8418 - acc: 0.9752 - val_loss: 6.1019 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.93040\n",
      "Epoch 38/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.8324 - acc: 0.9757 - val_loss: 7.0097 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.93040 to 0.94034, saving model to model-0.94.h5\n",
      "Epoch 39/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.8390 - acc: 0.9758 - val_loss: 5.5110 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.94034\n",
      "Epoch 40/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.5641 - acc: 0.9776 - val_loss: 6.2721 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.94034\n",
      "Epoch 41/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.9172 - acc: 0.9765 - val_loss: 7.4072 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.94034\n",
      "Epoch 42/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.5845 - acc: 0.9778 - val_loss: 5.3455 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.94034\n",
      "Epoch 43/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 0.5553 - acc: 0.9781 - val_loss: 7.9729 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.94034\n",
      "Epoch 44/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.7728 - acc: 0.9744 - val_loss: 6.9808 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.94034\n",
      "Epoch 45/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.6480 - acc: 0.9780 - val_loss: 7.7656 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.94034\n",
      "Epoch 46/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.6279 - acc: 0.9767 - val_loss: 4.7622 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.94034\n",
      "Epoch 47/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.7833 - acc: 0.9763 - val_loss: 6.8394 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.94034\n",
      "Epoch 48/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 0.6629 - acc: 0.9789 - val_loss: 7.4624 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.94034\n",
      "Epoch 49/5000\n",
      "1028/1028 [==============================] - 179s 174ms/step - loss: 0.5367 - acc: 0.9778 - val_loss: 6.9355 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.94034\n",
      "Epoch 50/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.6175 - acc: 0.9776 - val_loss: 7.0967 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.94034\n",
      "Epoch 51/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 0.5541 - acc: 0.9772 - val_loss: 6.6054 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.94034\n",
      "Epoch 52/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.7229 - acc: 0.9765 - val_loss: 5.5267 - val_acc: 0.9290\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.94034\n",
      "Epoch 53/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 0.5158 - acc: 0.9801 - val_loss: 8.2298 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.94034\n",
      "Epoch 54/5000\n",
      "1028/1028 [==============================] - 179s 174ms/step - loss: 0.5523 - acc: 0.9801 - val_loss: 7.0150 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.94034\n",
      "Epoch 55/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.4951 - acc: 0.9790 - val_loss: 7.7679 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.94034\n",
      "Epoch 56/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 0.4806 - acc: 0.9790 - val_loss: 5.7852 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.94034\n",
      "Epoch 57/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.4878 - acc: 0.9788 - val_loss: 7.6074 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.94034\n",
      "Epoch 58/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.6210 - acc: 0.9782 - val_loss: 5.9737 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.94034\n",
      "Epoch 59/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 0.4799 - acc: 0.9803 - val_loss: 8.5719 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.94034\n",
      "Epoch 60/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.5355 - acc: 0.9800 - val_loss: 7.2522 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.94034\n",
      "Epoch 61/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.5529 - acc: 0.9802 - val_loss: 12.6080 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.94034\n",
      "Epoch 62/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.4534 - acc: 0.9810 - val_loss: 8.3326 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.94034\n",
      "Epoch 63/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.7432 - acc: 0.9768 - val_loss: 6.3467 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.94034\n",
      "Epoch 64/5000\n",
      "1028/1028 [==============================] - 179s 175ms/step - loss: 0.3980 - acc: 0.9794 - val_loss: 6.1961 - val_acc: 0.9276\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.94034\n",
      "Epoch 65/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.4024 - acc: 0.9795 - val_loss: 7.1489 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.94034\n",
      "Epoch 66/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.4860 - acc: 0.9791 - val_loss: 7.2976 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.94034\n",
      "Epoch 67/5000\n",
      "1028/1028 [==============================] - 180s 175ms/step - loss: 0.4933 - acc: 0.9810 - val_loss: 5.6967 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.94034\n",
      "Epoch 68/5000\n",
      " 317/1028 [========>.....................] - ETA: 2:03 - loss: 0.4645 - acc: 0.9817"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    model = create_mobile_net_model(IMAGE_SIZE, ALPHA)\n",
    "#     model = create_model2(IMAGE_SIZE, ALPHA)\n",
    "    train(model, EPOCHS, IMAGE_SIZE)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validation/ gen prediction lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "\n",
    "OUTPUT_TEST_PATH = './data/output_test'\n",
    "if os.path.isdir(OUTPUT_TEST_PATH):\n",
    "    shutil.rmtree(OUTPUT_TEST_PATH)\n",
    "model = create_mobile_net_model(IMAGE_SIZE, ALPHA)\n",
    "model.load_weights('model-0.94.h5')\n",
    "\n",
    "image_paths = sorted(glob.glob('{}/*png'.format(TEST_FOLDER)))\n",
    "for i in range(len(image_paths)):\n",
    "    image_path = image_paths[i]\n",
    "    image = cv2.resize(cv2.imread(image_path), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    points = model.predict(x=np.array([image]))[0].astype(int)\n",
    "    points = np.array([[points[0], points[1]], \n",
    "                       [points[2], points[3]], \n",
    "                       [points[6], points[7]], \n",
    "                       [points[4], points[5]]])\n",
    "#     print('points:', points)\n",
    "    \n",
    "#     with open('data/train/corners.csv', \"r\") as file:\n",
    "#         reader = csv.reader(file, delimiter=\",\")\n",
    "#         arr = list(reader)\n",
    "#         points = [np.int32(float(str)) for str in arr[0]]\n",
    "#         points = np.array([[points[0], points[1]], \n",
    "#                            [points[2], points[3]], \n",
    "#                            [points[6], points[7]], \n",
    "#                            [points[4], points[5]]])\n",
    "#         print('points:', points)\n",
    "    \n",
    "    cv2.polylines(image, [points], True, (255,255,255))\n",
    "    pathlib.Path(OUTPUT_TEST_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(f'{OUTPUT_TEST_PATH}/image{i}.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
