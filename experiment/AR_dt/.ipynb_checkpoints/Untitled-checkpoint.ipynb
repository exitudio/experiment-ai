{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import glob\n",
    "import csv\n",
    "import cv2\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "from keras.applications.mobilenet import MobileNet, _depthwise_conv_block\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils import Sequence\n",
    "\n",
    "ALPHA = 0.25\n",
    "# IMAGE_SIZE = 128 move to top\n",
    "\n",
    "EPOCHS = 5000\n",
    "PATIENCE = 100\n",
    "\n",
    "\n",
    "class DataSequence(Sequence):\n",
    "\n",
    "    def __load_images(self, dataset):\n",
    "        out = []\n",
    "        for file_name in dataset:\n",
    "            im = cv2.resize(cv2.imread(file_name), (self.image_size, self.image_size))\n",
    "            out.append(im)\n",
    "\n",
    "        return np.array(out)\n",
    "\n",
    "    def __init__(self, csv_file, image_path, image_size, batch_size=32, feature_scaling=False):\n",
    "        self.csv_file = csv_file\n",
    "        with open(self.csv_file, \"r\") as file:\n",
    "            reader = csv.reader(file, delimiter=\",\")\n",
    "            arr = list(reader)\n",
    "\n",
    "        self.y = np.zeros((len(arr), 8))\n",
    "        self.x = []\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # for index, (path, class_id, width, height, x0, y0, x1, y1) in enumerate(arr):\n",
    "        for index, coner_points in enumerate(arr):\n",
    "            self.y[index] = np.array(coner_points)\n",
    "            self.x.append(f'{image_path}/object_image{index}.png')\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_scaling = feature_scaling\n",
    "        if self.feature_scaling:\n",
    "            dataset = self.__load_images(self.x)\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[2] = dataset.shape[3]\n",
    "\n",
    "            self.mean = np.mean(dataset, axis=(0, 1, 2))\n",
    "            self.mean = np.reshape(self.mean, broadcast_shape)\n",
    "            self.std = np.std(dataset, axis=(0, 1, 2))\n",
    "            self.std = np.reshape(self.std, broadcast_shape) + K.epsilon()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        images = self.__load_images(batch_x).astype('float32')\n",
    "        if self.feature_scaling:\n",
    "            images -= self.mean\n",
    "            images /= self.std\n",
    "\n",
    "        return images, batch_y\n",
    "\n",
    "\n",
    "def create_model(size, alpha):\n",
    "    model_net = MobileNet(input_shape=(size, size, 3), include_top=False, alpha=alpha)\n",
    "    x = _depthwise_conv_block(model_net.layers[-1].output, 1024, alpha, 1, block_id=14)\n",
    "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "    x = Conv2D(4, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "#     x = Reshape((4,))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(8)(x)\n",
    "\n",
    "    return Model(inputs=model_net.input, outputs=x)\n",
    "\n",
    "\n",
    "def train(model, epochs, image_size):\n",
    "    train_datagen = DataSequence(\"./data/train/corners.csv\", \"./data/train\", image_size)\n",
    "    validation_datagen = DataSequence(\"./data/val/corners.csv\", \"./data/val\", image_size)\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    checkpoint = ModelCheckpoint(\"model-{val_acc:.2f}.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=True, mode=\"auto\", period=1)\n",
    "    stop = EarlyStopping(monitor=\"val_acc\", patience=PATIENCE, mode=\"auto\")\n",
    "\n",
    "    model.fit_generator(train_datagen, steps_per_epoch=1150, epochs=epochs, validation_data=validation_datagen,\n",
    "                        validation_steps=22, callbacks=[checkpoint, stop])\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = create_model(IMAGE_SIZE, ALPHA)\n",
    "    train(model, EPOCHS, IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_FOLDER = './data/test'\n",
    "OUTPUT_TEST_PATH = './data/output_test'\n",
    "\n",
    "model = create_model(IMAGE_SIZE, ALPHA)\n",
    "model.load_weights('model-0.69.h5')\n",
    "\n",
    "image_paths = sorted(glob.glob('{}/*png'.format(TEST_SET_FOLDER)))\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    image = cv2.resize(cv2.imread(image_path), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    points = model.predict(x=np.array([image]))[0].astype(int)\n",
    "    points = np.array([[points[0], points[1]], \n",
    "                       [points[2], points[3]], \n",
    "                       [points[6], points[7]], \n",
    "                       [points[4], points[5]]])\n",
    "    cv2.polylines(image, [points], True, (255,255,255))\n",
    "    pathlib.Path(OUTPUT_TEST_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(f'{OUTPUT_TEST_PATH}/image{i}.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff8955f6be0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np.zeros((100,100,3))\n",
    "image = cv2.resize(cv2.imread('./data/test/object_image0.png'), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "points = model.predict(x=np.array([image]))[0].astype(int)\n",
    "points = np.array([[points[0], points[1]], [points[2], points[3]], [points[6], points[7]], [points[4], points[5]]])\n",
    "\n",
    "# points = np.array([[10, 10], [40, 10], [50, 40], [20, 40]])\n",
    "cv2.polylines(img, [points], True, (255,255,255))\n",
    "plt.imshow(img.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.1,1.2,1.3]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
